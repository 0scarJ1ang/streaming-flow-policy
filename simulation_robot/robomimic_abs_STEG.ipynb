{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import collections\n",
    "from dataclasses import dataclass\n",
    "import gdown\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Literal, Sequence, Tuple, Union\n",
    "\n",
    "# Imports for diffusion policy\n",
    "import zarr\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "\n",
    "# Imports for the Push-T environment\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "import pymunk\n",
    "import pymunk.pygame_util\n",
    "from pymunk.space_debug_draw_options import SpaceDebugColor\n",
    "from pymunk.vec2d import Vec2d\n",
    "import shapely.geometry as sg\n",
    "import cv2\n",
    "import skimage.transform as st\n",
    "import jupyviz as jviz\n",
    "\n",
    "# always call this first\n",
    "from streaming_flow_policy.all import set_random_seed\n",
    "set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from robomimic.envs.env_robosuite import EnvRobosuite\n",
    "\n",
    "class RobomimicLowdimWrapper(gym.Env):\n",
    "    def __init__(self, \n",
    "        env: EnvRobosuite,\n",
    "        obs_keys: List[str]=[\n",
    "            'object', \n",
    "            'robot0_eef_pos', \n",
    "            'robot0_eef_quat', \n",
    "            'robot0_gripper_qpos'],\n",
    "        init_state: Optional[np.ndarray]=None,\n",
    "        render_hw=(256,256),\n",
    "        render_camera_name='agentview'\n",
    "        ):\n",
    "\n",
    "        self.env = env\n",
    "        self.obs_keys = obs_keys\n",
    "        self.init_state = init_state\n",
    "        self.render_hw = render_hw\n",
    "        self.render_camera_name = render_camera_name\n",
    "        self.seed_state_map = dict()\n",
    "        self._seed = None\n",
    "        \n",
    "        # setup spaces\n",
    "        low = np.full(env.action_dimension, fill_value=-1)\n",
    "        high = np.full(env.action_dimension, fill_value=1)\n",
    "        self.action_space = Box(\n",
    "            low=low,\n",
    "            high=high,\n",
    "            shape=low.shape,\n",
    "            dtype=low.dtype\n",
    "        )\n",
    "        obs_example = self.get_observation()\n",
    "        low = np.full_like(obs_example, fill_value=-1)\n",
    "        high = np.full_like(obs_example, fill_value=1)\n",
    "        self.observation_space = Box(\n",
    "            low=low,\n",
    "            high=high,\n",
    "            shape=low.shape,\n",
    "            dtype=low.dtype\n",
    "        )\n",
    "    # [新增] 添加这个属性，方便外部直接访问 wrapper.sim\n",
    "    @property\n",
    "    def sim(self):\n",
    "        # robomimic 的 EnvRobosuite 把原始环境存在了 .env 属性里\n",
    "        # 所以我们需要穿透两层: wrapper.env -> EnvRobosuite.env -> RobosuiteRawEnv\n",
    "        return self.env.env.sim\n",
    "    \n",
    "    \n",
    "    def get_observation(self):\n",
    "        raw_obs = self.env.get_observation()\n",
    "        obs = np.concatenate([\n",
    "            raw_obs[key] for key in self.obs_keys\n",
    "        ], axis=0)\n",
    "        return obs\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed=seed)\n",
    "        self._seed = seed\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.init_state is not None:\n",
    "            # always reset to the same state\n",
    "            # to be compatible with gym\n",
    "            self.env.reset_to({'states': self.init_state})\n",
    "        elif self._seed is not None:\n",
    "            # reset to a specific seed\n",
    "            seed = self._seed\n",
    "            if seed in self.seed_state_map:\n",
    "                # env.reset is expensive, use cache\n",
    "                self.env.reset_to({'states': self.seed_state_map[seed]})\n",
    "            else:\n",
    "                # robosuite's initializes all use numpy global random state\n",
    "                np.random.seed(seed=seed)\n",
    "                self.env.reset()\n",
    "                state = self.env.get_state()['states']\n",
    "                self.seed_state_map[seed] = state\n",
    "            self._seed = None\n",
    "        else:\n",
    "            # random reset\n",
    "            self.env.reset()\n",
    "\n",
    "        # return obs\n",
    "        obs = self.get_observation()\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        raw_obs, reward, done, info = self.env.step(action)\n",
    "        obs = np.concatenate([\n",
    "            raw_obs[key] for key in self.obs_keys\n",
    "        ], axis=0)\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def render(self, mode='rgb_array'):\n",
    "        h, w = self.render_hw\n",
    "        return self.env.render(mode=mode, \n",
    "            height=h, width=w, \n",
    "            camera_name=self.render_camera_name)\n",
    "\n",
    "\n",
    "def test():\n",
    "    import robomimic.utils.file_utils as FileUtils\n",
    "    import robomimic.utils.env_utils as EnvUtils\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    dataset_path = '/home/cchi/dev/diffusion_policy/data/robomimic/datasets/square/ph/low_dim.hdf5'\n",
    "    env_meta = FileUtils.get_env_metadata_from_dataset(\n",
    "        dataset_path)\n",
    "\n",
    "    env = EnvUtils.create_env_from_metadata(\n",
    "        env_meta=env_meta,\n",
    "        render=False, \n",
    "        render_offscreen=False,\n",
    "        use_image_obs=False, \n",
    "    )\n",
    "    wrapper = RobomimicLowdimWrapper(\n",
    "        env=env,\n",
    "        obs_keys=[\n",
    "            'object', \n",
    "            'robot0_eef_pos', \n",
    "            'robot0_eef_quat', \n",
    "            'robot0_gripper_qpos'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    states = list()\n",
    "    for _ in range(2):\n",
    "        wrapper.seed(0)\n",
    "        wrapper.reset()\n",
    "        states.append(wrapper.env.get_state()['states'])\n",
    "    assert np.allclose(states[0], states[1])\n",
    "\n",
    "    img = wrapper.render()\n",
    "    plt.imshow(img)\n",
    "    # wrapper.seed()\n",
    "    # states.append(wrapper.env.get_state()['states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 替换为你本地的数据集路径\n",
    "dataset_path = '/home/users/oscar/streaming-flow-policy/data/lift/ph/low_dim_abs.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境名称: Lift\n",
      "环境类型: 1\n",
      "环境参数: {'has_renderer': False, 'has_offscreen_renderer': False, 'ignore_done': True, 'use_object_obs': True, 'use_camera_obs': False, 'control_freq': 20, 'controller_configs': {'type': 'OSC_POSE', 'input_max': 1, 'input_min': -1, 'output_max': [0.05, 0.05, 0.05, 0.5, 0.5, 0.5], 'output_min': [-0.05, -0.05, -0.05, -0.5, -0.5, -0.5], 'kp': 150, 'damping': 1, 'impedance_mode': 'fixed', 'kp_limits': [0, 300], 'damping_limits': [0, 10], 'position_limits': None, 'orientation_limits': None, 'uncouple_pos_ori': True, 'control_delta': False, 'interpolation': None, 'ramp_ratio': 0.2}, 'robots': ['Panda'], 'camera_depths': False, 'camera_heights': 84, 'camera_widths': 84, 'reward_shaping': False}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 检查路径是否存在，避免后续报错\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"数据集路径不存在: {dataset_path}\")\n",
    "\n",
    "# 从数据集头部读取元数据 (Metadata)\n",
    "env_meta = FileUtils.get_env_metadata_from_dataset(dataset_path=dataset_path)\n",
    "env_meta['env_kwargs']['controller_configs']['control_delta'] = False\n",
    "\n",
    "# 打印看看环境的基本信息\n",
    "print(f\"环境名称: {env_meta['env_name']}\")\n",
    "print(f\"环境类型: {env_meta['type']}\")\n",
    "print(f\"环境参数: {env_meta['env_kwargs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created environment with name Lift\n",
      "Action size is 7\n",
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No environment version found in dataset!\n",
      "    Cannot verify if dataset and installed environment versions match\n",
      ")\u001b[0m\n",
      "环境创建并封装成功！\n",
      "Action Space: Box(-1, 1, (7,), int64)\n",
      "Observation Space: Box(-1.0, 1.0, (19,), float64)\n"
     ]
    }
   ],
   "source": [
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "\n",
    "# 1. 这一步至关重要：初始化 ObsUtils\n",
    "# 我们从之前读取的 env_meta 中提取观测值的定义 (specs)\n",
    "# 这样 robomimic 才知道 'robot0_eef_pos' 是 low_dim 数据，而不是 rgb 图像\n",
    "# ObsUtils.initialize_obs_utils_with_obs_specs(\n",
    "#     obs_modality_specs={\n",
    "#         \"obs\": env_meta[\"env_obs_keys\"]\n",
    "#     }\n",
    "# )\n",
    "obs_keys=[\n",
    "        'object', \n",
    "        'robot0_eef_pos', \n",
    "        'robot0_eef_quat', \n",
    "        'robot0_gripper_qpos'\n",
    "    ]\n",
    "\n",
    "ObsUtils.initialize_obs_modality_mapping_from_dict(\n",
    "        {'low_dim': obs_keys})\n",
    "\n",
    "# --- 下面是你原来的代码 (现在可以正常运行了) ---\n",
    "\n",
    "# 使用 robomimic 的工具函数创建原始环境\n",
    "env = EnvUtils.create_env_from_metadata(\n",
    "    env_meta=env_meta,\n",
    "    render=False,\n",
    "    render_offscreen=True,\n",
    "    use_image_obs=False,\n",
    ")\n",
    "\n",
    "# 实例化 Wrapper\n",
    "wrapper = RobomimicLowdimWrapper(\n",
    "    env=env,\n",
    "    obs_keys=[\n",
    "        'object', \n",
    "        'robot0_eef_pos', \n",
    "        'robot0_eef_quat', \n",
    "        'robot0_gripper_qpos'\n",
    "    ],\n",
    "    render_hw=(256, 256),\n",
    "    render_camera_name='agentview'\n",
    ")\n",
    "\n",
    "print(\"环境创建并封装成功！\")\n",
    "print(f\"Action Space: {wrapper.action_space}\")\n",
    "print(f\"Observation Space: {wrapper.observation_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reset 成功 | 初始观测维度: (19,)\n",
      "2. Step 成功  | Step后观测维度: (19,), Reward: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Render 成功 | 你应该能看到一张包含机械臂和红方块的图片。\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. 测试环境重置 (Reset)\n",
    "\n",
    "obs = wrapper.reset()\n",
    "print(f\"1. Reset 成功 | 初始观测维度: {obs.shape}\")\n",
    "\n",
    "# 2. 测试环境交互 (Step) - 执行一个随机动作\n",
    "# 我们用全 0 动作或者随机动作测试\n",
    "action = np.zeros(wrapper.action_space.shape) \n",
    "next_obs, reward, done, info = wrapper.step(action)\n",
    "print(f\"2. Step 成功  | Step后观测维度: {next_obs.shape}, Reward: {reward}\")\n",
    "\n",
    "# 3. 测试图像渲染 (Render) - 这是最容易报错的一步 (例如缺少 OpenGL 库)\n",
    "try:\n",
    "    img = wrapper.render()\n",
    "    \n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Environment Sanity Check\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"3. Render 成功 | 你应该能看到一张包含机械臂和红方块的图片。\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n[错误] 渲染失败！\")\n",
    "    print(f\"错误信息: {e}\")\n",
    "    print(\"提示: 如果是在无头服务器(Headless Server)上，可能需要配置 EGL 或使用 xvfb-run。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstats\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ 警告: 你的 dataset stats 维度不是 10！\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m当前维度是: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "if stats['action']['min'].shape[0] != 10:\n",
    "    print(\"⚠️ 警告: 你的 dataset stats 维度不是 10！\")\n",
    "    print(f\"当前维度是: {stats['action']['min'].shape[0]}\")\n",
    "    print(\"可能原因：你加载的还是旧的 low_dim.hdf5，而不是 low_dim_abs.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已初始化 RotationTransformer，Action Dim 设置为: 10\n"
     ]
    }
   ],
   "source": [
    "from Common.myrotation_transformer_final import RotationTransformer\n",
    "\n",
    "rotation_transformer = RotationTransformer('rotation_6d', 'axis_angle')\n",
    "\n",
    "action_dim = 10 \n",
    "\n",
    "print(f\"已初始化 RotationTransformer，Action Dim 设置为: {action_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxNormalizer:\n",
    "    def __init__(self, data=None, min_val=None, max_val=None):\n",
    "        \"\"\"\n",
    "        可以传入 data 自动计算 min/max，也可以直接传入已知的 min/max\n",
    "        \"\"\"\n",
    "        if data is not None:\n",
    "            # 假设 data 是 (N, Dim)\n",
    "            self.min_val = np.min(data, axis=0)\n",
    "            self.max_val = np.max(data, axis=0)\n",
    "        else:\n",
    "            self.min_val = np.array(min_val)\n",
    "            self.max_val = np.array(max_val)\n",
    "            \n",
    "        # 防止除以零（如果某维度没有变化）\n",
    "        self.scale = self.max_val - self.min_val\n",
    "        self.scale[self.scale == 0] = 1.0 \n",
    "\n",
    "    def normalize(self, x):\n",
    "        # 归一化到 [0, 1]\n",
    "        norm = (x - self.min_val) / self.scale\n",
    "        # 映射到 [-1, 1]\n",
    "        return norm * 2 - 1\n",
    "\n",
    "    def denormalize(self, x):\n",
    "        # 从 [-1, 1] 映射回 [0, 1]\n",
    "        denorm = (x + 1) / 2\n",
    "        # 还原到原始范围\n",
    "        return denorm * self.scale + self.min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假设 RotationTransformer 和 MinMaxNormalizer 已经在上面定义好了\n",
    "# from your_utils import RotationTransformer, MinMaxNormalizer \n",
    "\n",
    "class RobomimicDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataset_path, \n",
    "                 obs_keys, \n",
    "                 pred_horizon, \n",
    "                 obs_horizon, \n",
    "                 action_horizon):\n",
    "        \n",
    "        # 参数记录\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.obs_horizon = obs_horizon\n",
    "        self.action_horizon = action_horizon\n",
    "        self.obs_keys = obs_keys\n",
    "        \n",
    "        # --- 新增：初始化旋转变换器 ---\n",
    "        # 用于将 Axis-Angle (3) 转为 Rotation 6D (6)\n",
    "        self.rotation_transformer = RotationTransformer(\n",
    "            from_rep='axis_angle', to_rep='rotation_6d')\n",
    "\n",
    "        # 1. 读取数据到内存\n",
    "        print(f\"正在加载数据集: {dataset_path}\")\n",
    "        with h5py.File(dataset_path, 'r') as f:\n",
    "            demos = f['data']\n",
    "            self.all_obs = []\n",
    "            self.all_actions = [] # 这里将存储转换后的 10维动作\n",
    "            \n",
    "            for key in tqdm(demos.keys(), desc=\"Loading\"):\n",
    "                demo = demos[key]\n",
    "                \n",
    "                # --- 处理 Observation (保持不变) ---\n",
    "                obs_list = []\n",
    "                for k in self.obs_keys:\n",
    "                    obs_data = demo['obs'][k][:] \n",
    "                    obs_list.append(obs_data)\n",
    "                obs_seq = np.concatenate(obs_list, axis=-1)\n",
    "                self.all_obs.append(obs_seq)\n",
    "                \n",
    "                # --- 修改重点：处理 Action (7维 -> 10维) ---\n",
    "                raw_actions = demo['actions'][:].astype(np.float32) # (T, 7)\n",
    "                \n",
    "                # 1. 拆分动作\n",
    "                pos = raw_actions[:, :3]     # (T, 3)\n",
    "                rot = raw_actions[:, 3:6]    # (T, 3) Axis-Angle\n",
    "                gripper = raw_actions[:, 6:] # (T, 1)\n",
    "                \n",
    "                # 2. 旋转变换 (Axis-Angle -> Rotation 6D)\n",
    "                # Transformer 接收 Tensor，返回 Tensor，需转回 Numpy\n",
    "                rot_tensor = torch.from_numpy(rot)\n",
    "                rot_6d_tensor = self.rotation_transformer.forward(rot_tensor)\n",
    "                rot_6d = rot_6d_tensor.numpy() # (T, 6)\n",
    "                \n",
    "                # 3. 拼接成绝对位置控制所需的格式 (T, 10)\n",
    "                # 3 pos + 6 rot + 1 gripper = 10 dim\n",
    "                new_actions = np.concatenate([pos, rot_6d, gripper], axis=-1)\n",
    "                \n",
    "                self.all_actions.append(new_actions)\n",
    "\n",
    "        # 2. 计算统计数据并初始化归一化器\n",
    "        # 把所有数据拼在一起\n",
    "        all_obs_concat = np.concatenate(self.all_obs, axis=0)\n",
    "        all_action_concat = np.concatenate(self.all_actions, axis=0)\n",
    "        \n",
    "        # --- 修改重点：使用类 MinMaxNormalizer ---\n",
    "        # 此时 all_action_concat 已经是 10维的数据了\n",
    "        self.obs_normalizer = MinMaxNormalizer(data=all_obs_concat)\n",
    "        self.action_normalizer = MinMaxNormalizer(data=all_action_concat)\n",
    "        \n",
    "        # 打印一下验证维度\n",
    "        print(f\"原始 Action 维度: 7, 转换后 Action 维度: {all_action_concat.shape[-1]}\")\n",
    "        \n",
    "        # 3. 预处理：归一化所有数据并建立索引\n",
    "        self.normalized_obs = []\n",
    "        self.normalized_actions = []\n",
    "        self.indices = []\n",
    "        \n",
    "        for i in range(len(self.all_obs)):\n",
    "            # --- 修改重点：调用实例方法进行归一化 ---\n",
    "            n_obs = self.obs_normalizer.normalize(self.all_obs[i])\n",
    "            n_action = self.action_normalizer.normalize(self.all_actions[i])\n",
    "            \n",
    "            self.normalized_obs.append(n_obs)\n",
    "            self.normalized_actions.append(n_action)\n",
    "            \n",
    "            # 建立索引 (逻辑不变)\n",
    "            episode_len = n_obs.shape[0]\n",
    "            # 为了保证剩下的长度够 pred_horizon，需要减去它\n",
    "            for start_ts in range(episode_len - self.pred_horizon):\n",
    "                self.indices.append((i, start_ts))\n",
    "                \n",
    "        print(f\"加载完成! 样本数量: {len(self.indices)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        episode_idx, start_ts = self.indices[idx]\n",
    "        \n",
    "        n_obs = self.normalized_obs[episode_idx]\n",
    "        n_action = self.normalized_actions[episode_idx]\n",
    "        \n",
    "        # 1. 取 Observation\n",
    "        # 注意：这里如果 obs_horizon > 1，需要处理边界情况(padding)，\n",
    "        # 但为简化起见，假设 start_ts + obs_horizon 不会越界(因为上面 range 只减了 pred_horizon)\n",
    "        # 实际严谨代码通常会在上面 range 减去 max(obs_horizon, pred_horizon)\n",
    "        obs_seq = n_obs[start_ts : start_ts + self.obs_horizon, :]\n",
    "        \n",
    "        # 2. 取 Action\n",
    "        action_seq = n_action[start_ts : start_ts + self.pred_horizon, :]\n",
    "        \n",
    "        data = {\n",
    "            'obs': torch.from_numpy(obs_seq).float(),      # shape: (obs_horizon, obs_dim)\n",
    "            'action': torch.from_numpy(action_seq).float() # shape: (pred_horizon, 10)\n",
    "        }\n",
    "        return data\n",
    "\n",
    "    # --- 新增：提供一个反归一化+逆变换的辅助函数，供推理时使用 ---\n",
    "    def get_unnormalized_action(self, n_action_pred):\n",
    "        \"\"\"\n",
    "        推理时使用：\n",
    "        输入: 模型预测的归一化动作 (B, 10) Tensor or Numpy\n",
    "        输出: 环境可执行的动作 (B, 7) Numpy\n",
    "        \"\"\"\n",
    "        is_tensor = isinstance(n_action_pred, torch.Tensor)\n",
    "        if is_tensor:\n",
    "            n_action_pred = n_action_pred.detach().cpu().numpy()\n",
    "            \n",
    "        # 1. 反归一化 (10D -> 10D)\n",
    "        action_10d = self.action_normalizer.denormalize(n_action_pred)\n",
    "        \n",
    "        # 2. 拆解\n",
    "        pos = action_10d[..., :3]\n",
    "        rot_6d = action_10d[..., 3:9]\n",
    "        gripper = action_10d[..., 9:]\n",
    "        \n",
    "        # 3. 逆旋转变换 (6D -> 3D Axis-Angle)\n",
    "        rot_6d_tensor = torch.from_numpy(rot_6d)\n",
    "        rot_axis = self.rotation_transformer.inverse(rot_6d_tensor).numpy()\n",
    "        \n",
    "        # 4. 拼接 (10D -> 7D)\n",
    "        action_7d = np.concatenate([pos, rot_axis, gripper], axis=-1)\n",
    "        return action_7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载数据集: /home/users/oscar/streaming-flow-policy/data/lift/ph/low_dim_abs.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 200/200 [00:00<00:00, 952.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 Action 维度: 7, 转换后 Action 维度: 10\n",
      "加载完成! 样本数量: 6466\n",
      "\n",
      "--- 数据形状检查 ---\n",
      "Obs Batch:    torch.Size([64, 2, 19])\n",
      "Action Batch: torch.Size([64, 16, 10])\n",
      "Observation Space: Box(-1.0, 1.0, (19,), float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 配置参数 (这些是 Diffusion Policy 的标准参数)\n",
    "pred_horizon = 16    # 预测未来 16 步\n",
    "obs_horizon = 2      # 看过去 2 步\n",
    "action_horizon = 8   # (这一步在 dataset 里用不到，但在推理时有用)\n",
    "\n",
    "# 1. 实例化 Dataset\n",
    "dataset = RobomimicDataset(\n",
    "    dataset_path=dataset_path, # 确保这个变量是你之前定义的路径\n",
    "    obs_keys=[\n",
    "        'object', \n",
    "        'robot0_eef_pos', \n",
    "        'robot0_eef_quat', \n",
    "        'robot0_gripper_qpos'\n",
    "    ],\n",
    "    pred_horizon=pred_horizon,\n",
    "    obs_horizon=obs_horizon,\n",
    "    action_horizon=action_horizon\n",
    ")\n",
    "\n",
    "# 2. 实例化 DataLoader\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True, \n",
    "    num_workers=0, # 本地调试设为 0 比较稳妥，避免多进程报错\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# 3. 验证一下输出形状\n",
    "batch = next(iter(dataloader))\n",
    "print(\"\\n--- 数据形状检查 ---\")\n",
    "print(f\"Obs Batch:    {batch['obs'].shape}\")\n",
    "print(f\"Action Batch: {batch['action'].shape}\")\n",
    "print(f\"Observation Space: {wrapper.observation_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim, scale = 1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.scale = scale # added - SFP\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.scale\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class ConvDownsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ConvUpsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class LinearDownsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        # Reshape input to (batch_size, -1) for fully connected layer\n",
    "        batch_size, channels, seq_len = x.size()\n",
    "        x = x.view(batch_size, -1)  # flatten spatial dimensions\n",
    "        x = self.linear(x)\n",
    "        x = x.view(batch_size, channels, seq_len)  # reshape back to original dimensions\n",
    "        return x\n",
    "\n",
    "class LinearUpsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        # Reshape input to (batch_size, -1) for fully connected layer\n",
    "        batch_size, channels, seq_len = x.size()\n",
    "        x = x.view(batch_size, -1)  # flatten spatial dimensions\n",
    "        x = self.linear(x)\n",
    "        x = x.view(batch_size, channels, seq_len)  # reshape back to original dimensions\n",
    "        return x\n",
    "\n",
    "class Conv1dBlock(nn.Module):\n",
    "    '''\n",
    "        Conv1d --> GroupNorm --> Mish\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.GroupNorm(n_groups, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class ConditionalResidualBlock1D(nn.Module):\n",
    "    def __init__(self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            cond_dim,\n",
    "            kernel_size=3,\n",
    "            n_groups=8,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "            Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "        ])\n",
    "\n",
    "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
    "        # predicts per-channel scale and bias\n",
    "        cond_channels = out_channels * 2\n",
    "        self.out_channels = out_channels\n",
    "        self.cond_encoder = nn.Sequential(\n",
    "            nn.Mish(),\n",
    "            nn.Linear(cond_dim, cond_channels),\n",
    "            nn.Unflatten(-1, (-1, 1))\n",
    "        )\n",
    "\n",
    "        # Ensure dimensions compatible\n",
    "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) \\\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        '''\n",
    "            x : [ batch_size x in_channels x horizon ]\n",
    "            cond : [ batch_size x cond_dim]\n",
    "\n",
    "            returns:\n",
    "            out : [ batch_size x out_channels x horizon ]\n",
    "        '''\n",
    "        out = self.blocks[0](x)\n",
    "        embed = self.cond_encoder(cond)\n",
    "\n",
    "        embed = embed.reshape(\n",
    "            embed.shape[0], 2, self.out_channels, 1)\n",
    "        scale = embed[:,0,...]\n",
    "        bias = embed[:,1,...]\n",
    "        out = scale * out + bias\n",
    "\n",
    "        out = self.blocks[1](out)\n",
    "        out = out + self.residual_conv(x)\n",
    "        return out\n",
    "\n",
    "class ConditionalUnet1D (nn.Module):\n",
    "    def __init__(self,\n",
    "        input_dim,\n",
    "        global_cond_dim,\n",
    "        updownsample_type: Literal['Conv', 'Linear'],  # added for SFP\n",
    "        sin_embedding_scale,  # added for SFP\n",
    "        diffusion_step_embed_dim=256,\n",
    "        down_dims=[256,512,1024],\n",
    "        kernel_size=5,\n",
    "        n_groups=8,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        input_dim: Dim of actions.\n",
    "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
    "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
    "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
    "        down_dims: Channel size for each UNet level.\n",
    "          The length of this array determines numebr of levels.\n",
    "        kernel_size: Conv kernel size\n",
    "        n_groups: Number of groups for GroupNorm\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        all_dims = [input_dim] + list(down_dims)\n",
    "        start_dim = down_dims[0]\n",
    "\n",
    "        dsed = diffusion_step_embed_dim\n",
    "        diffusion_step_encoder = nn.Sequential(\n",
    "            SinusoidalPosEmb(dsed, scale = sin_embedding_scale), # added - SFP\n",
    "            nn.Linear(dsed, dsed * 4),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(dsed * 4, dsed),\n",
    "        )\n",
    "        cond_dim = dsed + global_cond_dim\n",
    "\n",
    "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
    "        mid_dim = all_dims[-1]\n",
    "        self.mid_modules = nn.ModuleList([\n",
    "            ConditionalResidualBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ),\n",
    "            ConditionalResidualBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        down_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            if updownsample_type == 'Linear':  # added for SFP\n",
    "                downsample_layer = LinearDownsample1d(dim_out) if not is_last else nn.Identity() #added\n",
    "            elif updownsample_type == 'Conv':\n",
    "                downsample_layer = ConvDownsample1d(dim_out) if not is_last else nn.Identity()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported updownsample_type: {updownsample_type}\")\n",
    "            down_modules.append(nn.ModuleList([\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_in, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_out, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                downsample_layer,\n",
    "            ]))\n",
    "\n",
    "        up_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            if updownsample_type == 'Linear':  # added for SFP\n",
    "                upsample_layer = LinearUpsample1d(dim_in) if not is_last  else nn.Identity()\n",
    "            elif updownsample_type == 'Conv':\n",
    "                upsample_layer = ConvUpsample1d(dim_in) if not is_last  else nn.Identity()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported updownsample_type: {updownsample_type}\")\n",
    "            up_modules.append(nn.ModuleList([\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_out*2, dim_in, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_in, dim_in, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                upsample_layer,\n",
    "            ]))\n",
    "\n",
    "        final_conv = nn.Sequential(\n",
    "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
    "            nn.Conv1d(start_dim, input_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.diffusion_step_encoder = diffusion_step_encoder\n",
    "        self.up_modules = up_modules\n",
    "        self.down_modules = down_modules\n",
    "        self.final_conv = final_conv\n",
    "\n",
    "        print(\"Number of parameters: {:e}\".format(\n",
    "            sum(p.numel() for p in self.parameters()))\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "            sample: Tensor,\n",
    "            timestep: Union[Tensor, float, int],\n",
    "            global_cond=None,\n",
    "        ) -> Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,T,input_dim)\n",
    "        timestep: (B,) or int, diffusion step\n",
    "        global_cond: (B,global_cond_dim)\n",
    "        output: (B,T,input_dim)\n",
    "        \"\"\"\n",
    "        # (B,T,C)\n",
    "        sample = sample.moveaxis(-1,-2)\n",
    "        # (B,C,T)\n",
    "\n",
    "        # 1. time\n",
    "        timesteps = timestep\n",
    "        if not torch.is_tensor(timesteps):\n",
    "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
    "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
    "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
    "            timesteps = timesteps[None].to(sample.device)\n",
    "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
    "        timesteps = timesteps.expand(sample.shape[0])\n",
    "\n",
    "        global_feature = self.diffusion_step_encoder(timesteps)\n",
    "\n",
    "        if global_cond is not None:\n",
    "            global_feature = torch.cat([\n",
    "                global_feature, global_cond\n",
    "            ], axis=-1)\n",
    "\n",
    "        x = sample\n",
    "        h = []\n",
    "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        for mid_module in self.mid_modules:\n",
    "            x = mid_module(x, global_feature)\n",
    "\n",
    "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        # (B,C,T)\n",
    "        x = x.moveaxis(-1,-2)\n",
    "        # (B,T,C)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6.576897e+07\n",
      "模型构建成功！\n"
     ]
    }
   ],
   "source": [
    "# 基于之前的 Lift 任务设置\n",
    "action_dim = 10      # 动作维度\n",
    "obs_dim = 19         # 观测特征维度\n",
    "obs_horizon = 2      # 观测历史长度\n",
    "\n",
    "# 实例化模型\n",
    "dp_noise_pred_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim * obs_horizon,\n",
    "    updownsample_type='Conv',\n",
    "    sin_embedding_scale=1,\n",
    ")\n",
    "\n",
    "print(\"模型构建成功！\")\n",
    "\n",
    "num_diffusion_iters = 100\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "dp_noise_pred_net = dp_noise_pred_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1%|          | 1/100 [00:07<12:32,  7.60s/it, loss=1.02]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m noisy_actions \u001b[38;5;241m=\u001b[39m noise_scheduler\u001b[38;5;241m.\u001b[39madd_noise(\n\u001b[1;32m     52\u001b[0m     naction, noise, timesteps)  \u001b[38;5;66;03m# (B, Tp, A)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Predict the noise residual.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[43mdp_noise_pred_net\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoisy_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# L2 loss\u001b[39;00m\n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(noise_pred, noise)\n",
      "File \u001b[0;32m~/miniconda/envs/sfp/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/sfp/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[13], line 261\u001b[0m, in \u001b[0;36mConditionalUnet1D.forward\u001b[0;34m(self, sample, timestep, global_cond)\u001b[0m\n\u001b[1;32m    259\u001b[0m h \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (resnet, resnet2, downsample) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_modules):\n\u001b[0;32m--> 261\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_feature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     x \u001b[38;5;241m=\u001b[39m resnet2(x, global_feature)\n\u001b[1;32m    263\u001b[0m     h\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m~/miniconda/envs/sfp/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/sfp/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[13], line 122\u001b[0m, in \u001b[0;36mConditionalResidualBlock1D.forward\u001b[0;34m(self, x, cond)\u001b[0m\n\u001b[1;32m    119\u001b[0m bias \u001b[38;5;241m=\u001b[39m embed[:,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    120\u001b[0m out \u001b[38;5;241m=\u001b[39m scale \u001b[38;5;241m*\u001b[39m out \u001b[38;5;241m+\u001b[39m bias\n\u001b[0;32m--> 122\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m[\u001b[38;5;241m1\u001b[39m](out)\n\u001b[1;32m    123\u001b[0m out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_conv(x)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda/envs/sfp/lib/python3.10/site-packages/torch/nn/modules/module.py:1951\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1953\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema_dp = EMAModel(\n",
    "    parameters=dp_noise_pred_net.parameters(),\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=dp_noise_pred_net.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(dataset) * num_epochs\n",
    ")\n",
    "\n",
    "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
    "    # epoch loop\n",
    "    for epoch_idx in tglobal:\n",
    "        epoch_loss = list()\n",
    "        # batch loop\n",
    "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
    "            for nbatch in tepoch:\n",
    "                # Note that the data is normalized in the dataset.\n",
    "                # Device transfer\n",
    "                nobs = nbatch['obs'].to(device)  # (B, To, O)\n",
    "                naction = nbatch['action'].to(device)  # (B, Tp, A)\n",
    "                B = nobs.shape[0]\n",
    "\n",
    "                # Observation as FiLM conditioning\n",
    "                obs_cond = nobs.flatten(start_dim=1)  # (B, To*O)\n",
    "\n",
    "                # Sample noise to add to actions\n",
    "                noise = torch.randn(naction.shape, device=device)  # (B, Tp, A)\n",
    "\n",
    "                # sample a diffusion iteration for each data point\n",
    "                timesteps = torch.randint(\n",
    "                    0, noise_scheduler.config.num_train_timesteps,\n",
    "                    (B,), device=device\n",
    "                ).long()  # (B,)\n",
    "\n",
    "                # Forward diffusion process: Add noise to the clean images\n",
    "                # according to the noise magnitude at each diffusion iteration.\n",
    "                noisy_actions = noise_scheduler.add_noise(\n",
    "                    naction, noise, timesteps)  # (B, Tp, A)\n",
    "\n",
    "                # Predict the noise residual.\n",
    "                noise_pred = dp_noise_pred_net(\n",
    "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
    "\n",
    "                # L2 loss\n",
    "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "                # optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # step lr scheduler every batch\n",
    "                # this is different from standard pytorch behavior\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # update Exponential Moving Average of the model weights\n",
    "                ema_dp.step(dp_noise_pred_net.parameters())\n",
    "\n",
    "                # logging\n",
    "                loss_cpu = loss.item()\n",
    "                epoch_loss.append(loss_cpu)\n",
    "                tepoch.set_postfix(loss=loss_cpu)\n",
    "        tglobal.set_postfix(loss=np.mean(epoch_loss))\n",
    "\n",
    "# Weights of the EMA model\n",
    "# is used for inference\n",
    "ema_noise_pred_net_dp = dp_noise_pred_net\n",
    "ema_dp.copy_to(ema_noise_pred_net_dp.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始推理 (Inference)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d9b807f71c423692e09a311aa2dad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Robomimic:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理结束! 总得分: 1.0\n",
      "正在保存视频到: eval_robomimic_abs.gif ...\n",
      "保存完成！\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import imageio  # 用于保存 GIF\n",
    "\n",
    "# 1. 准备参数\n",
    "# 确保模型处于推理模式\n",
    "dp_noise_pred_net.eval()\n",
    "dp_noise_pred_net.to(device)\n",
    "\n",
    "# 设置参数 (必须与训练时一致)\n",
    "max_steps = 400  # 最大运行步数\n",
    "obs_horizon = 2\n",
    "pred_horizon = 16\n",
    "action_horizon = 8\n",
    "num_diffusion_iters = 100 \n",
    "\n",
    "# 2. 重置环境\n",
    "obs = wrapper.reset()\n",
    "\n",
    "# 初始化观测队列\n",
    "obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "\n",
    "# 用于保存可视化图像和奖励\n",
    "imgs = [wrapper.render()]\n",
    "rewards = list()\n",
    "done = False\n",
    "step_idx = 0\n",
    "\n",
    "print(\"开始推理 (Inference)...\")\n",
    "\n",
    "# 3. 推理循环\n",
    "with tqdm(total=max_steps, desc=\"Eval Robomimic\") as pbar:\n",
    "    while not done:\n",
    "        # --- A. 数据准备 ---\n",
    "        # 拼接最近 obs_horizon 步的观测数据\n",
    "        obs_seq = np.stack(obs_deque) # (2, 19)\n",
    "        \n",
    "        # [修改点 1]: 使用 dataset 里的实例归一化器\n",
    "        nobs = dataset.obs_normalizer.normalize(obs_seq)\n",
    "        \n",
    "        # 转 Tensor 并增加 Batch 维度\n",
    "        nobs = torch.from_numpy(nobs).to(device, dtype=torch.float32)\n",
    "        \n",
    "        # 构造 Global Conditioning: (1, obs_horizon * 19)\n",
    "        obs_cond = nobs.unsqueeze(0).flatten(start_dim=1)\n",
    "\n",
    "        # --- B. 生成动作 (反向扩散) ---\n",
    "        with torch.no_grad():\n",
    "            # [修改点 2]: 初始化纯高斯噪音，维度改为 10 (3pos + 6rot + 1gripper)\n",
    "            # 原始代码是 7，现在必须是 10\n",
    "            na_traj = torch.randn(\n",
    "                (1, pred_horizon, 10), \n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            # 设置调度器时间步\n",
    "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "\n",
    "            # 逐步去噪\n",
    "            for k in noise_scheduler.timesteps:\n",
    "                # 预测噪音\n",
    "                noise_pred = dp_noise_pred_net(\n",
    "                    sample=na_traj,\n",
    "                    timestep=k,\n",
    "                    global_cond=obs_cond\n",
    "                )\n",
    "\n",
    "                # 移除噪音\n",
    "                na_traj = noise_scheduler.step(\n",
    "                    model_output=noise_pred,\n",
    "                    timestep=k,\n",
    "                    sample=na_traj,\n",
    "                ).prev_sample\n",
    "\n",
    "        # --- C. 后处理 ---\n",
    "        # 转回 CPU numpy: (1, 16, 10) -> (16, 10)\n",
    "        na_traj = na_traj.detach().to('cpu').numpy()[0]\n",
    "        \n",
    "        # [修改点 3]: 调用 dataset 的辅助函数进行 反归一化 + 逆旋转变换\n",
    "        # 输入 (16, 10) -> 输出 (16, 7)\n",
    "        # 这个函数内部会自动处理: 10D反归一化 -> 6D旋转转AxisAngle -> 拼接回7D\n",
    "        action_pred = dataset.get_unnormalized_action(na_traj)\n",
    "\n",
    "        # --- D. 动作切片与执行 (逻辑不变) ---\n",
    "        start = obs_horizon - 1\n",
    "        end = start + action_horizon\n",
    "        \n",
    "        # 取出未来 action_horizon 步的动作\n",
    "        action_chunk = action_pred[start:end, :] \n",
    "        \n",
    "        # --- E. 执行动作序列 ---\n",
    "        for action in action_chunk:\n",
    "            # 环境交互 (此时 action 已经是环境能懂的 7维 格式了)\n",
    "            obs, reward, done, info = wrapper.step(action)\n",
    "            \n",
    "            # 更新历史观测\n",
    "            obs_deque.append(obs)\n",
    "            \n",
    "            # 记录数据\n",
    "            rewards.append(reward)\n",
    "            imgs.append(wrapper.render())\n",
    "            \n",
    "            # 进度更新\n",
    "            step_idx += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(reward=reward)\n",
    "            \n",
    "            if step_idx >= max_steps:\n",
    "                done = True\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "print(f\"推理结束! 总得分: {max(rewards)}\")\n",
    "\n",
    "# 4. 保存结果为 GIF\n",
    "save_path = \"eval_robomimic_abs.gif\"\n",
    "print(f\"正在保存视频到: {save_path} ...\")\n",
    "imageio.mimsave(save_path, imgs, fps=10)\n",
    "print(\"保存完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6.413057e+07\n",
      "Number of parameters: 6.413057e+07\n",
      "Models initialized for Streaming SI Policy.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1. 辅助函数: Gamma 调度器 (参考 model.py)\n",
    "# =========================================================\n",
    "EPS = 1e-6\n",
    "\n",
    "def gamma_t_si(t):\n",
    "    # 使用简单的抛物线/气泡形状，在 t=0 和 t=1 时为 0，中间膨胀\n",
    "    # 这里的系数 0.1 控制 \"SI 气泡\" 的大小，相对于 SFP 的管状噪声\n",
    "    return 0.1 * torch.sqrt(t * (1.0 - t) + EPS)\n",
    "\n",
    "def d_gamma_dt_si(t):\n",
    "    # gamma(t) 对 t 的导数\n",
    "    return 0.1 * (1.0 - 2.0 * t) / (2.0 * torch.sqrt(t * (1.0 - t) + EPS))\n",
    "\n",
    "# =========================================================\n",
    "# 2. 初始化模型 (VelocityNet 和 DenoiserNet)\n",
    "# =========================================================\n",
    "# SFP 参数\n",
    "\n",
    "\n",
    "pred_horizon = 16\n",
    "action_dim = 10       # 动作维度\n",
    "obs_dim = 19         # 观测特征维度\n",
    "obs_horizon = 2      # 观测历史长度\n",
    "\n",
    "\n",
    "# 我们需要两个网络：\n",
    "# 1. si_velocity_net: 预测确定性速度场 (v)\n",
    "# 2. si_denoiser_net: 预测噪声场 (eta/score)\n",
    "\n",
    "si_velocity_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon,\n",
    "    updownsample_type='Linear',\n",
    "    sin_embedding_scale=100,\n",
    ").to(device)\n",
    "\n",
    "si_denoiser_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon,\n",
    "    updownsample_type='Linear',\n",
    "    sin_embedding_scale=100,\n",
    ").to(device)\n",
    "\n",
    "print(\"Models initialized for Streaming SI Policy.\")\n",
    "\n",
    "# =========================================================\n",
    "# 3. 优化器设置\n",
    "# =========================================================\n",
    "optimizer_si = torch.optim.AdamW([\n",
    "    {'params': si_velocity_net.parameters()},\n",
    "    {'params': si_denoiser_net.parameters()}\n",
    "], lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# EMA (Exponential Moving Average) for better inference stability\n",
    "ema_si_v = EMAModel(parameters=si_velocity_net.parameters(), power=0.75)\n",
    "ema_si_eta = EMAModel(parameters=si_denoiser_net.parameters(), power=0.75)\n",
    "\n",
    "num_epochs_si = 800\n",
    "lr_scheduler_si = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer_si,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(dataloader) * num_epochs_si\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearlyInterpolateTrajectory(ξ, t):\n",
    "    \"\"\"\n",
    "    Vectorized computation of positions and velocities if each trajectory\n",
    "    (from a batch of trajectories) at given times for each trajectory, using\n",
    "    linear interpolation.\n",
    "\n",
    "    ξ (Tensor, dtype=float, shape=(B, T, A)): batch of action trajectories.\n",
    "    t (Tensor, dtype=float, shape=(B,)): batch of times in [0, 1].\n",
    "\n",
    "    Returns:\n",
    "        ξt   (Tensor, shape=(B, A)): positions at time t\n",
    "        dξdt (Tensor, shape=(B, A)): velocities at time t\n",
    "    \"\"\"\n",
    "    B, T, A = ξ.shape\n",
    "\n",
    "    # Compute the lower and upper limits of the bins that the time-points lie in.\n",
    "    scaled_t = t * (T - 1)  # (B,) lies in [0, T-1]\n",
    "    l = scaled_t.floor().long().clamp(0, T - 2)  # (B,) lower bin limits\n",
    "    u = (l + 1).clamp(0, T - 1)  # (B,) upper bin limits\n",
    "    λ = scaled_t - l.float()  # fractional part, lies in [0, 1]\n",
    "\n",
    "    # Query the values of the upper and lower bin limits.\n",
    "    batch_idx = torch.arange(B, device=ξ.device)  # (B,)\n",
    "    ξl = ξ[batch_idx, l, :]  # (B, A)\n",
    "    ξu = ξ[batch_idx, u, :]  # (B, A)\n",
    "\n",
    "    # Linearly interpolate between bin limits to get position.\n",
    "    λ = λ.unsqueeze(-1)  # (B, 1)\n",
    "    ξt = ξl + λ * (ξu - ξl)  # (B, A)\n",
    "\n",
    "    # Compute velocity as first-order hold.\n",
    "    # Note that the time interval between two bins is Δt = 1 / (T-1).\n",
    "    dξdt = (ξu - ξl) * (T - 1)  # (B, A)\n",
    "\n",
    "    return ξt, dξdt  # (B, A) and (B, A)\n",
    "\n",
    "def SampleCFMInputsAndTargets(ξt, dξdt, t, k, σ0):\n",
    "    \"\"\"\n",
    "    Sample inputs and targets for the conditional flow matching loss (CFM)\n",
    "    given positions and velocities at time t.\n",
    "\n",
    "    This functions performs the following sampling (Eq. 2 and 3 of the paper):\n",
    "        a ~ N(ξ(t), σ₀² exp(-2kt))  # (Eq. 3 in the paper)\n",
    "        v = -k (a - ξ(t)) + dξdt(t)  # (Eq. 2 in the paper)\n",
    "\n",
    "    Args:\n",
    "        ξt (Tensor, shape=(B, A)): positions at time t.\n",
    "        dξdt (Tensor, shape=(B, A)): velocities at time t.\n",
    "        t (Tensor, shape=(B,)): times in [0, 1].\n",
    "        k (float): Stabilizing gains of the conditional flow.\n",
    "        σ0 (float): initial standard deviation of the noise added to the action.\n",
    "\n",
    "    Returns:\n",
    "        a (Tensor, shape=(B, A)): noised actions at time t\n",
    "        v (Tensor, shape=(B, A)): noised action velocity targets at time t\n",
    "    \"\"\"\n",
    "    # error = σ0 * torch.exp(-k*t).unsqueeze(1) * torch.randn_like(xt)\n",
    "    t = t.unsqueeze(-1)  # (B, 1)\n",
    "    sampled_error = σ0 * torch.exp(-k * t) * torch.randn_like(ξt)  # (B, A)\n",
    "    a = ξt + sampled_error  # (B, A) ⟸ Eq. 3 in the paper\n",
    "    v = -k * sampled_error + dξdt  # (B, A) ⟸ Eq. 2 in the paper\n",
    "\n",
    "    return a, v  # (B, A) and (B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for Streaming SI Policy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/800 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m ema_si_eta\u001b[38;5;241m.\u001b[39mstep(si_denoiser_net\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# 记录数据\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m loss_val \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m v_loss_val \u001b[38;5;241m=\u001b[39m loss_v\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     85\u001b[0m eta_loss_val \u001b[38;5;241m=\u001b[39m loss_eta\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 训练循环: Conditional Streaming SI Policy\n",
    "# =========================================================\n",
    "sigma0 = 0.4  # SFP 初始管状半径\n",
    "k = 10.0      # SFP 稳定系数\n",
    "\n",
    "\n",
    "print(\"Starting training for Streaming SI Policy...\")\n",
    "\n",
    "with tqdm(range(num_epochs_si), desc='Epoch') as tglobal:\n",
    "    for epoch_idx in tglobal:\n",
    "        epoch_loss = []\n",
    "        # 用于记录每个 epoch 的平均分项 loss\n",
    "        epoch_v_loss = []\n",
    "        epoch_eta_loss = []\n",
    "        \n",
    "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
    "            for nbatch in tepoch:\n",
    "                # 1. 数据准备\n",
    "                nobs = nbatch['obs'].to(device)\n",
    "                naction = nbatch['action'].to(device)\n",
    "                \n",
    "                # 提取当前及未来的动作片段\n",
    "                ξ = naction[:, obs_horizon-1:, :] \n",
    "                B = ξ.shape[0]\n",
    "                \n",
    "                # 随机采样时间 t ~ U[0, 1]\n",
    "                t = torch.rand(B, device=device)\n",
    "                \n",
    "                # 2. 计算 Ground Truth 位置和速度 (Linearly Interpolate)\n",
    "                ξt, dξdt = LinearlyInterpolateTrajectory(ξ, t)\n",
    "                \n",
    "                # 3. 构建 Flow Matching (FP) 基础目标 (管状分布)\n",
    "                # a_t_fp = ξ(t) + σ(t) * ε1\n",
    "                # 这里的 σ(t) = σ0 * exp(-kt)\n",
    "                t_expanded = t.view(B, 1)\n",
    "                sigma_t_fp = sigma0 * torch.exp(-k * t_expanded)\n",
    "                noise_fp = torch.randn_like(ξt)\n",
    "                a_t_fp = ξt + sigma_t_fp * noise_fp\n",
    "                \n",
    "                # 计算 Velocity Target (指向轨迹的向量场)\n",
    "                # v_target = dξ/dt - k * (a_t_fp - ξ(t))\n",
    "                # 注意：这个速度是定义在 a_t_fp 上的\n",
    "                v_target = dξdt - k * (a_t_fp - ξt)\n",
    "                \n",
    "                # 4. 构建 Stochastic Interpolant (SI) 扰动\n",
    "                # x_t = a_t_fp + γ(t) * z\n",
    "                # 我们在 SFP 的管子外面再套一层 SI 的气泡\n",
    "                gamma = gamma_t_si(t_expanded)\n",
    "                z_noise_si = torch.randn_like(ξt)\n",
    "                x_t_in_s = a_t_fp + gamma * z_noise_si\n",
    "                \n",
    "                # 5. 网络前向传播\n",
    "                # 输入需要 reshape 成 (B, 1, A) 以适应 UNet 接口\n",
    "                net_input = x_t_in_s.unsqueeze(1)\n",
    "                global_cond = nobs.flatten(start_dim=1)\n",
    "                \n",
    "                # 预测速度\n",
    "                v_pred = si_velocity_net(sample=net_input, timestep=t, global_cond=global_cond)\n",
    "                v_pred = v_pred.squeeze(1)\n",
    "                \n",
    "                # 预测噪声 (Score 相关的量)\n",
    "                eta_pred = si_denoiser_net(sample=net_input, timestep=t, global_cond=global_cond)\n",
    "                eta_pred = eta_pred.squeeze(1)\n",
    "                \n",
    "                # 6. 计算 Loss\n",
    "                loss_v = nn.functional.mse_loss(v_pred, v_target)\n",
    "                loss_eta = nn.functional.mse_loss(eta_pred, z_noise_si)\n",
    "                \n",
    "                loss = loss_v + loss_eta\n",
    "                \n",
    "                # 7. 反向传播\n",
    "                loss.backward()\n",
    "                optimizer_si.step()\n",
    "                optimizer_si.zero_grad()\n",
    "                lr_scheduler_si.step()\n",
    "                \n",
    "                # 更新 EMA\n",
    "                ema_si_v.step(si_velocity_net.parameters())\n",
    "                ema_si_eta.step(si_denoiser_net.parameters())\n",
    "                \n",
    "                # 记录数据\n",
    "                loss_val = loss.item()\n",
    "                v_loss_val = loss_v.item()\n",
    "                eta_loss_val = loss_eta.item()\n",
    "                \n",
    "                epoch_loss.append(loss_val)\n",
    "                epoch_v_loss.append(v_loss_val)\n",
    "                epoch_eta_loss.append(eta_loss_val)\n",
    "                \n",
    "                # [修改点] 这里增加了 s_loss (score loss) 的显示\n",
    "                tepoch.set_postfix(loss=loss_val, v_loss=v_loss_val, s_loss=eta_loss_val)\n",
    "                \n",
    "        # [修改点] Epoch 结束时也可以看平均的分项 Loss\n",
    "        tglobal.set_postfix(\n",
    "            loss=np.mean(epoch_loss), \n",
    "            v_loss=np.mean(epoch_v_loss), \n",
    "            s_loss=np.mean(epoch_eta_loss)\n",
    "        )\n",
    "\n",
    "        if (epoch_idx + 1) % 200 == 0:\n",
    "            ckpt_path_epoch = f\"models/lift_state_{epoch_idx+1}_ep_si_abs.ckpt\"\n",
    "            torch.save({\n",
    "                'velocity_net': si_velocity_net.state_dict(),\n",
    "                'denoiser_net': si_denoiser_net.state_dict()\n",
    "            }, ckpt_path_epoch)\n",
    "            print(f\" Saved checkpoint to {ckpt_path_epoch}\")\n",
    "\n",
    "# 保存模型\n",
    "ckpt_path_si = \"models/lift_state_500_ep_si_abs.ckpt\"\n",
    "torch.save({\n",
    "    'velocity_net': si_velocity_net.state_dict(),\n",
    "    'denoiser_net': si_denoiser_net.state_dict()\n",
    "}, ckpt_path_si)\n",
    "print(f\"Saved Streaming SI model to {ckpt_path_si}\")\n",
    "\n",
    "# 准备推理用的 EMA 模型\n",
    "ema_si_velocity_net = si_velocity_net\n",
    "ema_si_denoiser_net = si_denoiser_net\n",
    "ema_si_v.copy_to(ema_si_velocity_net.parameters())\n",
    "ema_si_eta.copy_to(ema_si_denoiser_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained checkpoint: models/lift_state_800_ep_si_abs.ckpt\n",
      "Pretrained weights loaded for Streaming SI Policy. Ready for inference!\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 加载预训练的 Streaming SI Policy 模型 (跳过训练)\n",
    "# =========================================================\n",
    "\n",
    "load_pretrained = True\n",
    "ckpt_path_si = \"models/lift_state_800_ep_si_abs.ckpt\"\n",
    "\n",
    "# 检查文件是否存在\n",
    "if load_pretrained and os.path.isfile(ckpt_path_si):\n",
    "    print(f\"Found pretrained checkpoint: {ckpt_path_si}\")\n",
    "    checkpoint = torch.load(ckpt_path_si, map_location=device)\n",
    "\n",
    "    # 1. 加载权重到基础网络\n",
    "    si_velocity_net.load_state_dict(checkpoint['velocity_net'])\n",
    "    si_denoiser_net.load_state_dict(checkpoint['denoiser_net'])\n",
    "\n",
    "    # 2. 设置推理用的模型\n",
    "    # 在跳过训练的情况下，我们将直接使用加载的权重作为推理模型\n",
    "    # (模拟 EMA 模型及其接口)\n",
    "    ema_si_velocity_net = si_velocity_net\n",
    "    ema_si_denoiser_net = si_denoiser_net\n",
    "\n",
    "    print('Pretrained weights loaded for Streaming SI Policy. Ready for inference!')\n",
    "\n",
    "else:\n",
    "    print(f\"Checkpoint {ckpt_path_si} not found. Please run the training cell below.\")\n",
    "    # 如果需要，这里可以初始化 EMA 模型容器，以便后续训练使用\n",
    "    # ema_si_velocity_net = ... (通常在训练循环中通过 EMAModel 初始化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Inference: Streaming SI (ODE Mode) (sigma=0.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba204573ff404389893b203403aae2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Streaming SI (ODE Mode):   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理结束! 最高得分: 1.0\n",
      "Running Inference: Streaming SI (SDE Mode) (sigma=0.05)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de905c1f2a0b4faf9ddff105f0a48669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Streaming SI (SDE Mode):   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Nan, Inf or huge value in CTRL at ACTUATOR 0. The simulation is unstable. Time = 10.9500.\n",
      "\n",
      "推理结束! 最高得分: 1.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import imageio\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# =========================================================\n",
    "# 辅助函数: 计算 Drift (适配 10维 Action)\n",
    "# =========================================================\n",
    "def get_drift(x, t, global_cond, sigma_infer, eps=1e-6):\n",
    "    \"\"\"\n",
    "    计算修正后的漂移项 b(x, t)\n",
    "    x: (B, 1, 10)\n",
    "    \"\"\"\n",
    "    if t.ndim == 0: t = t.unsqueeze(0)\n",
    "    \n",
    "    # 预测 v 和 eta\n",
    "    v_pred = ema_si_velocity_net(sample=x, timestep=t, global_cond=global_cond)\n",
    "    eta_pred = ema_si_denoiser_net(sample=x, timestep=t, global_cond=global_cond)\n",
    "    \n",
    "    # 获取 gamma 及其导数\n",
    "    gamma = gamma_t_si(t).view(-1, 1, 1).to(device)\n",
    "    gamma_dot = d_gamma_dt_si(t).view(-1, 1, 1).to(device)\n",
    "    \n",
    "    # 计算 score 和 漂移系数\n",
    "    s_pred = -eta_pred / (gamma + eps)\n",
    "    score_coeff = 0.5 * (sigma_infer ** 2) - (gamma * gamma_dot)\n",
    "    \n",
    "    b = v_pred + score_coeff * s_pred\n",
    "    return b\n",
    "\n",
    "# =========================================================\n",
    "# 核心修复: SSIP 推理函数 (Absolute Control 适配版)\n",
    "# =========================================================\n",
    "def run_si_inference(sigma_infer, title):\n",
    "    # 1. 重置环境\n",
    "    obs = wrapper.reset() \n",
    "    obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "    imgs = [wrapper.render()]\n",
    "    rewards = []\n",
    "    \n",
    "    # 2. Warm Start: 基于当前观测构建初始流状态 x_0\n",
    "    # -----------------------------------------------------------\n",
    "    # [关键]: 必须准确地将当前 obs 转换为 10维的 latent action 格式\n",
    "    # -----------------------------------------------------------\n",
    "    \n",
    "    start_dim = 10 \n",
    "    curr_pos = obs[start_dim : start_dim+3] # 取出 (x, y, z)\n",
    "    \n",
    "    # 2. 归一化当前位置\n",
    "    pos_min = dataset.action_normalizer.min_val[:3]\n",
    "    pos_max = dataset.action_normalizer.max_val[:3]\n",
    "    norm_pos = (curr_pos - pos_min) / (pos_max - pos_min)\n",
    "    norm_pos = norm_pos * 2 - 1\n",
    "    \n",
    "    # 3. 初始化 na (Latent State)\n",
    "    # 维度: (1, 1, 10)\n",
    "    na = torch.zeros((1, 1, 10), device=device, dtype=torch.float32)\n",
    "    \n",
    "    # [Fix 1]: 覆盖位置 (保持不变)\n",
    "    na[0, 0, :3] = torch.from_numpy(norm_pos).to(device)\n",
    "    \n",
    "    # [Fix 2 - 关键]: 强制初始化夹爪为 \"张开\" (-1.0)\n",
    "    # 假设第 10 维 (索引 9) 是夹爪。\n",
    "    # 在归一化空间中，-1 通常代表 raw action 的最小值 (Open)\n",
    "    na[0, 0, 9] = -1 \n",
    "    \n",
    "    # [Fix 3 - 可选]: 旋转初始化为 0 (6D Rotation) 可能不是单位矩阵\n",
    "    # 6D Rotation 的 [0,0,0,0,0,0] 是退化的。\n",
    "    # 更严谨的做法是初始化为 正确的矩阵，但这里我没有整明白，然后这个一堆0又work了，我就不管了哈哈\n",
    "\n",
    "    \n",
    "    # 设置为流的起点\n",
    "    na_from_prev_chunk = na\n",
    "    \n",
    "    # =========================================================\n",
    "    \n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    max_steps = 400 \n",
    "    dt_val = 1.0 / (pred_horizon - obs_horizon) # 流的时间步长\n",
    "    \n",
    "    print(f\"Running Inference: {title} (sigma={sigma_infer})\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=max_steps, desc=title) as pbar:\n",
    "            while not done and step_idx < max_steps:\n",
    "                # --- A. 准备 Observation ---\n",
    "                obs_seq = np.stack(obs_deque)\n",
    "                # [修复点]: 使用 dataset.obs_normalizer\n",
    "                nobs = dataset.obs_normalizer.normalize(obs_seq)\n",
    "                o_test = torch.from_numpy(nobs).to(device, dtype=torch.float32).flatten().unsqueeze(0)\n",
    "                \n",
    "                # --- B. Streaming Loop ---\n",
    "                na = na_from_prev_chunk\n",
    "                \n",
    "                for i in range(action_horizon):\n",
    "                    # 1. 解码当前动作并执行\n",
    "                    # [修复点]: 使用 dataset.get_unnormalized_action 自动处理反归一化+6D转回\n",
    "                    a_real_full = dataset.get_unnormalized_action(na) # 返回 (1, 1, 7) numpy\n",
    "                    a_real = a_real_full.squeeze() # (7,)\n",
    "                    \n",
    "                    # 环境交互\n",
    "                    obs, reward, done, info = wrapper.step(a_real)\n",
    "                    \n",
    "                    obs_deque.append(obs)\n",
    "                    rewards.append(reward)\n",
    "                    imgs.append(wrapper.render())\n",
    "                    \n",
    "                    step_idx += 1\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix(reward=reward)\n",
    "                    \n",
    "                    if done or step_idx >= max_steps: break\n",
    "                    \n",
    "                    # 2. 积分 (Euler Step) 计算下一个时间步的动作\n",
    "                    t_scalar = np.clip(i * dt_val, 1e-3, 1.0 - 1e-3)\n",
    "                    t = torch.tensor([t_scalar], device=device, dtype=torch.float32)\n",
    "                    \n",
    "                    b_drift = get_drift(na, t, o_test, sigma_infer)\n",
    "                    noise = torch.randn_like(na)\n",
    "                    diffusion = sigma_infer * math.sqrt(dt_val) * noise\n",
    "                    \n",
    "                    na = na + b_drift * dt_val + diffusion\n",
    "                \n",
    "                # 更新流的起点 (Streaming)\n",
    "                na_from_prev_chunk = na\n",
    "                \n",
    "                if done: break\n",
    "\n",
    "    print(f\"推理结束! 最高得分: {max(rewards) if rewards else 0}\")\n",
    "    return imgs\n",
    "\n",
    "# =========================================================\n",
    "# 执行推理\n",
    "# =========================================================\n",
    "\n",
    "# 1. ODE 模式 (平滑)\n",
    "imgs_ode = run_si_inference(sigma_infer=0.0, title=\"Streaming SI (ODE Mode)\")\n",
    "imageio.mimsave(\"eval_ssip_ode_abs.gif\", imgs_ode, fps=10)\n",
    "\n",
    "# 2. SDE 模式 (探索)\n",
    "imgs_sde = run_si_inference(sigma_infer=0.05, title=\"Streaming SI (SDE Mode)\")\n",
    "imageio.mimsave(\"eval_ssip_sde_abs.gif\", imgs_sde, fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEG Implementation Archived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TEG on Lift: Obstacle at [0.0, -0.1, 0.95]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7612e601a5d5494abd56334cadd873c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TEG Lift:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Score: 0.0\n",
      "Saving GIF to eval_teg_lift.gif...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import collections\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import imageio\n",
    "\n",
    "# =========================================================\n",
    "# 1. 辅助工具: 3D 到 2D 的简单投影 & 绘图\n",
    "# =========================================================\n",
    "def project_3d_to_2d_heuristic(pos_3d, img_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    一个简单的启发式投影，将 Robosuite 的 3D 坐标映射到 AgentView 的 2D 像素坐标。\n",
    "    注意：这只是一个近似值，用于可视化箭头方向。准确投影需要 env.sim 的相机矩阵。\n",
    "    \"\"\"\n",
    "    x, y, z = pos_3d\n",
    "    h, w = img_size\n",
    "    \n",
    "    # 针对 Robosuite Lift 环境 AgentView 的经验参数\n",
    "    # 如果箭头位置不对，可以微调这里\n",
    "    scale_x = 180.0\n",
    "    scale_y = 180.0\n",
    "    offset_x = 128.0 \n",
    "    offset_y = 128.0 \n",
    "    \n",
    "    # Robosuite坐标系: x向前, y向左, z向上\n",
    "    # 图片坐标系: u向右, v向下\n",
    "    # 简单的透视/正交模拟\n",
    "    u = int(-y * scale_x + offset_x)\n",
    "    v = int(h - (x * scale_y + offset_y + z * 50)) # z轴增加会让物体在图里看起来更高(v更小)\n",
    "    \n",
    "    return (u, v)\n",
    "\n",
    "def draw_vector_arrow_3d(img, start_pos_3d, vector_3d, color, scale=1.0, thickness=2):\n",
    "    \"\"\"\n",
    "    在图像上绘制 3D 向量的 2D 投影\n",
    "    \"\"\"\n",
    "    if vector_3d is None or np.linalg.norm(vector_3d) < 1e-6:\n",
    "        return\n",
    "\n",
    "    # 计算 3D 空间中的终点\n",
    "    end_pos_3d = start_pos_3d + vector_3d * scale\n",
    "    \n",
    "    # 投影到像素\n",
    "    start_px = project_3d_to_2d_heuristic(start_pos_3d, img_size=img.shape[:2])\n",
    "    end_px = project_3d_to_2d_heuristic(end_pos_3d, img_size=img.shape[:2])\n",
    "    \n",
    "    # 绘制箭头\n",
    "    cv2.arrowedLine(img, start_px, end_px, color, thickness, tipLength=0.3)\n",
    "\n",
    "# =========================================================\n",
    "# 2. TEG Inference for Lift (SSIP + 3D Obstacle)\n",
    "# =========================================================\n",
    "\n",
    "def run_teg_inference_lift(obstacle_pos_3d, guidance_scale=20.0, N_ensemble=32):\n",
    "    \"\"\"\n",
    "    obstacle_pos_3d: [x, y, z] list or np.array, 障碍物的绝对物理坐标\n",
    "    \"\"\"\n",
    "    # 1. 环境初始化\n",
    "    obs = wrapper.reset()\n",
    "    obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "    imgs = [wrapper.render()]\n",
    "    rewards = []\n",
    "    \n",
    "    # 2. 准备障碍物 Tensor (用于计算 Cost)\n",
    "    # 我们将其归一化到 Latent Space，因为梯度是在 Latent Space 计算的更稳定\n",
    "    # 注意：只取前3维 (Position)\n",
    "    obs_pos_phys = np.array(obstacle_pos_3d)\n",
    "    \n",
    "    # 归一化障碍物位置\n",
    "    pos_min = dataset.action_normalizer.min_val[:3]\n",
    "    pos_max = dataset.action_normalizer.max_val[:3]\n",
    "    obs_pos_norm = (obs_pos_phys - pos_min) / (pos_max - pos_min) * 2 - 1\n",
    "    \n",
    "    # 转为 Tensor (N, 3)\n",
    "    target_obs_tensor = torch.tensor(obs_pos_norm, device=device, dtype=torch.float32).repeat(N_ensemble, 1)\n",
    "\n",
    "    # 3. Warm Start (同 SSIP Inference)\n",
    "    start_dim = 10 \n",
    "    curr_pos = obs[start_dim : start_dim+3]\n",
    "    norm_pos = (curr_pos - pos_min) / (pos_max - pos_min) * 2 - 1\n",
    "    \n",
    "    na = torch.zeros((1, 1, 10), device=device, dtype=torch.float32)\n",
    "    na[0, 0, :3] = torch.from_numpy(norm_pos).to(device)\n",
    "    na[0, 0, 9] = -1 # Gripper Open\n",
    "    na_from_prev_chunk = na\n",
    "    \n",
    "    # 参数设置\n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    max_steps = 200\n",
    "    dt_real = 1.0 / (pred_horizon - obs_horizon)\n",
    "    \n",
    "    # TEG 参数\n",
    "    K_horizon = 5         # 向前模拟步数\n",
    "    dt_est = 0.1          # 模拟步长\n",
    "    activation_distance = 10  # 归一化空间下的激活距离 (需要根据 Latent Space 的尺度调整)\n",
    "    sigma_est = 0.1       # 模拟时的噪声强度\n",
    "    \n",
    "    # 可视化参数\n",
    "    vis_arrow_scale = 0.5 # 物理空间下箭头的长度缩放\n",
    "    \n",
    "    print(f\"Running TEG on Lift: Obstacle at {obstacle_pos_3d}\")\n",
    "    \n",
    "    with tqdm(total=max_steps, desc=\"TEG Lift\") as pbar:\n",
    "        while not done and step_idx < max_steps:\n",
    "            # --- A. Observation ---\n",
    "            obs_seq = np.stack(obs_deque)\n",
    "            nobs = dataset.obs_normalizer.normalize(obs_seq)\n",
    "            o_test = torch.from_numpy(nobs).to(device, dtype=torch.float32).flatten().unsqueeze(0)\n",
    "            \n",
    "            na = na_from_prev_chunk\n",
    "            \n",
    "            for i in range(action_horizon):\n",
    "                # -------------------------------------------------\n",
    "                # 1. 计算 Base Drift (原始策略场)\n",
    "                # -------------------------------------------------\n",
    "                t_scalar = np.clip(i * dt_real, 1e-3, 1.0 - 1e-3)\n",
    "                t_tensor = torch.tensor([t_scalar], device=device, dtype=torch.float32)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    base_drift = get_drift(na, t_tensor, o_test, sigma_infer=0.0) # 基础漂移不加噪\n",
    "                \n",
    "                # -------------------------------------------------\n",
    "                # 2. TEG: 计算避障梯度 (Repulsive Force)\n",
    "                # -------------------------------------------------\n",
    "                # 计算当前 Latent Position 与障碍物的距离\n",
    "                curr_na_pos = na[0, 0, :3]\n",
    "                dist_to_obs = torch.norm(curr_na_pos - target_obs_tensor[0]).item()\n",
    "                \n",
    "                grad_teg = torch.zeros_like(base_drift)\n",
    "                dynamic_scale = 0.0\n",
    "                \n",
    "                # 只有当距离小于阈值时才启动昂贵的梯度计算\n",
    "                if dist_to_obs < activation_distance:\n",
    "                    with torch.enable_grad():\n",
    "                        # 复制当前状态用于模拟\n",
    "                        # na: (1, 1, 10)\n",
    "                        a_curr = na.detach().requires_grad_(True)\n",
    "                        \n",
    "                        # Batch Expansion: (N, 1, 10)\n",
    "                        a_ens = a_curr.repeat(N_ensemble, 1, 1)\n",
    "                        t_ens = t_tensor.expand(N_ensemble)\n",
    "                        cond_ens = o_test.expand(N_ensemble, -1)\n",
    "                        \n",
    "                        cum_cost = torch.zeros(N_ensemble, device=device)\n",
    "                        curr_a_sim = a_ens\n",
    "                        curr_t_sim = t_ens\n",
    "                        \n",
    "                        # --- K步 模拟循环 ---\n",
    "                        for k_sim in range(K_horizon):\n",
    "                            # 预测速度\n",
    "                            t_input = torch.clamp(curr_t_sim, 0.0, 1.0)\n",
    "                            v_p = ema_si_velocity_net(curr_a_sim, t_input, cond_ens) # (N, 1, 10)\n",
    "                            \n",
    "                            # 这里为了速度，模拟时只用 VelocityNet 的 Euler 积分，暂不计算 Score 修正\n",
    "                            # (在 Push-T 经验中，仅用 v_p 足够估算未来轨迹)\n",
    "                            b_drift_sim = v_p \n",
    "                            \n",
    "                            # 计算 Cost: 只看前3维 (XYZ)\n",
    "                            # 高斯势场: exp(-dist^2 / sigma^2)\n",
    "                            # 距离越近，Cost 越高\n",
    "                            sim_pos = curr_a_sim[:, 0, :3] # (N, 3)\n",
    "                            dist_sq = ((sim_pos - target_obs_tensor)**2).sum(dim=-1) # (N,)\n",
    "                            step_cost = torch.exp(-dist_sq / (2 * 0.15**2)) # 0.15 是势场宽度\n",
    "                            \n",
    "                            cum_cost += step_cost * dt_est\n",
    "                            \n",
    "                            # 更新状态\n",
    "                            noise = torch.randn_like(curr_a_sim)\n",
    "                            curr_a_sim = curr_a_sim + b_drift_sim * dt_est + sigma_est * math.sqrt(dt_est) * noise\n",
    "                            curr_t_sim = curr_t_sim + dt_est\n",
    "                        \n",
    "                        # --- 计算梯度 ---\n",
    "                        # 我们希望最小化 Cost，即最大化 -Cost\n",
    "                        # TEG Paper: grad log( sum exp(-Cost) )\n",
    "                        neg_cost = -cum_cost # We want to minimize cost -> maximize utility\n",
    "                        log_utility = torch.logsumexp(neg_cost, dim=0)\n",
    "                        \n",
    "                        # 对当前动作求导\n",
    "                        (g,) = torch.autograd.grad(log_utility, a_curr)\n",
    "                        grad_teg = g # (1, 1, 10)\n",
    "                        \n",
    "                        # 确保梯度只作用于位置 (XYZ)，清零旋转和夹爪的梯度\n",
    "                        # 这是一个非常重要的步骤，防止避障破坏抓取姿态\n",
    "                        grad_mask = torch.zeros_like(grad_teg)\n",
    "                        grad_mask[:, :, :3] = 1.0\n",
    "                        grad_teg = grad_teg * grad_mask\n",
    "                    \n",
    "                    # 动态权重：距离越近，权重越大\n",
    "                    # Linear ramp: (1 - dist/threshold)\n",
    "                    dynamic_scale = guidance_scale * max(0, (1.0 - dist_to_obs / activation_distance))\n",
    "\n",
    "                # -------------------------------------------------\n",
    "                # 3. 可视化绘制 (Render Vectors)\n",
    "                # -------------------------------------------------\n",
    "                img_rgb = wrapper.render().copy()\n",
    "                \n",
    "                # 获取当前的物理位置 (用于画起点)\n",
    "                curr_phys_10d = dataset.action_normalizer.denormalize(na.detach().cpu().numpy().squeeze())\n",
    "                curr_phys_pos = curr_phys_10d[:3]\n",
    "                \n",
    "                # 1. 绘制障碍物 (黄色球)\n",
    "                # 投影并画圆圈模拟球体\n",
    "                obs_px = project_3d_to_2d_heuristic(obs_pos_phys)\n",
    "                cv2.circle(img_rgb, obs_px, 10, (0, 255, 255), -1)\n",
    "                cv2.putText(img_rgb, \"OBSTACLE\", (obs_px[0]-30, obs_px[1]-15), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)\n",
    "\n",
    "                # 2. 准备向量 (转换回物理空间尺度以便可视化)\n",
    "                # 注意：Latent空间的向量数值在 [-1, 1] 之间，直接画可能很小\n",
    "                # 我们这里直接画 Latent 向量的方向，乘以前面定义的 vis_arrow_scale\n",
    "                \n",
    "                vec_base_np = base_drift[0,0,:3].detach().cpu().numpy()\n",
    "                vec_teg_np = (grad_teg[0,0,:3] * dynamic_scale).detach().cpu().numpy()\n",
    "                \n",
    "                # 绘制 Base Drift (蓝色: 原始意图)\n",
    "                draw_vector_arrow_3d(img_rgb, curr_phys_pos, vec_base_np, (255, 0, 0), scale=vis_arrow_scale)\n",
    "                \n",
    "                # 绘制 TEG Repulsion (红色: 避障力)\n",
    "                if dynamic_scale > 1e-4:\n",
    "                    draw_vector_arrow_3d(img_rgb, curr_phys_pos, vec_teg_np, (0, 0, 255), scale=vis_arrow_scale)\n",
    "                    cv2.putText(img_rgb, f\"TEG: {dynamic_scale:.2f}\", (10, 30), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "                imgs.append(img_rgb)\n",
    "\n",
    "                # -------------------------------------------------\n",
    "                # 4. 执行动作更新 & 环境交互\n",
    "                # -------------------------------------------------\n",
    "                \n",
    "                # 组合漂移: Base + Guidance\n",
    "                total_drift = base_drift + dynamic_scale * grad_teg\n",
    "                \n",
    "                # SDE 更新 (加一点点噪声增加鲁棒性)\n",
    "                noise = torch.randn_like(na)\n",
    "                # 这里 sigma 取小一点，比如 0.01，避免震荡\n",
    "                diffusion = 0.01 * math.sqrt(dt_real) * noise\n",
    "                \n",
    "                na = na + total_drift * dt_real + diffusion\n",
    "                na = na.detach() # 截断梯度\n",
    "                \n",
    "                # 解码动作并执行\n",
    "                action_7d = dataset.get_unnormalized_action(na.cpu().numpy()).squeeze()\n",
    "                \n",
    "                obs, reward, done, info = wrapper.step(action_7d)\n",
    "                obs_deque.append(obs)\n",
    "                rewards.append(reward)\n",
    "                \n",
    "                step_idx += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(rew=reward, teg=dynamic_scale)\n",
    "                \n",
    "                if done or step_idx >= max_steps: break\n",
    "            \n",
    "            na_from_prev_chunk = na\n",
    "            if done: break\n",
    "            \n",
    "    print(f\"Final Score: {max(rewards) if rewards else 0}\")\n",
    "    return imgs\n",
    "\n",
    "# =========================================================\n",
    "# 3. 运行测试\n",
    "# =========================================================\n",
    "\n",
    "# 设置障碍物位置 [x, y, z]\n",
    "# 根据 Lift 任务，方块大约在 [0.1, 0, 0.85] 左右\n",
    "# 我们在路径中间放一个障碍物，迫使它绕路\n",
    "# 比如放在 [0.05, 0.0, 0.9] (稍微高一点，挡在去方块的路上)\n",
    "obstacle_pos = [0.0, -0.1, 0.95] \n",
    "\n",
    "# 运行推理\n",
    "# guidance_scale 越大，斥力越强\n",
    "imgs_teg = run_teg_inference_lift(obstacle_pos, guidance_scale=10.0, N_ensemble=32)\n",
    "\n",
    "# 保存 GIF\n",
    "save_path = \"eval_teg_lift.gif\"\n",
    "print(f\"Saving GIF to {save_path}...\")\n",
    "imageio.mimsave(save_path, imgs_teg, fps=15)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SSIP with TEG Obstacle Avoidance...\n",
      "Target Obstacle: [-0.02  0.08  0.8 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07490f74c9da4ad4af66769c62af4d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SSIP+TEG:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理结束! 最高得分: 1.0\n",
      "正在保存视频到: eval_ssip_teg_avoidance.gif ...\n",
      "保存完成！\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import collections\n",
    "import math\n",
    "import imageio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# 1. 可视化辅助工具\n",
    "# =========================================================\n",
    "def draw_vector_arrow_2d(img, start_px, vector_2d, color, scale=100, thickness=2):\n",
    "    \"\"\"\n",
    "    在图像上绘制 2D 向量箭头 (仅可视化 X, Y 分量)\n",
    "    \"\"\"\n",
    "    if vector_2d is None or np.linalg.norm(vector_2d) < 1e-6:\n",
    "        return\n",
    "    \n",
    "    # 计算终点 (注意 opencv 坐标系: x水平向右, y垂直向下)\n",
    "    # Lift 环境的坐标系通常与图像坐标系有旋转关系，这里做简单的直接映射用于示意\n",
    "    # 如果箭头方向反了，可以调整符号\n",
    "    end_px = (int(start_px[0] + vector_2d[1] * scale),  # 简单的映射尝试，根据实际画面调整\n",
    "              int(start_px[1] - vector_2d[0] * scale))\n",
    "    \n",
    "    try:\n",
    "        cv2.arrowedLine(img, start_px, end_px, color, thickness, tipLength=0.3)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def world_to_pixel_heuristic(pos_3d):\n",
    "    \"\"\"\n",
    "    将 3D 物理坐标 (x,y,z) 映射到 2D 像素坐标的启发式函数。\n",
    "    注意：在没有真实相机矩阵的情况下，这是一个近似映射，仅用于可视化。\n",
    "    Lift 环境通常 AgentView 是斜视。\n",
    "    \"\"\"\n",
    "    # 这里的参数是根据典型的 Robosuite Lift AgentView 手调的近似值\n",
    "    # 实际应用中最好使用 muojco 的 camera matrix\n",
    "    x, y, z = pos_3d\n",
    "    img_size = 256 # 假设渲染尺寸\n",
    "    \n",
    "    # 简单的透视投影模拟\n",
    "    u = 128 + int(y * 600)  \n",
    "    v = 200 - int(z * 600) \n",
    "    return (u, v)\n",
    "\n",
    "# =========================================================\n",
    "# 2. TEG 推理核心函数 (带避障)\n",
    "# =========================================================\n",
    "def run_ssip_teg_inference(\n",
    "    obstacle_pos_phys, \n",
    "    guidance_scale=10.0, \n",
    "    activation_dist=0.3, \n",
    "    N_ensemble=32,       \n",
    "    K_horizon=5          \n",
    "):\n",
    "    # --- 准备工作 ---\n",
    "    obs = wrapper.reset()\n",
    "    obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "    imgs = [wrapper.render()]\n",
    "    rewards = []\n",
    "    \n",
    "    # [修复]: 确保 obstacle_pos_phys 也是 float32\n",
    "    obs_phys_tensor = torch.tensor(obstacle_pos_phys, device=device, dtype=torch.float32)\n",
    "    \n",
    "    start_dim = 10 \n",
    "    curr_pos = obs[start_dim : start_dim+3] \n",
    "    \n",
    "    pos_min = dataset.action_normalizer.min_val[:3]\n",
    "    pos_max = dataset.action_normalizer.max_val[:3]\n",
    "    norm_pos = (curr_pos - pos_min) / (pos_max - pos_min)\n",
    "    norm_pos = norm_pos * 2 - 1\n",
    "    \n",
    "    na = torch.zeros((1, 1, 10), device=device, dtype=torch.float32)\n",
    "    na[0, 0, :3] = torch.from_numpy(norm_pos).to(device, dtype=torch.float32) # 确保 float32\n",
    "    na[0, 0, 9] = -1 \n",
    "    \n",
    "    na_from_prev_chunk = na\n",
    "    \n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    max_steps = 400\n",
    "    dt_val = 1.0 / (pred_horizon - obs_horizon)\n",
    "    dt_est = 0.1 \n",
    "    sigma_infer = 0.05 \n",
    "    \n",
    "    print(f\"Running SSIP with TEG Obstacle Avoidance...\")\n",
    "    print(f\"Target Obstacle: {obstacle_pos_phys}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=max_steps, desc=\"SSIP+TEG\") as pbar:\n",
    "            while not done and step_idx < max_steps:\n",
    "                obs_seq = np.stack(obs_deque)\n",
    "                nobs = dataset.obs_normalizer.normalize(obs_seq)\n",
    "                o_test = torch.from_numpy(nobs).to(device, dtype=torch.float32).flatten().unsqueeze(0)\n",
    "                \n",
    "                na = na_from_prev_chunk\n",
    "                \n",
    "                for i in range(action_horizon):\n",
    "                    t_scalar = np.clip(i * dt_val, 1e-3, 1.0 - 1e-3)\n",
    "\n",
    "                    # ---------------------------------------------------------\n",
    "                    # 1. 计算 TEG 梯度\n",
    "                    # ---------------------------------------------------------\n",
    "                    grad_teg = torch.zeros_like(na)\n",
    "                    dynamic_scale = 0.0\n",
    "                    \n",
    "                    curr_action_phys = dataset.get_unnormalized_action(na) \n",
    "                    curr_xyz = torch.tensor(curr_action_phys[0,0,:3], device=device, dtype=torch.float32)\n",
    "                    dist_to_obs = torch.norm(curr_xyz - obs_phys_tensor).item()\n",
    "                    \n",
    "                    if dist_to_obs < activation_dist:\n",
    "                        with torch.enable_grad():\n",
    "                            na_in = na.squeeze(1).detach().requires_grad_(True)\n",
    "                            \n",
    "                            na_ens = na_in.repeat(N_ensemble, 1) \n",
    "                            \n",
    "                            # [关键修复 1]: 显式指定 dtype=torch.float32，否则 np.clip 返回的 float64 会导致 tensor 变成 double\n",
    "                            t_ens = torch.tensor([t_scalar], device=device, dtype=torch.float32).repeat(N_ensemble)\n",
    "                            cond_ens = o_test.repeat(N_ensemble, 1)\n",
    "                            \n",
    "                            curr_na_sim = na_ens\n",
    "                            curr_t_sim = t_ens\n",
    "                            cum_cost = torch.zeros(N_ensemble, device=device, dtype=torch.float32)\n",
    "                            \n",
    "                            for k_step in range(K_horizon):\n",
    "                                t_input = torch.clamp(curr_t_sim, 0.05, 0.95)\n",
    "                                \n",
    "                                # 网络输入必须全是 float32\n",
    "                                v_p = ema_si_velocity_net(curr_na_sim.unsqueeze(1), t_input, cond_ens).squeeze(1)\n",
    "                                eta_p = ema_si_denoiser_net(curr_na_sim.unsqueeze(1), t_input, cond_ens).squeeze(1)\n",
    "                                \n",
    "                                gamma = gamma_t_si(t_input).view(-1, 1)\n",
    "                                g_dot = d_gamma_dt_si(t_input).view(-1, 1)\n",
    "                                s_p = -eta_p / (gamma + 1e-6)\n",
    "                                sigma_est = 0.05 \n",
    "                                score_coeff = 0.5 * (sigma_est**2) - (gamma * g_dot)\n",
    "                                b_drift = v_p + score_coeff * s_p\n",
    "                                \n",
    "                                # [关键修复 2]: min_val/max_val 是 numpy float64，必须转为 float32\n",
    "                                min_v = torch.from_numpy(dataset.action_normalizer.min_val).to(device, dtype=torch.float32)\n",
    "                                max_v = torch.from_numpy(dataset.action_normalizer.max_val).to(device, dtype=torch.float32)\n",
    "                                scale_v = max_v - min_v\n",
    "                                scale_v[scale_v==0] = 1.0\n",
    "                                \n",
    "                                denorm_sim = ((curr_na_sim + 1) / 2) * scale_v + min_v\n",
    "                                sim_xyz = denorm_sim[:, :3]\n",
    "                                \n",
    "                                dist_sq = ((sim_xyz - obs_phys_tensor)**2).sum(dim=-1)\n",
    "                                cost_step = torch.exp(-dist_sq / (2 * 0.05**2)) \n",
    "                                cum_cost = cum_cost + cost_step * dt_est\n",
    "                                \n",
    "                                curr_na_sim = curr_na_sim + b_drift * dt_est\n",
    "                                curr_t_sim = curr_t_sim + dt_est\n",
    "                                \n",
    "                            neg_cost = -cum_cost\n",
    "                            log_utility = torch.logsumexp(neg_cost, dim=0)\n",
    "                            \n",
    "                            (g,) = torch.autograd.grad(log_utility, na_in)\n",
    "                            grad_teg = g.unsqueeze(1)\n",
    "                            \n",
    "                        dynamic_scale = guidance_scale * max(0, (1.0 - dist_to_obs / activation_dist))\n",
    "                    \n",
    "                    # ---------------------------------------------------------\n",
    "                    # 2. Base Policy\n",
    "                    # ---------------------------------------------------------\n",
    "                    t = torch.tensor([t_scalar], device=device, dtype=torch.float32)\n",
    "                    b_drift_base = get_drift(na, t, o_test, sigma_infer)\n",
    "                    \n",
    "                    # ---------------------------------------------------------\n",
    "                    # 3. Update\n",
    "                    # ---------------------------------------------------------\n",
    "                    total_drift = b_drift_base + dynamic_scale * grad_teg\n",
    "                    \n",
    "                    noise = torch.randn_like(na)\n",
    "                    diffusion = sigma_infer * math.sqrt(dt_val) * noise\n",
    "                    \n",
    "                    na = na + total_drift * dt_val + diffusion\n",
    "                    \n",
    "                    # ---------------------------------------------------------\n",
    "                    # 4. Step & Vis\n",
    "                    # ---------------------------------------------------------\n",
    "                    a_real_full = dataset.get_unnormalized_action(na)\n",
    "                    a_real = a_real_full.squeeze()\n",
    "                    obs, reward, done, info = wrapper.step(a_real)\n",
    "                    \n",
    "                    obs_deque.append(obs)\n",
    "                    rewards.append(reward)\n",
    "                    \n",
    "                    img_rgb = wrapper.render().copy()\n",
    "                    \n",
    "                    if img_rgb.shape[0] > 64:\n",
    "                        obs_px = world_to_pixel_heuristic(obstacle_pos_phys)\n",
    "                        curr_px = world_to_pixel_heuristic(curr_xyz.detach().cpu().numpy())\n",
    "                        \n",
    "                        cv2.circle(img_rgb, obs_px, 5, (255, 255, 0), -1)\n",
    "                        cv2.circle(img_rgb, curr_px, 5, (0, 0, 255), -1)\n",
    "                        \n",
    "                        if dynamic_scale > 1e-4:\n",
    "                            vec_teg = (grad_teg * dynamic_scale).detach().cpu().numpy().squeeze()[:2]\n",
    "                            draw_vector_arrow_2d(img_rgb, curr_px, vec_teg, (0, 255, 0), scale=200, thickness=2)\n",
    "                    \n",
    "                    imgs.append(img_rgb)\n",
    "                    \n",
    "                    step_idx += 1\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix(reward=reward)\n",
    "                    \n",
    "                    if done or step_idx >= max_steps: break\n",
    "                \n",
    "                na_from_prev_chunk = na\n",
    "                if done: break\n",
    "\n",
    "    print(f\"推理结束! 最高得分: {max(rewards) if rewards else 0}\")\n",
    "    return imgs\n",
    "\n",
    "# =========================================================\n",
    "# 3. 运行示例\n",
    "# =========================================================\n",
    "\n",
    "# 定义一个虚拟障碍物位置 (x, y, z)\n",
    "# Lift 环境中，方块通常在 [0, 0, 0] 附近，机械臂在上方\n",
    "# 我们在方块上方或侧面放一个障碍物，强迫机械臂绕行\n",
    "obstacle_pos = np.array([-0.02, 0.08, 0.8]) \n",
    "\n",
    "# 运行推理\n",
    "imgs_teg = run_ssip_teg_inference(\n",
    "    obstacle_pos_phys=obstacle_pos,\n",
    "    guidance_scale=8.0,   # 这里的 scale 可以根据效果调整，越大斥力越强\n",
    "    activation_dist=0.25, # 当距离小于 25cm 时触发避障\n",
    "    N_ensemble=16         # 并行采样数，显存够可以开大\n",
    ")\n",
    "\n",
    "# 保存 GIF\n",
    "save_path = \"eval_ssip_teg_avoidance.gif\"\n",
    "print(f\"正在保存视频到: {save_path} ...\")\n",
    "imageio.mimsave(save_path, imgs_teg, fps=15)\n",
    "print(\"保存完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Inference with Accurate Projection...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2be0de43754e048c950d8bc335341a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理结束! 最高得分: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import collections\n",
    "import math\n",
    "import imageio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# 工具函数: MuJoCo 真实坐标投影\n",
    "# =========================================================\n",
    "def world_to_pixel_mujoco(sim, pos_3d, camera_name, img_h, img_w):\n",
    "    \"\"\" 利用 MuJoCo 内参矩阵进行精确投影 \"\"\"\n",
    "    try:\n",
    "        cam_id = sim.model.camera_name2id(camera_name)\n",
    "        cam_pos = sim.data.cam_xpos[cam_id]\n",
    "        cam_mat = sim.data.cam_xmat[cam_id].reshape(3, 3)\n",
    "        \n",
    "        pos_rel = pos_3d - cam_pos\n",
    "        pos_cam_opengl = cam_mat.T @ pos_rel\n",
    "        \n",
    "        x, y, z = pos_cam_opengl[0], -pos_cam_opengl[1], -pos_cam_opengl[2]\n",
    "        \n",
    "        if z < 0.01: return None\n",
    "            \n",
    "        fovy = sim.model.cam_fovy[cam_id]\n",
    "        f = 0.5 * img_h / np.tan(fovy * np.pi / 360)\n",
    "        cx, cy = img_w / 2, img_h / 2\n",
    "        \n",
    "        u = int(cx + f * x / z)\n",
    "        v = int(cy + f * y / z)\n",
    "        \n",
    "        if 0 <= u < img_w and 0 <= v < img_h:\n",
    "            return (u, v)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # print(f\"Proj Error: {e}\") \n",
    "        return None\n",
    "\n",
    "# =========================================================\n",
    "# 推理函数 (集成版)\n",
    "# =========================================================\n",
    "def run_ssip_teg_inference_accurate_vis(\n",
    "    obstacle_pos_phys, \n",
    "    guidance_scale=15.0, \n",
    "    activation_dist=0.3, \n",
    "    N_ensemble=16,       \n",
    "    update_interval=4    \n",
    "):\n",
    "    # 1. 重置环境\n",
    "    obs = wrapper.reset()\n",
    "    obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "    imgs = [wrapper.render()]\n",
    "    rewards = []\n",
    "    \n",
    "    # 确保障碍物坐标是 float32 Tensor\n",
    "    obs_phys_tensor = torch.tensor(obstacle_pos_phys, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 初始化 Latent Action (na)\n",
    "    start_dim = 10 \n",
    "    curr_pos = obs[start_dim : start_dim+3] \n",
    "    pos_min = dataset.action_normalizer.min_val[:3]\n",
    "    pos_max = dataset.action_normalizer.max_val[:3]\n",
    "    norm_pos = (curr_pos - pos_min) / (pos_max - pos_min) * 2 - 1\n",
    "    \n",
    "    na = torch.zeros((1, 1, 10), device=device, dtype=torch.float32)\n",
    "    na[0, 0, :3] = torch.from_numpy(norm_pos).to(device, dtype=torch.float32)\n",
    "    na[0, 0, 9] = -1 \n",
    "    na_from_prev_chunk = na\n",
    "    \n",
    "    # 缓存变量\n",
    "    cached_grad = torch.zeros_like(na)\n",
    "    cached_scale = 0.0\n",
    "    \n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    max_steps = 400\n",
    "    dt_val = 1.0 / (pred_horizon - obs_horizon)\n",
    "    sigma_infer = 0.05 \n",
    "\n",
    "    print(f\"Running Inference with Accurate Projection...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=max_steps) as pbar:\n",
    "            while not done and step_idx < max_steps:\n",
    "                obs_seq = np.stack(obs_deque)\n",
    "                nobs = dataset.obs_normalizer.normalize(obs_seq)\n",
    "                o_test = torch.from_numpy(nobs).to(device, dtype=torch.float32).flatten().unsqueeze(0)\n",
    "                \n",
    "                na = na_from_prev_chunk\n",
    "                \n",
    "                for i in range(action_horizon):\n",
    "                    t_scalar = np.clip(i * dt_val, 1e-3, 1.0 - 1e-3)\n",
    "\n",
    "                    # --- 1. TEG 计算 (省略具体逻辑，与之前相同，重点在下面的可视化) ---\n",
    "                    curr_action_phys = dataset.get_unnormalized_action(na) \n",
    "                    curr_xyz = torch.tensor(curr_action_phys[0,0,:3], device=device, dtype=torch.float32)\n",
    "                    dist_to_obs = torch.norm(curr_xyz - obs_phys_tensor).item()\n",
    "                    \n",
    "                    should_compute = (dist_to_obs < activation_dist) and (step_idx % update_interval == 0)\n",
    "                    \n",
    "                    if should_compute:\n",
    "                        # ... (此处填入之前的 TEG 梯度计算代码) ...\n",
    "                        # 为了简洁，假设我们算出了 cached_grad\n",
    "                        # 下面这行是占位，请复用之前的逻辑\n",
    "                        pass \n",
    "                        \n",
    "                        # 这是一个示例逻辑，你需要把之前的 TEG 代码块放进来\n",
    "                        cached_scale = guidance_scale * max(0, (1.0 - dist_to_obs / activation_dist))\n",
    "                    elif dist_to_obs >= activation_dist:\n",
    "                        cached_scale = 0.0\n",
    "\n",
    "                    # --- 2. SSIP Update ---\n",
    "                    t = torch.tensor([t_scalar], device=device, dtype=torch.float32)\n",
    "                    b_drift_base = get_drift(na, t, o_test, sigma_infer)\n",
    "                    total_drift = b_drift_base + cached_scale * cached_grad\n",
    "                    \n",
    "                    noise = torch.randn_like(na)\n",
    "                    na = na + total_drift * dt_val + sigma_infer * math.sqrt(dt_val) * noise\n",
    "                    \n",
    "                    # --- 3. Step & Render ---\n",
    "                    a_real = dataset.get_unnormalized_action(na).squeeze()\n",
    "                    obs, reward, done, _ = wrapper.step(a_real)\n",
    "                    obs_deque.append(obs)\n",
    "                    rewards.append(reward)\n",
    "                    \n",
    "                    img_rgb = wrapper.render().copy()\n",
    "                    \n",
    "                    # [关键修改]: 使用 wrapper.sim 进行精确投影\n",
    "                    if img_rgb.shape[0] > 64:\n",
    "                        h, w = img_rgb.shape[:2]\n",
    "                        # 确保 Wrapper 里添加了 @property sim\n",
    "                        sim_obj = getattr(wrapper, 'sim', None) \n",
    "                        \n",
    "                        if sim_obj:\n",
    "                            # 1. 投影障碍物\n",
    "                            obs_px = world_to_pixel_mujoco(sim_obj, obstacle_pos_phys, \"agentview\", h, w)\n",
    "                            \n",
    "                            # 2. 投影 Agent 当前位置\n",
    "                            curr_phys_pos = curr_xyz.detach().cpu().numpy()\n",
    "                            curr_px = world_to_pixel_mujoco(sim_obj, curr_phys_pos, \"agentview\", h, w)\n",
    "                            \n",
    "                            # 绘制\n",
    "                            if obs_px:\n",
    "                                cv2.circle(img_rgb, obs_px, 6, (255, 255, 0), -1)\n",
    "                                cv2.putText(img_rgb, \"OBS\", (obs_px[0]+8, obs_px[1]), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "                            \n",
    "                            if curr_px and cached_scale > 1e-4:\n",
    "                                cv2.circle(img_rgb, curr_px, 6, (0, 0, 255), -1)\n",
    "                                # 简单画个方向 (仅供参考)\n",
    "                                vec = (cached_grad * cached_scale).detach().cpu().numpy().squeeze()[:2]\n",
    "                                end_pt = (int(curr_px[0] + vec[1]*200), int(curr_px[1] - vec[0]*200))\n",
    "                                cv2.arrowedLine(img_rgb, curr_px, end_pt, (0, 255, 0), 2)\n",
    "                        \n",
    "                    imgs.append(img_rgb)\n",
    "                    step_idx += 1\n",
    "                    pbar.update(1)\n",
    "                    if done or step_idx >= max_steps: break\n",
    "                \n",
    "                na_from_prev_chunk = na\n",
    "                if done: break\n",
    "\n",
    "    return imgs\n",
    "\n",
    "# =========================================================\n",
    "# 3. 运行示例\n",
    "# =========================================================\n",
    "\n",
    "# 定义一个虚拟障碍物位置 (x, y, z)\n",
    "# Lift 环境中，方块通常在 [0, 0, 0] 附近，机械臂在上方\n",
    "# 我们在方块上方或侧面放一个障碍物，强迫机械臂绕行\n",
    "obstacle_pos = np.array([-0.02, 0.08, 0.8]) \n",
    "\n",
    "# 运行推理\n",
    "imgs_teg = run_ssip_teg_inference_accurate_vis(\n",
    "    obstacle_pos_phys=obstacle_pos,\n",
    "    guidance_scale=8.0,   # 这里的 scale 可以根据效果调整，越大斥力越强\n",
    "    activation_dist=0.25, # 当距离小于 25cm 时触发避障\n",
    "    N_ensemble=16         # 并行采样数，显存够可以开大\n",
    ")\n",
    "\n",
    "# 保存 GIF\n",
    "save_path = \"eval_ssip_teg_avoidance.gif\"\n",
    "print(f\"正在保存视频到: {save_path} ...\")\n",
    "imageio.mimsave(save_path, imgs_teg, fps=15)\n",
    "print(\"保存完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 环境信息 ---\n",
      "Body Name: table\n",
      "Table Position (World Frame): [0.    0.    0.775]\n",
      "Table Top Height (Z): 0.775\n",
      "桌子中心高度: 0.775\n",
      "桌子半厚度 (z_half): 0.025\n",
      "桌面绝对高度: 0.8\n"
     ]
    }
   ],
   "source": [
    "import robosuite as suite\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个环境，例如 Lift\n",
    "env = suite.make(\n",
    "    env_name=\"Lift\",\n",
    "    robots=\"Panda\",\n",
    "    has_renderer=False,\n",
    "    use_camera_obs=False,\n",
    ")\n",
    "\n",
    "env.reset()\n",
    "\n",
    "# 1. 获取桌子刚体 (Body) 的 ID\n",
    "# 在 TableArena 中，桌面的 body 名称通常包含 \"table\"\n",
    "# 常见的名称是 \"table_main\" 或者直接就是 XML 里的定义\n",
    "body_name = \"table\" # 这通常是 TableArena 中桌面的名称\n",
    "\n",
    "try:\n",
    "    body_id = env.sim.model.body_name2id(body_name)\n",
    "    # 2. 获取该 ID 对应的笛卡尔坐标 (x, y, z)\n",
    "    table_pos = env.sim.data.body_xpos[body_id]\n",
    "    \n",
    "    print(f\"--- 环境信息 ---\")\n",
    "    print(f\"Body Name: {body_name}\")\n",
    "    print(f\"Table Position (World Frame): {table_pos}\")\n",
    "    # 注意：这个位置通常是桌子几何体的中心点\n",
    "    \n",
    "    # 获取桌面高度的另一种方式（利用其几何尺寸）\n",
    "    # geom_name 通常也类似，或者可以通过 body 查 geom\n",
    "    # 这里简单打印一下 z 轴高度\n",
    "    print(f\"Table Top Height (Z): {table_pos[2]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"无法找到名为 '{body_name}' 的 body。\")\n",
    "    print(\"可用的 body 名称有:\", env.sim.model.body_names)\n",
    "# 假设 env 是你的环境实例\n",
    "# 1. 找到桌子碰撞体 (Geom) 的 ID\n",
    "# 注意：Body 是刚体容器，Geom 才是定义形状和碰撞属性的\n",
    "# 在 TableArena 中，碰撞体通常叫 'table_collision' 或直接用 body 名去查 geom\n",
    "geom_name = \"table_collision\" \n",
    "\n",
    "try:\n",
    "    geom_id = env.sim.model.geom_name2id(geom_name)\n",
    "    \n",
    "    # 2. 获取几何体尺寸 (MuJoCo 中存储的是半长/half-extents)\n",
    "    # 返回的是 [x_half, y_half, z_half]\n",
    "    table_size = env.sim.model.geom_size[geom_id]\n",
    "    \n",
    "    # 3. 获取桌子中心位置 (之前你获取的那个)\n",
    "    body_id = env.sim.model.body_name2id(\"table\")\n",
    "    table_pos = env.sim.data.body_xpos[body_id]\n",
    "    \n",
    "    # 4. 计算桌面高度\n",
    "    table_top_z = table_pos[2] + table_size[2]\n",
    "    \n",
    "    print(f\"桌子中心高度: {table_pos[2]}\")\n",
    "    print(f\"桌子半厚度 (z_half): {table_size[2]}\")\n",
    "    print(f\"桌面绝对高度: {table_top_z}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"找不到 geom: {geom_name}. 请检查 XML 中的 geom 名称。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Inference with Accurate Projection...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe8e21a72c5487bbc2dd50ec3502317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理结束! 最高得分: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import collections\n",
    "import math\n",
    "import imageio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# 工具函数: MuJoCo 真实坐标投影\n",
    "# =========================================================\n",
    "def world_to_pixel_mujoco(sim, pos_3d, camera_name, img_h, img_w):\n",
    "    \"\"\" 利用 MuJoCo 内参矩阵进行精确投影 \"\"\"\n",
    "    try:\n",
    "        cam_id = sim.model.camera_name2id(camera_name)\n",
    "        cam_pos = sim.data.cam_xpos[cam_id]\n",
    "        cam_mat = sim.data.cam_xmat[cam_id].reshape(3, 3)\n",
    "        \n",
    "        pos_rel = pos_3d - cam_pos\n",
    "        pos_cam_opengl = cam_mat.T @ pos_rel\n",
    "        \n",
    "        x, y, z = pos_cam_opengl[0], -pos_cam_opengl[1], -pos_cam_opengl[2]\n",
    "        \n",
    "        if z < 0.01: return None\n",
    "            \n",
    "        fovy = sim.model.cam_fovy[cam_id]\n",
    "        f = 0.5 * img_h / np.tan(fovy * np.pi / 360)\n",
    "        cx, cy = img_w / 2, img_h / 2\n",
    "        \n",
    "        u = int(cx + f * x / z)\n",
    "        v = int(cy + f * y / z)\n",
    "        \n",
    "        if 0 <= u < img_w and 0 <= v < img_h:\n",
    "            return (u, v)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# =========================================================\n",
    "# 推理函数 (集成版 - 补全了 STEG 核心逻辑)\n",
    "# =========================================================\n",
    "def run_ssip_teg_inference_accurate_vis(\n",
    "    obstacle_pos_phys, \n",
    "    guidance_scale=15.0, \n",
    "    activation_dist=0.3, \n",
    "    N_ensemble=16,       \n",
    "    update_interval=4,\n",
    "    K_horizon=3          # 新增参数: 向前模拟步数\n",
    "):\n",
    "    # 1. 重置环境\n",
    "    obs = wrapper.reset()\n",
    "    obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "    imgs = [wrapper.render()]\n",
    "    rewards = []\n",
    "    \n",
    "    # 确保障碍物坐标是 float32 Tensor\n",
    "    obs_phys_tensor = torch.tensor(obstacle_pos_phys, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 初始化 Latent Action (na)\n",
    "    start_dim = 10 \n",
    "    curr_pos = obs[start_dim : start_dim+3] \n",
    "    pos_min = dataset.action_normalizer.min_val[:3]\n",
    "    pos_max = dataset.action_normalizer.max_val[:3]\n",
    "    norm_pos = (curr_pos - pos_min) / (pos_max - pos_min) * 2 - 1\n",
    "    \n",
    "    na = torch.zeros((1, 1, 10), device=device, dtype=torch.float32)\n",
    "    na[0, 0, :3] = torch.from_numpy(norm_pos).to(device, dtype=torch.float32)\n",
    "    na[0, 0, 9] = -1 \n",
    "    na_from_prev_chunk = na\n",
    "    \n",
    "    # 缓存变量\n",
    "    cached_grad = torch.zeros_like(na)\n",
    "    cached_scale = 0.0\n",
    "    \n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    max_steps = 400\n",
    "    dt_val = 1.0 / (pred_horizon - obs_horizon)\n",
    "    dt_est = 0.1 # 模拟步长\n",
    "    sigma_infer = 0.05 \n",
    "\n",
    "    print(f\"Running Inference with Accurate Projection...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=max_steps) as pbar:\n",
    "            while not done and step_idx < max_steps:\n",
    "                obs_seq = np.stack(obs_deque)\n",
    "                nobs = dataset.obs_normalizer.normalize(obs_seq)\n",
    "                o_test = torch.from_numpy(nobs).to(device, dtype=torch.float32).flatten().unsqueeze(0)\n",
    "                \n",
    "                na = na_from_prev_chunk\n",
    "                \n",
    "                for i in range(action_horizon):\n",
    "                    t_scalar = np.clip(i * dt_val, 1e-3, 1.0 - 1e-3)\n",
    "\n",
    "                    # --- 1. TEG 计算 ---\n",
    "                    curr_action_phys = dataset.get_unnormalized_action(na) \n",
    "                    curr_xyz = torch.tensor(curr_action_phys[0,0,:3], device=device, dtype=torch.float32)\n",
    "                    dist_to_obs = torch.norm(curr_xyz - obs_phys_tensor).item()\n",
    "                    \n",
    "                    # 判断是否需要重新计算梯度 (距离近 + 间隔步数到了)\n",
    "                    should_compute = (dist_to_obs < activation_dist) and (step_idx % update_interval == 0)\n",
    "                    \n",
    "                    if should_compute:\n",
    "                        # === [核心补全] STEG 梯度计算 ===\n",
    "                        with torch.enable_grad():\n",
    "                            # 1. 准备梯度输入\n",
    "                            na_in = na.squeeze(1).detach().requires_grad_(True)\n",
    "                            \n",
    "                            # 2. 扩展 Batch 进行并行模拟\n",
    "                            na_ens = na_in.repeat(N_ensemble, 1) \n",
    "                            # 确保时间是 float32\n",
    "                            t_ens = torch.tensor([t_scalar], device=device, dtype=torch.float32).repeat(N_ensemble)\n",
    "                            cond_ens = o_test.repeat(N_ensemble, 1)\n",
    "                            \n",
    "                            curr_na_sim = na_ens\n",
    "                            curr_t_sim = t_ens\n",
    "                            cum_cost = torch.zeros(N_ensemble, device=device, dtype=torch.float32)\n",
    "                            \n",
    "                            # 3. 向前模拟循环 (Rollout)\n",
    "                            for k_step in range(K_horizon):\n",
    "                                t_input = torch.clamp(curr_t_sim, 0.05, 0.95)\n",
    "                                \n",
    "                                # 网络预测\n",
    "                                v_p = ema_si_velocity_net(curr_na_sim.unsqueeze(1), t_input, cond_ens).squeeze(1)\n",
    "                                eta_p = ema_si_denoiser_net(curr_na_sim.unsqueeze(1), t_input, cond_ens).squeeze(1)\n",
    "                                \n",
    "                                # 计算系数\n",
    "                                gamma = gamma_t_si(t_input).view(-1, 1)\n",
    "                                g_dot = d_gamma_dt_si(t_input).view(-1, 1)\n",
    "                                s_p = -eta_p / (gamma + 1e-6)\n",
    "                                sigma_est = 0.05 \n",
    "                                score_coeff = 0.5 * (sigma_est**2) - (gamma * g_dot)\n",
    "                                b_drift = v_p + score_coeff * s_p\n",
    "                                \n",
    "                                # --- 物理空间 Cost 计算 ---\n",
    "                                # 准备归一化参数 (转为 Tensor float32)\n",
    "                                min_v = torch.from_numpy(dataset.action_normalizer.min_val).to(device, dtype=torch.float32)\n",
    "                                max_v = torch.from_numpy(dataset.action_normalizer.max_val).to(device, dtype=torch.float32)\n",
    "                                scale_v = max_v - min_v\n",
    "                                scale_v[scale_v==0] = 1.0\n",
    "                                \n",
    "                                # 可微反归一化 (Differentiable Denormalization)\n",
    "                                denorm_sim = ((curr_na_sim + 1) / 2) * scale_v + min_v\n",
    "                                sim_xyz = denorm_sim[:, :3] # 只取 XYZ 位置\n",
    "                                \n",
    "                                # 计算与障碍物的距离 Cost (高斯排斥)\n",
    "                                dist_sq = ((sim_xyz - obs_phys_tensor)**2).sum(dim=-1)\n",
    "                                cost_step = torch.exp(-dist_sq / (2 * 0.05**2)) # 0.05 是障碍物半径参数\n",
    "                                cum_cost = cum_cost + cost_step * dt_est\n",
    "                                \n",
    "                                # Euler 更新模拟状态\n",
    "                                curr_na_sim = curr_na_sim + b_drift * dt_est\n",
    "                                curr_t_sim = curr_t_sim + dt_est\n",
    "                                \n",
    "                            # 4. 反向传播求梯度\n",
    "                            neg_cost = -cum_cost\n",
    "                            log_utility = torch.logsumexp(neg_cost, dim=0)\n",
    "                            \n",
    "                            (g,) = torch.autograd.grad(log_utility, na_in)\n",
    "                            \n",
    "                            # 更新缓存的梯度\n",
    "                            cached_grad = g.unsqueeze(1).detach()\n",
    "                            \n",
    "                        # 更新引导强度\n",
    "                        cached_scale = guidance_scale * max(0, (1.0 - dist_to_obs / activation_dist))\n",
    "                    \n",
    "                    elif dist_to_obs >= activation_dist:\n",
    "                        # 距离远时，清空梯度和强度\n",
    "                        cached_scale = 0.0\n",
    "                        cached_grad = torch.zeros_like(na)\n",
    "\n",
    "                    # --- 2. SSIP Update (Base Policy + Guidance) ---\n",
    "                    t = torch.tensor([t_scalar], device=device, dtype=torch.float32)\n",
    "                    b_drift_base = get_drift(na, t, o_test, sigma_infer)\n",
    "                    \n",
    "                    # 叠加 cached_grad\n",
    "                    total_drift = b_drift_base + cached_scale * cached_grad\n",
    "                    \n",
    "                    noise = torch.randn_like(na)\n",
    "                    na = na + total_drift * dt_val + sigma_infer * math.sqrt(dt_val) * noise\n",
    "                    \n",
    "                    # --- 3. Step & Render ---\n",
    "                    a_real = dataset.get_unnormalized_action(na).squeeze()\n",
    "                    obs, reward, done, _ = wrapper.step(a_real)\n",
    "                    obs_deque.append(obs)\n",
    "                    rewards.append(reward)\n",
    "                    \n",
    "                    img_rgb = wrapper.render().copy()\n",
    "                    \n",
    "                    # ---------------------------------------------------------\n",
    "                    # 4. 可视化绘制 (增强版: 增加桌面投影和距离连线)\n",
    "                    # ---------------------------------------------------------\n",
    "                    if img_rgb.shape[0] > 64:\n",
    "                        h, w = img_rgb.shape[:2]\n",
    "                        sim_obj = getattr(wrapper, 'sim', None) \n",
    "                        \n",
    "                        if sim_obj:\n",
    "                            # --- A. 准备 3D 坐标 ---\n",
    "                            # 1. 障碍物中心坐标\n",
    "                            pos_obs_3d = obstacle_pos_phys\n",
    "                            \n",
    "                            # 2. 障碍物在桌面的投影点 (利用已知的 table_z = 0.8)\n",
    "                            table_z = 0.8\n",
    "                            pos_obs_ground_3d = pos_obs_3d.copy()\n",
    "                            pos_obs_ground_3d[2] = table_z\n",
    "                            \n",
    "                            # 3. Agent (End-Effector) 当前坐标\n",
    "                            pos_agent_3d = curr_xyz.detach().cpu().numpy()\n",
    "\n",
    "                            # --- B. 投影到 2D 像素 ---\n",
    "                            px_obs = world_to_pixel_mujoco(sim_obj, pos_obs_3d, \"agentview\", h, w)\n",
    "                            px_obs_ground = world_to_pixel_mujoco(sim_obj, pos_obs_ground_3d, \"agentview\", h, w)\n",
    "                            px_agent = world_to_pixel_mujoco(sim_obj, pos_agent_3d, \"agentview\", h, w)\n",
    "                            \n",
    "                            # --- C. 绘制辅助线 ---\n",
    "                            \n",
    "                            # 1. 画垂直投影线 (从障碍物中心 -> 桌面)\n",
    "                            # 作用: 帮助通过 2D 图像理解障碍物的高度\n",
    "                            if px_obs is not None and px_obs_ground is not None:\n",
    "                                # 画一条细线表示高度\n",
    "                                cv2.line(img_rgb, px_obs, px_obs_ground, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "                                # 在桌面落点画一个小叉或圆圈\n",
    "                                cv2.circle(img_rgb, px_obs_ground, 3, (255, 255, 0), 1)\n",
    "\n",
    "                            # 2. 画 Agent 到 障碍物 的连线\n",
    "                            # 作用: 直观展示当前的距离关系\n",
    "                            if px_agent is not None and px_obs is not None:\n",
    "                                # 使用浅灰色或白色，避免抢眼\n",
    "                                cv2.line(img_rgb, px_agent, px_obs, (200, 200, 200), 1, cv2.LINE_AA)\n",
    "\n",
    "                            # --- D. 绘制原有元素 (圆点和梯度箭头) ---\n",
    "                            \n",
    "                            # 绘制障碍物本体\n",
    "                            if px_obs is not None:\n",
    "                                cv2.circle(img_rgb, px_obs, 6, (255,0, 255), -1) # Cyan/Yellowish\n",
    "                                cv2.putText(img_rgb, \"OBS\", (px_obs[0]+8, px_obs[1]), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "                            \n",
    "                            # 绘制 Agent 本体和梯度\n",
    "                            if px_agent is not None and cached_scale > 1e-4:\n",
    "                                cv2.circle(img_rgb, px_agent, 6, (0, 0, 255), -1) # Red\n",
    "                                \n",
    "                                # 计算梯度箭头的物理终点\n",
    "                                grad_vec_3d = (cached_grad * cached_scale).detach().cpu().numpy().squeeze()[:3]\n",
    "                                vis_scale = 1.0 \n",
    "                                pos_grad_end_3d = pos_agent_3d + grad_vec_3d * vis_scale\n",
    "                                \n",
    "                                px_grad_end = world_to_pixel_mujoco(sim_obj, pos_grad_end_3d, \"agentview\", h, w)\n",
    "                                \n",
    "                                if px_grad_end is not None:\n",
    "                                    cv2.arrowedLine(img_rgb, px_agent, px_grad_end, (0, 255, 0), 2, tipLength=0.3)\n",
    "                        \n",
    "                    imgs.append(img_rgb)\n",
    "                    step_idx += 1\n",
    "                    pbar.update(1)\n",
    "                    if done or step_idx >= max_steps: break\n",
    "                \n",
    "                na_from_prev_chunk = na\n",
    "                if done: break\n",
    "\n",
    "    print(f\"推理结束! 最高得分: {max(rewards) if rewards else 0}\")\n",
    "    return imgs\n",
    "\n",
    "# =========================================================\n",
    "# 3. 运行示例\n",
    "# =========================================================\n",
    "\n",
    "# 定义一个虚拟障碍物位置 (悬浮在方块上方)\n",
    "obstacle_pos = np.array([0.03, 0.016, 0.93]) \n",
    "\n",
    "# 运行推理 (调用新的函数名)\n",
    "imgs_teg = run_ssip_teg_inference_accurate_vis(\n",
    "    obstacle_pos_phys=obstacle_pos,\n",
    "    guidance_scale=1.0,   \n",
    "    activation_dist=0.3, \n",
    "    N_ensemble=16,         \n",
    "    update_interval=4,\n",
    "    K_horizon=3          \n",
    ")\n",
    "\n",
    "imageio.mimsave(\"eval_ssip_teg_accurate_vis.gif\", imgs_teg, fps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Inference with Accurate Projection...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2488e0182dd54696bb8873dab412eebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理结束! 最高得分: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import collections\n",
    "import math\n",
    "import imageio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# =========================================================\n",
    "# 工具函数: MuJoCo 真实坐标投影\n",
    "# =========================================================\n",
    "def world_to_pixel_mujoco(sim, pos_3d, camera_name, img_h, img_w):\n",
    "    \"\"\" 利用 MuJoCo 内参矩阵进行精确投影 \"\"\"\n",
    "    try:\n",
    "        cam_id = sim.model.camera_name2id(camera_name)\n",
    "        cam_pos = sim.data.cam_xpos[cam_id]\n",
    "        cam_mat = sim.data.cam_xmat[cam_id].reshape(3, 3)\n",
    "        \n",
    "        pos_rel = pos_3d - cam_pos\n",
    "        pos_cam_opengl = cam_mat.T @ pos_rel\n",
    "        \n",
    "        x, y, z = pos_cam_opengl[0], -pos_cam_opengl[1], -pos_cam_opengl[2]\n",
    "        \n",
    "        if z < 0.01: return None\n",
    "            \n",
    "        fovy = sim.model.cam_fovy[cam_id]\n",
    "        f = 0.5 * img_h / np.tan(fovy * np.pi / 360)\n",
    "        cx, cy = img_w / 2, img_h / 2\n",
    "        \n",
    "        u = int(cx + f * x / z)\n",
    "        v = int(cy + f * y / z)\n",
    "        \n",
    "        if 0 <= u < img_w and 0 <= v < img_h:\n",
    "            return (u, v)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# =========================================================\n",
    "# 推理函数 (集成版 - 补全了 STEG 核心逻辑)\n",
    "# =========================================================\n",
    "def run_ssip_teg_inference_accurate_vis(\n",
    "    obstacle_pos_phys, \n",
    "    guidance_scale=15.0, \n",
    "    activation_dist=0.3, \n",
    "    N_ensemble=16,       \n",
    "    update_interval=4,\n",
    "    K_horizon=3          # 新增参数: 向前模拟步数\n",
    "):\n",
    "    # 1. 重置环境\n",
    "    wrapper.seed(0)\n",
    "    obs = wrapper.reset()\n",
    "    obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "    imgs = [wrapper.render()]\n",
    "    rewards = []\n",
    "    \n",
    "    # 确保障碍物坐标是 float32 Tensor\n",
    "    obs_phys_tensor = torch.tensor(obstacle_pos_phys, device=device, dtype=torch.float32)\n",
    "    \n",
    "    # 初始化 Latent Action (na)\n",
    "    start_dim = 10 \n",
    "    curr_pos = obs[start_dim : start_dim+3] \n",
    "    pos_min = dataset.action_normalizer.min_val[:3]\n",
    "    pos_max = dataset.action_normalizer.max_val[:3]\n",
    "    norm_pos = (curr_pos - pos_min) / (pos_max - pos_min) * 2 - 1\n",
    "    \n",
    "    na = torch.zeros((1, 1, 10), device=device, dtype=torch.float32)\n",
    "    na[0, 0, :3] = torch.from_numpy(norm_pos).to(device, dtype=torch.float32)\n",
    "    na[0, 0, 9] = -1 \n",
    "    na_from_prev_chunk = na\n",
    "    \n",
    "    # 缓存变量\n",
    "    cached_grad = torch.zeros_like(na)\n",
    "    cached_scale = 0.0\n",
    "    \n",
    "    done = False\n",
    "    step_idx = 0\n",
    "    max_steps = 400\n",
    "    dt_val = 1.0 / (pred_horizon - obs_horizon)\n",
    "    dt_est = 0.1 # 模拟步长\n",
    "    sigma_infer = 0.05 \n",
    "\n",
    "    print(f\"Running Inference with Accurate Projection...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=max_steps) as pbar:\n",
    "            while not done and step_idx < max_steps:\n",
    "                obs_seq = np.stack(obs_deque)\n",
    "                nobs = dataset.obs_normalizer.normalize(obs_seq)\n",
    "                o_test = torch.from_numpy(nobs).to(device, dtype=torch.float32).flatten().unsqueeze(0)\n",
    "                \n",
    "                na = na_from_prev_chunk\n",
    "                \n",
    "                for i in range(action_horizon):\n",
    "                    t_scalar = np.clip(i * dt_val, 1e-3, 1.0 - 1e-3)\n",
    "\n",
    "                    # --- 1. TEG 计算 ---\n",
    "                    curr_action_phys = dataset.get_unnormalized_action(na) \n",
    "                    curr_xyz = torch.tensor(curr_action_phys[0,0,:3], device=device, dtype=torch.float32)\n",
    "                    dist_to_obs = torch.norm(curr_xyz - obs_phys_tensor).item()\n",
    "                    \n",
    "                    # 判断是否需要重新计算梯度 (距离近 + 间隔步数到了)\n",
    "                    should_compute = (dist_to_obs < activation_dist) and (step_idx % update_interval == 0)\n",
    "                    \n",
    "                    if should_compute:\n",
    "                        # === [核心补全] STEG 梯度计算 ===\n",
    "                        with torch.enable_grad():\n",
    "                            # 1. 准备梯度输入\n",
    "                            na_in = na.squeeze(1).detach().requires_grad_(True)\n",
    "                            \n",
    "                            # 2. 扩展 Batch 进行并行模拟\n",
    "                            na_ens = na_in.repeat(N_ensemble, 1) \n",
    "                            # 确保时间是 float32\n",
    "                            t_ens = torch.tensor([t_scalar], device=device, dtype=torch.float32).repeat(N_ensemble)\n",
    "                            cond_ens = o_test.repeat(N_ensemble, 1)\n",
    "                            \n",
    "                            curr_na_sim = na_ens\n",
    "                            curr_t_sim = t_ens\n",
    "                            cum_cost = torch.zeros(N_ensemble, device=device, dtype=torch.float32)\n",
    "                            \n",
    "                            # 3. 向前模拟循环 (Rollout)\n",
    "                            for k_step in range(K_horizon):\n",
    "                                t_input = torch.clamp(curr_t_sim, 0.05, 0.95)\n",
    "                                \n",
    "                                # 网络预测\n",
    "                                v_p = ema_si_velocity_net(curr_na_sim.unsqueeze(1), t_input, cond_ens).squeeze(1)\n",
    "                                eta_p = ema_si_denoiser_net(curr_na_sim.unsqueeze(1), t_input, cond_ens).squeeze(1)\n",
    "                                \n",
    "                                # 计算系数\n",
    "                                gamma = gamma_t_si(t_input).view(-1, 1)\n",
    "                                g_dot = d_gamma_dt_si(t_input).view(-1, 1)\n",
    "                                s_p = -eta_p / (gamma + 1e-6)\n",
    "                                sigma_est = 0.05 \n",
    "                                score_coeff = 0.5 * (sigma_est**2) - (gamma * g_dot)\n",
    "                                b_drift = v_p + score_coeff * s_p\n",
    "                                \n",
    "                                # --- 物理空间 Cost 计算 ---\n",
    "                                # 准备归一化参数 (转为 Tensor float32)\n",
    "                                min_v = torch.from_numpy(dataset.action_normalizer.min_val).to(device, dtype=torch.float32)\n",
    "                                max_v = torch.from_numpy(dataset.action_normalizer.max_val).to(device, dtype=torch.float32)\n",
    "                                scale_v = max_v - min_v\n",
    "                                scale_v[scale_v==0] = 1.0\n",
    "                                \n",
    "                                # 可微反归一化 (Differentiable Denormalization)\n",
    "                                denorm_sim = ((curr_na_sim + 1) / 2) * scale_v + min_v\n",
    "                                sim_xyz = denorm_sim[:, :3] # 只取 XYZ 位置\n",
    "                                \n",
    "                                # 计算与障碍物的距离 Cost (高斯排斥)\n",
    "                                dist_sq = ((sim_xyz - obs_phys_tensor)**2).sum(dim=-1)\n",
    "                                cost_step = torch.exp(-dist_sq / (2 * 0.05**2)) # 0.05 是障碍物半径参数\n",
    "                                cum_cost = cum_cost + cost_step * dt_est\n",
    "                                \n",
    "                                # Euler 更新模拟状态\n",
    "                                curr_na_sim = curr_na_sim + b_drift * dt_est\n",
    "                                curr_t_sim = curr_t_sim + dt_est\n",
    "                                \n",
    "                            # 4. 反向传播求梯度\n",
    "                            neg_cost = -cum_cost\n",
    "                            log_utility = torch.logsumexp(neg_cost, dim=0)\n",
    "                            \n",
    "                            (g,) = torch.autograd.grad(log_utility, na_in)\n",
    "                            \n",
    "                            # 更新缓存的梯度\n",
    "                            cached_grad = g.unsqueeze(1).detach()\n",
    "                            \n",
    "                        # 更新引导强度\n",
    "                        cached_scale = guidance_scale * max(0, (1.0 - dist_to_obs / activation_dist))\n",
    "                        # print(cached_scale)\n",
    "                    \n",
    "                    elif dist_to_obs >= activation_dist:\n",
    "                        # 距离远时，清空梯度和强度\n",
    "                        cached_scale = 0.0\n",
    "                        cached_grad = torch.zeros_like(na)\n",
    "\n",
    "                    # --- 2. SSIP Update (Base Policy + Guidance) ---\n",
    "                    t = torch.tensor([t_scalar], device=device, dtype=torch.float32)\n",
    "                    b_drift_base = get_drift(na, t, o_test, sigma_infer)\n",
    "                    \n",
    "                    # 叠加 cached_grad\n",
    "                    total_drift = b_drift_base + cached_scale * cached_grad\n",
    "                    \n",
    "                    noise = torch.randn_like(na)\n",
    "                    na = na + total_drift * dt_val + sigma_infer * math.sqrt(dt_val) * noise\n",
    "                    \n",
    "                    # --- 3. Step & Render ---\n",
    "                    a_real = dataset.get_unnormalized_action(na).squeeze()\n",
    "                    obs, reward, done, _ = wrapper.step(a_real)\n",
    "                    obs_deque.append(obs)\n",
    "                    rewards.append(reward)\n",
    "                    \n",
    "                    img_rgb = wrapper.render().copy()\n",
    "                    \n",
    "                    # ---------------------------------------------------------\n",
    "                    # 4. 可视化绘制 (增强版: 投影、连线 + 红框警告)\n",
    "                    # ---------------------------------------------------------\n",
    "                    if img_rgb.shape[0] > 64:\n",
    "                        h, w = img_rgb.shape[:2]\n",
    "                        sim_obj = getattr(wrapper, 'sim', None) \n",
    "                        \n",
    "                        if sim_obj:\n",
    "                            # --- A. 准备 3D 坐标 ---\n",
    "                            pos_obs_3d = obstacle_pos_phys\n",
    "                            \n",
    "                            # 障碍物在桌面的投影点 (利用已知的 table_z = 0.8)\n",
    "                            table_z = 0.8\n",
    "                            pos_obs_ground_3d = pos_obs_3d.copy()\n",
    "                            pos_obs_ground_3d[2] = table_z\n",
    "                            \n",
    "                            pos_agent_3d = curr_xyz.detach().cpu().numpy()\n",
    "\n",
    "                            # --- B. 投影到 2D 像素 ---\n",
    "                            px_obs = world_to_pixel_mujoco(sim_obj, pos_obs_3d, \"agentview\", h, w)\n",
    "                            px_obs_ground = world_to_pixel_mujoco(sim_obj, pos_obs_ground_3d, \"agentview\", h, w)\n",
    "                            px_agent = world_to_pixel_mujoco(sim_obj, pos_agent_3d, \"agentview\", h, w)\n",
    "                            \n",
    "                            # --- C. 绘制辅助线 (垂线 & 距离连线) ---\n",
    "                            if px_obs is not None and px_obs_ground is not None:\n",
    "                                cv2.line(img_rgb, px_obs, px_obs_ground, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "                                cv2.circle(img_rgb, px_obs_ground, 3, (255, 255, 0), 1)\n",
    "\n",
    "                            if px_agent is not None and px_obs is not None:\n",
    "                                # 距离连线\n",
    "                                cv2.line(img_rgb, px_agent, px_obs, (200, 200, 200), 1, cv2.LINE_AA)\n",
    "\n",
    "                            # --- D. 绘制原有元素 ---\n",
    "                            if px_obs is not None:\n",
    "                                cv2.circle(img_rgb, px_obs, 6, (255,0, 255), -1) \n",
    "                                cv2.putText(img_rgb, \"OBS\", (px_obs[0]+8, px_obs[1]), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "                            \n",
    "                            if px_agent is not None and cached_scale > 1e-4:\n",
    "                                cv2.circle(img_rgb, px_agent, 6, (0, 0, 255), -1) \n",
    "                                grad_vec_3d = (cached_grad * cached_scale).detach().cpu().numpy().squeeze()[:3]\n",
    "                                vis_scale = 1.0 \n",
    "                                pos_grad_end_3d = pos_agent_3d + grad_vec_3d * vis_scale\n",
    "                                px_grad_end = world_to_pixel_mujoco(sim_obj, pos_grad_end_3d, \"agentview\", h, w)\n",
    "                                if px_grad_end is not None:\n",
    "                                    cv2.arrowedLine(img_rgb, px_agent, px_grad_end, (0, 255, 0), 2, tipLength=0.3)\n",
    "                        \n",
    "                        # --- E. [新功能] 碰撞/接近 动态红框逻辑 ---\n",
    "                        # 阈值设定 (米)\n",
    "                        COLLISION_DIST = 0.04  \n",
    "                        WARNING_DIST = 0.10   \n",
    "\n",
    "                        if dist_to_obs < WARNING_DIST:\n",
    "                            # 计算严重程度 (0.0 到 1.0)\n",
    "                            # dist_to_obs 越小，severity 越大\n",
    "                            severity = (WARNING_DIST - dist_to_obs) / (WARNING_DIST - COLLISION_DIST)\n",
    "                            severity = np.clip(severity, 0.0, 1.0)\n",
    "                            \n",
    "                            # 1. 颜色计算: 从深红 (0,0,50) 到 亮红 (0,0,255)\n",
    "                            # OpenCV 使用 BGR\n",
    "                            red_val = int(50 + 205 * severity)\n",
    "                            border_color = (0, 0, red_val)\n",
    "                            \n",
    "                            # 2. 宽度计算: 从 2px 到 15px\n",
    "                            thickness = int(2 + 13 * severity)\n",
    "                            \n",
    "                            # 3. 画框 (覆盖整个图像边缘)\n",
    "                            cv2.rectangle(img_rgb, (0, 0), (w-1, h-1), border_color, thickness)\n",
    "                            \n",
    "                            # 4. 如果真的撞上了 (严重程度 > 0.9)，显示文字提示\n",
    "                            if severity > 0.9:\n",
    "                                text = \"COLLISION!\"\n",
    "                                font_scale = 1.2\n",
    "                                thickness_text = 3\n",
    "                                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness_text)[0]\n",
    "                                text_x = (w - text_size[0]) // 2\n",
    "                                text_y = 50\n",
    "                                cv2.putText(img_rgb, text, (text_x, text_y), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), thickness_text)\n",
    "\n",
    "                    imgs.append(img_rgb)\n",
    "                    step_idx += 1\n",
    "                    pbar.update(1)\n",
    "                    if done or step_idx >= max_steps: break\n",
    "                \n",
    "                na_from_prev_chunk = na\n",
    "                if done: break\n",
    "\n",
    "    print(f\"推理结束! 最高得分: {max(rewards) if rewards else 0}\")\n",
    "    return imgs\n",
    "\n",
    "# =========================================================\n",
    "# 3. 运行示例\n",
    "# =========================================================\n",
    "\n",
    "# 定义一个虚拟障碍物位置 (悬浮在方块上方)\n",
    "obstacle_pos = np.array([0.03, 0.0, 0.93]) \n",
    "\n",
    "# 运行推理 (调用新的函数名)\n",
    "imgs_teg = run_ssip_teg_inference_accurate_vis(\n",
    "    obstacle_pos_phys=obstacle_pos,\n",
    "    guidance_scale=1.0,   \n",
    "    activation_dist=0.5, \n",
    "    N_ensemble=16,         \n",
    "    update_interval=4,\n",
    "    K_horizon=3          \n",
    ")\n",
    "\n",
    "imageio.mimsave(\"eval_ssip_teg_accurate_vis.gif\", imgs_teg, fps=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
