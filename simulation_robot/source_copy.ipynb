{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming flow policy in the Push-T environment\n",
    "```{note}\n",
    "*This notebook is adapted from [Diffusion policy's Colab notebook](https://colab.research.google.com/drive/1gxdkgRVfM55zihY9TFLja97cSVZOZq2B?usp=sharing) with an implementation of [Streaming flow policy](https://streaming-flow-policy.github.io/).*\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "VrX4VTl5pYNq",
    "outputId": "f36bee18-3a67-4f2b-db14-e5472f8ed2ef"
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import collections\n",
    "from dataclasses import dataclass\n",
    "import gdown\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Literal, Sequence, Tuple, Union\n",
    "\n",
    "# Imports for diffusion policy\n",
    "import zarr\n",
    "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "\n",
    "# Imports for the Push-T environment\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pygame\n",
    "import pymunk\n",
    "import pymunk.pygame_util\n",
    "from pymunk.space_debug_draw_options import SpaceDebugColor\n",
    "from pymunk.vec2d import Vec2d\n",
    "import shapely.geometry as sg\n",
    "import cv2\n",
    "import skimage.transform as st\n",
    "import jupyviz as jviz\n",
    "\n",
    "# always call this first\n",
    "from streaming_flow_policy.all import set_random_seed\n",
    "set_random_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robomimic Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "from robomimic.envs.env_robosuite import EnvRobosuite\n",
    "\n",
    "class RobomimicLowdimWrapper(gym.Env):\n",
    "    def __init__(self, \n",
    "        env: EnvRobosuite,\n",
    "        obs_keys: List[str]=[\n",
    "            'object', \n",
    "            'robot0_eef_pos', \n",
    "            'robot0_eef_quat', \n",
    "            'robot0_gripper_qpos'],\n",
    "        init_state: Optional[np.ndarray]=None,\n",
    "        render_hw=(256,256),\n",
    "        render_camera_name='agentview'\n",
    "        ):\n",
    "\n",
    "        self.env = env\n",
    "        self.obs_keys = obs_keys\n",
    "        self.init_state = init_state\n",
    "        self.render_hw = render_hw\n",
    "        self.render_camera_name = render_camera_name\n",
    "        self.seed_state_map = dict()\n",
    "        self._seed = None\n",
    "        \n",
    "        # setup spaces\n",
    "        low = np.full(env.action_dimension, fill_value=-1)\n",
    "        high = np.full(env.action_dimension, fill_value=1)\n",
    "        self.action_space = Box(\n",
    "            low=low,\n",
    "            high=high,\n",
    "            shape=low.shape,\n",
    "            dtype=low.dtype\n",
    "        )\n",
    "        obs_example = self.get_observation()\n",
    "        low = np.full_like(obs_example, fill_value=-1)\n",
    "        high = np.full_like(obs_example, fill_value=1)\n",
    "        self.observation_space = Box(\n",
    "            low=low,\n",
    "            high=high,\n",
    "            shape=low.shape,\n",
    "            dtype=low.dtype\n",
    "        )\n",
    "\n",
    "    def get_observation(self):\n",
    "        raw_obs = self.env.get_observation()\n",
    "        obs = np.concatenate([\n",
    "            raw_obs[key] for key in self.obs_keys\n",
    "        ], axis=0)\n",
    "        return obs\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed=seed)\n",
    "        self._seed = seed\n",
    "    \n",
    "    def reset(self):\n",
    "        if self.init_state is not None:\n",
    "            # always reset to the same state\n",
    "            # to be compatible with gym\n",
    "            self.env.reset_to({'states': self.init_state})\n",
    "        elif self._seed is not None:\n",
    "            # reset to a specific seed\n",
    "            seed = self._seed\n",
    "            if seed in self.seed_state_map:\n",
    "                # env.reset is expensive, use cache\n",
    "                self.env.reset_to({'states': self.seed_state_map[seed]})\n",
    "            else:\n",
    "                # robosuite's initializes all use numpy global random state\n",
    "                np.random.seed(seed=seed)\n",
    "                self.env.reset()\n",
    "                state = self.env.get_state()['states']\n",
    "                self.seed_state_map[seed] = state\n",
    "            self._seed = None\n",
    "        else:\n",
    "            # random reset\n",
    "            self.env.reset()\n",
    "\n",
    "        # return obs\n",
    "        obs = self.get_observation()\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        raw_obs, reward, done, info = self.env.step(action)\n",
    "        obs = np.concatenate([\n",
    "            raw_obs[key] for key in self.obs_keys\n",
    "        ], axis=0)\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def render(self, mode='rgb_array'):\n",
    "        h, w = self.render_hw\n",
    "        return self.env.render(mode=mode, \n",
    "            height=h, width=w, \n",
    "            camera_name=self.render_camera_name)\n",
    "\n",
    "\n",
    "def test():\n",
    "    import robomimic.utils.file_utils as FileUtils\n",
    "    import robomimic.utils.env_utils as EnvUtils\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    dataset_path = '/home/cchi/dev/diffusion_policy/data/robomimic/datasets/square/ph/low_dim.hdf5'\n",
    "    env_meta = FileUtils.get_env_metadata_from_dataset(\n",
    "        dataset_path)\n",
    "\n",
    "    env = EnvUtils.create_env_from_metadata(\n",
    "        env_meta=env_meta,\n",
    "        render=False, \n",
    "        render_offscreen=False,\n",
    "        use_image_obs=False, \n",
    "    )\n",
    "    wrapper = RobomimicLowdimWrapper(\n",
    "        env=env,\n",
    "        obs_keys=[\n",
    "            'object', \n",
    "            'robot0_eef_pos', \n",
    "            'robot0_eef_quat', \n",
    "            'robot0_gripper_qpos'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    states = list()\n",
    "    for _ in range(2):\n",
    "        wrapper.seed(0)\n",
    "        wrapper.reset()\n",
    "        states.append(wrapper.env.get_state()['states'])\n",
    "    assert np.allclose(states[0], states[1])\n",
    "\n",
    "    img = wrapper.render()\n",
    "    plt.imshow(img)\n",
    "    # wrapper.seed()\n",
    "    # states.append(wrapper.env.get_state()['states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 检查输出里是否包含 /home/users/oscar/.mujoco/mujoco210/bin\n",
    "print(os.environ.get('LD_LIBRARY_PATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. 填入你刚才从 Terminal 复制出来的路径\n",
    "# 加上系统默认库路径 /usr/lib/x86_64-linux-gnu 确保万无一失\n",
    "os.environ['LD_LIBRARY_PATH'] = (\n",
    "    \"/home/users/oscar/.mujoco/mujoco210/bin:\"\n",
    "    \"/usr/lib/nvidia:\"\n",
    "    \"/usr/lib/x86_64-linux-gnu:\"\n",
    "    + os.environ.get('LD_LIBRARY_PATH', '')\n",
    ")\n",
    "\n",
    "# 2. 尝试 import\n",
    "try:\n",
    "    import mujoco_py\n",
    "    print(\"导入成功！\")\n",
    "except ImportError as e:\n",
    "    print(f\"仍然报错: {e}\")\n",
    "    print(\"这通常是因为 libglewegl.so 这个文件名不存在。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 替换为你本地的数据集路径\n",
    "dataset_path = '/home/users/oscar/miniconda/envs/sfp/lib/python3.10/site-packages/datasets/lift/phlow_dim_v141.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "id": "VrX4VTl5pYNq",
    "outputId": "f36bee18-3a67-4f2b-db14-e5472f8ed2ef"
   },
   "source": [
    "## **Push-T environment in PyMunk**\n",
    "Here, we define a PyMunk-based `PushTEnv` environment.\n",
    "This implementation is adapted from [Diffusion policy](https://diffusion-policy.cs.columbia.edu/), which in turn is adapted from [Implicit Behavior Cloning](https://implicitbc.github.io/).\n",
    "The goal is to push the gray T-block to its target position and orientation denoted in green.\n",
    "\n",
    "<img src=\"./pusht.png\" width=\"256px\" style=\"display: block; margin-left: auto; margin-right: auto;\" class=\"centered\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "L5E-nR6ornyg",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "positive_y_is_up: bool = False\n",
    "\"\"\"Make increasing values of y point upwards.\n",
    "\n",
    "When True::            When False::\n",
    "\n",
    "    y                   +------ > x\n",
    "    ^                   |\n",
    "    |      . (3, 3)     |   . (2, 2)\n",
    "    |                   |\n",
    "    |   . (2, 2)        |      . (3, 3)\n",
    "    |                   v\n",
    "    +------ > x         y\n",
    "\"\"\"\n",
    "\n",
    "def to_pygame(p: Tuple[float, float], surface: pygame.Surface) -> Tuple[int, int]:\n",
    "    \"\"\"Convenience method to convert pymunk coordinates to pygame surface\n",
    "    local coordinates.\n",
    "\n",
    "    Note that in case positive_y_is_up is False, this function wont actually do\n",
    "    anything except converting the point to integers.\n",
    "    \"\"\"\n",
    "    if positive_y_is_up:\n",
    "        return round(p[0]), surface.get_height() - round(p[1])\n",
    "    else:\n",
    "        return round(p[0]), round(p[1])\n",
    "\n",
    "\n",
    "def light_color(color: SpaceDebugColor):\n",
    "    color = np.minimum(1.2 * np.float32([color.r, color.g, color.b, color.a]), np.float32([255]))\n",
    "    color = SpaceDebugColor(r=color[0], g=color[1], b=color[2], a=color[3])\n",
    "    return color\n",
    "\n",
    "class DrawOptions(pymunk.SpaceDebugDrawOptions):\n",
    "    def __init__(self, surface: pygame.Surface) -> None:\n",
    "        \"\"\"Draw a pymunk.Space on a pygame.Surface object.\n",
    "\n",
    "        Typical usage::\n",
    "\n",
    "        >>> import pymunk\n",
    "        >>> surface = pygame.Surface((10,10))\n",
    "        >>> space = pymunk.Space()\n",
    "        >>> options = pymunk.pygame_util.DrawOptions(surface)\n",
    "        >>> space.debug_draw(options)\n",
    "\n",
    "        You can control the color of a shape by setting shape.color to the color\n",
    "        you want it drawn in::\n",
    "\n",
    "        >>> c = pymunk.Circle(None, 10)\n",
    "        >>> c.color = pygame.Color(\"pink\")\n",
    "\n",
    "        See pygame_util.demo.py for a full example\n",
    "\n",
    "        Since pygame uses a coordiante system where y points down (in contrast\n",
    "        to many other cases), you either have to make the physics simulation\n",
    "        with Pymunk also behave in that way, or flip everything when you draw.\n",
    "\n",
    "        The easiest is probably to just make the simulation behave the same\n",
    "        way as Pygame does. In that way all coordinates used are in the same\n",
    "        orientation and easy to reason about::\n",
    "\n",
    "        >>> space = pymunk.Space()\n",
    "        >>> space.gravity = (0, -1000)\n",
    "        >>> body = pymunk.Body()\n",
    "        >>> body.position = (0, 0) # will be positioned in the top left corner\n",
    "        >>> space.debug_draw(options)\n",
    "\n",
    "        To flip the drawing its possible to set the module property\n",
    "        :py:data:`positive_y_is_up` to True. Then the pygame drawing will flip\n",
    "        the simulation upside down before drawing::\n",
    "\n",
    "        >>> positive_y_is_up = True\n",
    "        >>> body = pymunk.Body()\n",
    "        >>> body.position = (0, 0)\n",
    "        >>> # Body will be position in bottom left corner\n",
    "\n",
    "        :Parameters:\n",
    "                surface : pygame.Surface\n",
    "                    Surface that the objects will be drawn on\n",
    "        \"\"\"\n",
    "        self.surface = surface\n",
    "        super(DrawOptions, self).__init__()\n",
    "\n",
    "    def draw_circle(\n",
    "        self,\n",
    "        pos: Vec2d,\n",
    "        angle: float,\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        p = to_pygame(pos, self.surface)\n",
    "\n",
    "        pygame.draw.circle(self.surface, fill_color.as_int(), p, round(radius), 0)\n",
    "        pygame.draw.circle(self.surface, light_color(fill_color).as_int(), p, round(radius-4), 0)\n",
    "\n",
    "        circle_edge = pos + Vec2d(radius, 0).rotated(angle)\n",
    "        p2 = to_pygame(circle_edge, self.surface)\n",
    "        line_r = 2 if radius > 20 else 1\n",
    "        # pygame.draw.lines(self.surface, outline_color.as_int(), False, [p, p2], line_r)\n",
    "\n",
    "    def draw_segment(self, a: Vec2d, b: Vec2d, color: SpaceDebugColor) -> None:\n",
    "        p1 = to_pygame(a, self.surface)\n",
    "        p2 = to_pygame(b, self.surface)\n",
    "\n",
    "        pygame.draw.aalines(self.surface, color.as_int(), False, [p1, p2])\n",
    "\n",
    "    def draw_fat_segment(\n",
    "        self,\n",
    "        a: Tuple[float, float],\n",
    "        b: Tuple[float, float],\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        p1 = to_pygame(a, self.surface)\n",
    "        p2 = to_pygame(b, self.surface)\n",
    "\n",
    "        r = round(max(1, radius * 2))\n",
    "        pygame.draw.lines(self.surface, fill_color.as_int(), False, [p1, p2], r)\n",
    "        if r > 2:\n",
    "            orthog = [abs(p2[1] - p1[1]), abs(p2[0] - p1[0])]\n",
    "            if orthog[0] == 0 and orthog[1] == 0:\n",
    "                return\n",
    "            scale = radius / (orthog[0] * orthog[0] + orthog[1] * orthog[1]) ** 0.5\n",
    "            orthog[0] = round(orthog[0] * scale)\n",
    "            orthog[1] = round(orthog[1] * scale)\n",
    "            points = [\n",
    "                (p1[0] - orthog[0], p1[1] - orthog[1]),\n",
    "                (p1[0] + orthog[0], p1[1] + orthog[1]),\n",
    "                (p2[0] + orthog[0], p2[1] + orthog[1]),\n",
    "                (p2[0] - orthog[0], p2[1] - orthog[1]),\n",
    "            ]\n",
    "            pygame.draw.polygon(self.surface, fill_color.as_int(), points)\n",
    "            pygame.draw.circle(\n",
    "                self.surface,\n",
    "                fill_color.as_int(),\n",
    "                (round(p1[0]), round(p1[1])),\n",
    "                round(radius),\n",
    "            )\n",
    "            pygame.draw.circle(\n",
    "                self.surface,\n",
    "                fill_color.as_int(),\n",
    "                (round(p2[0]), round(p2[1])),\n",
    "                round(radius),\n",
    "            )\n",
    "\n",
    "    def draw_polygon(\n",
    "        self,\n",
    "        verts: Sequence[Tuple[float, float]],\n",
    "        radius: float,\n",
    "        outline_color: SpaceDebugColor,\n",
    "        fill_color: SpaceDebugColor,\n",
    "    ) -> None:\n",
    "        ps = [to_pygame(v, self.surface) for v in verts]\n",
    "        ps += [ps[0]]\n",
    "\n",
    "        radius = 2\n",
    "        pygame.draw.polygon(self.surface, light_color(fill_color).as_int(), ps)\n",
    "\n",
    "        if radius > 0:\n",
    "            for i in range(len(verts)):\n",
    "                a = verts[i]\n",
    "                b = verts[(i + 1) % len(verts)]\n",
    "                self.draw_fat_segment(a, b, radius, fill_color, fill_color)\n",
    "\n",
    "    def draw_dot(\n",
    "        self, size: float, pos: Tuple[float, float], color: SpaceDebugColor\n",
    "    ) -> None:\n",
    "        p = to_pygame(pos, self.surface)\n",
    "        pygame.draw.circle(self.surface, color.as_int(), p, round(size), 0)\n",
    "\n",
    "def pymunk_to_shapely(body, shapes):\n",
    "    geoms = list()\n",
    "    for shape in shapes:\n",
    "        if isinstance(shape, pymunk.shapes.Poly):\n",
    "            verts = [body.local_to_world(v) for v in shape.get_vertices()]\n",
    "            verts += [verts[0]]\n",
    "            geoms.append(sg.Polygon(verts))\n",
    "        else:\n",
    "            raise RuntimeError(f'Unsupported shape type {type(shape)}')\n",
    "    geom = sg.MultiPolygon(geoms)\n",
    "    return geom\n",
    "\n",
    "class PushTEnv(gym.Env):\n",
    "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 10}\n",
    "    reward_range = (0., 1.)\n",
    "\n",
    "    def __init__(self,\n",
    "            legacy=False,\n",
    "            block_cog=None, damping=None,\n",
    "            render_action=True,\n",
    "            render_size=256,  # was previously 96\n",
    "            reset_to_state=None\n",
    "        ):\n",
    "        self._seed = None\n",
    "        self.seed()\n",
    "        self.window_size = ws = 512  # The size of the PyGame window\n",
    "        self.render_size = render_size\n",
    "        self.sim_hz = 100\n",
    "        # Local controller params.\n",
    "        self.k_p, self.k_v = 100, 20    # PD control.z\n",
    "        self.control_hz = self.metadata['video.frames_per_second']\n",
    "        # legcay set_state for data compatiblity\n",
    "        self.legacy = legacy\n",
    "\n",
    "        # agent_pos, block_pos, block_angle\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0,0,0,0,0], dtype=np.float64),\n",
    "            high=np.array([ws,ws,ws,ws,np.pi*2], dtype=np.float64),\n",
    "            shape=(5,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        # positional goal for agent\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([0,0], dtype=np.float64),\n",
    "            high=np.array([ws,ws], dtype=np.float64),\n",
    "            shape=(2,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        self.block_cog = block_cog\n",
    "        self.damping = damping\n",
    "        self.render_action = render_action\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        self.screen = None\n",
    "\n",
    "        self.space = None\n",
    "        self.teleop = None\n",
    "        self.render_buffer = None\n",
    "        self.latest_action = None\n",
    "        self.reset_to_state = reset_to_state\n",
    "\n",
    "    def reset(self):\n",
    "        seed = self._seed\n",
    "        self._setup()\n",
    "        if self.block_cog is not None:\n",
    "            self.block.center_of_gravity = self.block_cog\n",
    "        if self.damping is not None:\n",
    "            self.space.damping = self.damping\n",
    "\n",
    "        # use legacy RandomState for compatiblity\n",
    "        state = self.reset_to_state\n",
    "        if state is None:\n",
    "            rs = np.random.RandomState(seed=seed)\n",
    "            state = np.array([\n",
    "                rs.randint(50, 450), rs.randint(50, 450),\n",
    "                rs.randint(100, 400), rs.randint(100, 400),\n",
    "                rs.randn() * 2 * np.pi - np.pi\n",
    "                ])\n",
    "        self._set_state(state)\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        dt = 1.0 / self.sim_hz\n",
    "        self.n_contact_points = 0\n",
    "        n_steps = self.sim_hz // self.control_hz\n",
    "        if action is not None:\n",
    "            self.latest_action = action\n",
    "            for i in range(n_steps):\n",
    "                # Step PD control.\n",
    "                # self.agent.velocity = self.k_p * (act - self.agent.position)    # P control works too.\n",
    "                acceleration = self.k_p * (action - self.agent.position) + self.k_v * (Vec2d(0, 0) - self.agent.velocity)\n",
    "                self.agent.velocity += acceleration * dt\n",
    "\n",
    "                # Step physics.\n",
    "                self.space.step(dt)\n",
    "\n",
    "        # compute reward\n",
    "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
    "        goal_geom = pymunk_to_shapely(goal_body, self.block.shapes)\n",
    "        block_geom = pymunk_to_shapely(self.block, self.block.shapes)\n",
    "\n",
    "        intersection_area = goal_geom.intersection(block_geom).area\n",
    "        goal_area = goal_geom.area\n",
    "        coverage = intersection_area / goal_area\n",
    "        reward = np.clip(coverage / self.success_threshold, 0, 1)\n",
    "        done = coverage > self.success_threshold\n",
    "        terminated = done\n",
    "        truncated = done\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self, mode=\"rgb_array\"):\n",
    "        return self._render_frame(mode)\n",
    "\n",
    "    def teleop_agent(self):\n",
    "        TeleopAgent = collections.namedtuple('TeleopAgent', ['act'])\n",
    "        def act(obs):\n",
    "            act = None\n",
    "            mouse_position = pymunk.pygame_util.from_pygame(Vec2d(*pygame.mouse.get_pos()), self.screen)\n",
    "            if self.teleop or (mouse_position - self.agent.position).length < 30:\n",
    "                self.teleop = True\n",
    "                act = mouse_position\n",
    "            return act\n",
    "        return TeleopAgent(act)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        obs = np.array(\n",
    "            tuple(self.agent.position) \\\n",
    "            + tuple(self.block.position) \\\n",
    "            + (self.block.angle % (2 * np.pi),))\n",
    "        return obs\n",
    "\n",
    "    def _get_goal_pose_body(self, pose):\n",
    "        mass = 1\n",
    "        inertia = pymunk.moment_for_box(mass, (50, 100))\n",
    "        body = pymunk.Body(mass, inertia)\n",
    "        # preserving the legacy assignment order for compatibility\n",
    "        # the order here dosn't matter somehow, maybe because CoM is aligned with body origin\n",
    "        body.position = pose[:2].tolist()\n",
    "        body.angle = pose[2]\n",
    "        return body\n",
    "\n",
    "    def _get_info(self):\n",
    "        n_steps = self.sim_hz // self.control_hz\n",
    "        n_contact_points_per_step = int(np.ceil(self.n_contact_points / n_steps))\n",
    "        info = {\n",
    "            'pos_agent': np.array(self.agent.position),\n",
    "            'vel_agent': np.array(self.agent.velocity),\n",
    "            'block_pose': np.array(list(self.block.position) + [self.block.angle]),\n",
    "            'goal_pose': self.goal_pose,\n",
    "            'n_contacts': n_contact_points_per_step}\n",
    "        return info\n",
    "\n",
    "    def _render_frame(self, mode):\n",
    "\n",
    "        if self.window is None and mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "        if self.clock is None and mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        self.screen = canvas\n",
    "\n",
    "        draw_options = DrawOptions(canvas)\n",
    "\n",
    "        # Draw goal pose.\n",
    "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
    "        for shape in self.block.shapes:\n",
    "            goal_points = [pymunk.pygame_util.to_pygame(goal_body.local_to_world(v), draw_options.surface) for v in shape.get_vertices()]\n",
    "            goal_points += [goal_points[0]]\n",
    "            pygame.draw.polygon(canvas, self.goal_color, goal_points)\n",
    "\n",
    "        # Draw agent and block.\n",
    "        self.space.debug_draw(draw_options)\n",
    "\n",
    "        if mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # the clock is aleady ticked during in step for \"human\"\n",
    "\n",
    "        img = np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    "        img = cv2.resize(img, (self.render_size, self.render_size))\n",
    "        if self.render_action:\n",
    "            if self.render_action and (self.latest_action is not None):\n",
    "                action = np.array(self.latest_action)\n",
    "                coord = (action / self.window_size * self.render_size).astype(np.int32)\n",
    "                marker_size = int(8 /96 *self.render_size)\n",
    "                thickness = int(1 / 96 * self.render_size)\n",
    "                cv2.drawMarker(img, coord,\n",
    "                    color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
    "                    markerSize=marker_size, thickness=thickness)\n",
    "        return img\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(0,25536)\n",
    "        self._seed = seed\n",
    "        self.np_random = np.random.default_rng(seed)\n",
    "\n",
    "    def _handle_collision(self, arbiter, space, data):\n",
    "        self.n_contact_points += len(arbiter.contact_point_set.points)\n",
    "\n",
    "    def _set_state(self, state):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = state.tolist()\n",
    "        pos_agent = state[:2]\n",
    "        pos_block = state[2:4]\n",
    "        rot_block = state[4]\n",
    "        self.agent.position = pos_agent\n",
    "        # setting angle rotates with respect to center of mass\n",
    "        # therefore will modify the geometric position\n",
    "        # if not the same as CoM\n",
    "        # therefore should be modified first.\n",
    "        if self.legacy:\n",
    "            # for compatiblity with legacy data\n",
    "            self.block.position = pos_block\n",
    "            self.block.angle = rot_block\n",
    "        else:\n",
    "            self.block.angle = rot_block\n",
    "            self.block.position = pos_block\n",
    "\n",
    "        # Run physics to take effect\n",
    "        self.space.step(1.0 / self.sim_hz)\n",
    "\n",
    "    def _set_state_local(self, state_local):\n",
    "        agent_pos_local = state_local[:2]\n",
    "        block_pose_local = state_local[2:]\n",
    "        tf_img_obj = st.AffineTransform(\n",
    "            translation=self.goal_pose[:2],\n",
    "            rotation=self.goal_pose[2])\n",
    "        tf_obj_new = st.AffineTransform(\n",
    "            translation=block_pose_local[:2],\n",
    "            rotation=block_pose_local[2]\n",
    "        )\n",
    "        tf_img_new = st.AffineTransform(\n",
    "            matrix=tf_img_obj.params @ tf_obj_new.params\n",
    "        )\n",
    "        agent_pos_new = tf_img_new(agent_pos_local)\n",
    "        new_state = np.array(\n",
    "            list(agent_pos_new[0]) + list(tf_img_new.translation) \\\n",
    "                + [tf_img_new.rotation])\n",
    "        self._set_state(new_state)\n",
    "        return new_state\n",
    "\n",
    "    def _setup(self):\n",
    "        self.space = pymunk.Space()\n",
    "        self.space.gravity = 0, 0\n",
    "        self.space.damping = 0\n",
    "        self.teleop = False\n",
    "        self.render_buffer = list()\n",
    "\n",
    "        # Add walls.\n",
    "        walls = [\n",
    "            self._add_segment((5, 506), (5, 5), 2),\n",
    "            self._add_segment((5, 5), (506, 5), 2),\n",
    "            self._add_segment((506, 5), (506, 506), 2),\n",
    "            self._add_segment((5, 506), (506, 506), 2)\n",
    "        ]\n",
    "        self.space.add(*walls)\n",
    "\n",
    "        # Add agent, block, and goal zone.\n",
    "        self.agent = self.add_circle((256, 400), 15)\n",
    "        self.block = self.add_tee((256, 300), 0)\n",
    "        self.goal_color = pygame.Color('LightGreen')\n",
    "        self.goal_pose = np.array([256,256,np.pi/4])  # x, y, theta (in radians)\n",
    "\n",
    "        # Add collision handling\n",
    "        self.space.on_collision(0, 0, post_solve=self._handle_collision)\n",
    "\n",
    "        self.n_contact_points = 0\n",
    "        self.max_score = 50 * 100\n",
    "        self.success_threshold = 0.95    # 95% coverage.\n",
    "\n",
    "    def _add_segment(self, a, b, radius):\n",
    "        shape = pymunk.Segment(self.space.static_body, a, b, radius)\n",
    "        shape.color = pygame.Color('LightGray')    # https://htmlcolorcodes.com/color-names\n",
    "        return shape\n",
    "\n",
    "    def add_circle(self, position, radius):\n",
    "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
    "        body.position = position\n",
    "        body.friction = 1\n",
    "        shape = pymunk.Circle(body, radius)\n",
    "        shape.color = pygame.Color('RoyalBlue')\n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "\n",
    "    def add_box(self, position, height, width):\n",
    "        mass = 1\n",
    "        inertia = pymunk.moment_for_box(mass, (height, width))\n",
    "        body = pymunk.Body(mass, inertia)\n",
    "        body.position = position\n",
    "        shape = pymunk.Poly.create_box(body, (height, width))\n",
    "        shape.color = pygame.Color('LightSlateGray')\n",
    "        self.space.add(body, shape)\n",
    "        return body\n",
    "\n",
    "    def add_tee(self, position, angle, scale=30, color='LightSlateGray', mask=pymunk.ShapeFilter.ALL_MASKS()):\n",
    "        mass = 1\n",
    "        length = 4\n",
    "        vertices1 = [(-length*scale/2, scale),\n",
    "                                 ( length*scale/2, scale),\n",
    "                                 ( length*scale/2, 0),\n",
    "                                 (-length*scale/2, 0)]\n",
    "        inertia1 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
    "        vertices2 = [(-scale/2, scale),\n",
    "                                 (-scale/2, length*scale),\n",
    "                                 ( scale/2, length*scale),\n",
    "                                 ( scale/2, scale)]\n",
    "        inertia2 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
    "        body = pymunk.Body(mass, inertia1 + inertia2)\n",
    "        shape1 = pymunk.Poly(body, vertices1)\n",
    "        shape2 = pymunk.Poly(body, vertices2)\n",
    "        shape1.color = pygame.Color(color)\n",
    "        shape2.color = pygame.Color(color)\n",
    "        shape1.filter = pymunk.ShapeFilter(mask=mask)\n",
    "        shape2.filter = pymunk.ShapeFilter(mask=mask)\n",
    "        body.center_of_gravity = (shape1.center_of_gravity + shape2.center_of_gravity) / 2\n",
    "        body.position = position\n",
    "        body.angle = angle\n",
    "        body.friction = 1\n",
    "        self.space.add(body, shape1, shape2)\n",
    "        return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PushTEnv` follows the standard OpenAI Gym API (0.21.0). Here's an illustration of the basic API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "OknH8Qfqrtc9"
   },
   "outputs": [],
   "source": [
    "# 0. create env object\n",
    "env = PushTEnv()\n",
    "\n",
    "# 1. Seed env for initial state.\n",
    "# Seed 0-200 are used for the demonstration dataset.\n",
    "env.seed(500)\n",
    "\n",
    "# 2. Must reset before starting each episode.\n",
    "obs, info = env.reset()\n",
    "\n",
    "# 3. 2D positional action space [0, 512].\n",
    "action = env.action_space.sample()\n",
    "\n",
    "# 4. Stepping through environment dynamics with standard OpenAI Gym API.\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "# 5. Render the environment.\n",
    "img = env.render()  # (256, 256, 3) RGB image\n",
    "jviz.img(img).html(title='Push-T render after reset').display()\n",
    "\n",
    "# prints and explains each dimension of the observation and action vectors\n",
    "with np.printoptions(precision=4, suppress=True, threshold=5):\n",
    "    print(\"Observ: \", repr(obs))\n",
    "    print(\"               [agent_x,  agent_y,  block_x,  block_y,    block_angle]\")\n",
    "    print(\"Action: \", repr(action) + \" ⟺ [target_agent_x, target_agent_y]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldarMQqvvEBZ"
   },
   "source": [
    "## **Demonstration dataset $/$ dataloader**\n",
    "\n",
    "Defines the `PushTDataset` (a subclass of `torch.utils.data.Dataset`) and helper functions.\n",
    "\n",
    "The dataset class:\n",
    "- Load episodes i.e. sequences of (observation, action) tuples from a zarr storage.\n",
    "- Normalizes each dimension of observation and action to [-1,1].\n",
    "- Returns: All possible segments of length `pred_horizon`. It also pads the beginning and the end of each episode with repetition, so that each timestep has a fixed number of observation length and action length.\n",
    "A dictionary is returned with the following signature:\n",
    "    ```python\n",
    "    {\n",
    "        \"obs\": torch.Tensor of shape (`obs_horizon`, `obs_dim`),\n",
    "        \"action\": torch.Tensor of shape (`pred_horizon`, `action_dim`)\n",
    "    }\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "vHepJOFBucwg",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SequencePointer:\n",
    "    \"\"\"\n",
    "    Container for sample extraction pointers.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"Starting index in the original data buffer to begin extraction.\"\"\"\n",
    "    buffer_start_idx: int\n",
    "\n",
    "    \"\"\"Ending index in the original data buffer (exclusive) for extraction.\"\"\"\n",
    "    buffer_end_idx: int\n",
    "    \n",
    "    \"\"\"Starting index within the padded sample.\"\"\"\n",
    "    sample_start_idx: int\n",
    "    \n",
    "    \"\"\"Ending index within the padded sample.\"\"\"\n",
    "    sample_end_idx: int\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Allow unpacking: buffer_start, buffer_end, sample_start, sample_end = indices\"\"\"\n",
    "        return iter([self.buffer_start_idx, self.buffer_end_idx, \n",
    "                     self.sample_start_idx, self.sample_end_idx])\n",
    "\n",
    "def create_sequence_pointers(\n",
    "        episode_ends: np.ndarray, sequence_length: int,\n",
    "        pad_before: int=0, pad_after: int=0,\n",
    "    ) -> List[SequencePointer]:\n",
    "    \"\"\"\n",
    "    Create sample indices for extracting sequences from episode data with padding support.\n",
    "    \n",
    "    This function generates indices for extracting fixed-length sequences from a dataset\n",
    "    composed of multiple episodes. It handles padding at the beginning and end of episodes\n",
    "    to ensure all timesteps can be used as starting points for sequences, even near episode\n",
    "    boundaries.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    episode_ends : (np.ndarray, shape=(E,))\n",
    "        Array containing the end indices (one-past-the-last) for each episode.\n",
    "        For example, if episodes have lengths [10, 15, 8], then episode_ends = [10, 25, 33].\n",
    "    sequence_length : int\n",
    "        Length of the sequences to extract from the dataset.\n",
    "    pad_before : int, default=0\n",
    "        Number of timesteps to pad before the episode start. This allows sequences\n",
    "        to start before the actual episode data by repeating the first values of all data keys.\n",
    "    pad_after : int, default=0\n",
    "        Number of timesteps to pad after the episode end. This allows sequences\n",
    "        to extend beyond the actual episode data by repeating the last values of all data keys.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[SequencePointer]\n",
    "        List of SequencePointer objects for extracting sequences from all episodes.\n",
    "        Can be converted to numpy array using np.array(indices) for compatibility.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The function handles episode boundaries by:\n",
    "    1. Computing valid start positions for sequences within each episode.\n",
    "    2. Accounting for padding requirements at episode boundaries.\n",
    "    3. Returning indices that can be used to extract properly padded sequences.\n",
    "    \n",
    "    The returned indices are designed to work with a sampling function that can\n",
    "    handle the padding by repeating boundary values when accessing out-of-bounds indices.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> episode_ends = np.array([10, 25, 33])  # 3 episodes of lengths 10, 15, 8\n",
    "    >>> indices = create_sample_indices(episode_ends, sequence_length=5, pad_before=2, pad_after=1)\n",
    "    >>> # Returns list of SequencePointer objects for all possible 5-step sequences\n",
    "    \"\"\"\n",
    "    indices = list()\n",
    "    for i in range(len(episode_ends)):\n",
    "        start_idx = 0\n",
    "        if i > 0:\n",
    "            start_idx = episode_ends[i-1]\n",
    "        end_idx = episode_ends[i]\n",
    "        episode_length = end_idx - start_idx\n",
    "\n",
    "        min_start = -pad_before\n",
    "        max_start = episode_length - sequence_length + pad_after\n",
    "\n",
    "        # range stops one idx before end\n",
    "        for idx in range(min_start, max_start+1):\n",
    "            buffer_start_idx = max(idx, 0) + start_idx\n",
    "            buffer_end_idx = min(idx+sequence_length, episode_length) + start_idx\n",
    "            start_offset = buffer_start_idx - (idx+start_idx)\n",
    "            end_offset = (idx+sequence_length+start_idx) - buffer_end_idx\n",
    "            sample_start_idx = 0 + start_offset\n",
    "            sample_end_idx = sequence_length - end_offset\n",
    "            indices.append(SequencePointer(\n",
    "                buffer_start_idx,\n",
    "                buffer_end_idx,\n",
    "                sample_start_idx,\n",
    "                sample_end_idx,\n",
    "            ))\n",
    "    return indices\n",
    "\n",
    "def extract_sequence(train_data, sequence_length, ptr: SequencePointer):\n",
    "    \"\"\"\n",
    "    Extract and pad a sequence from training data using specified indices.\n",
    "    \n",
    "    This function extracts a sequence from the training data buffer and applies padding\n",
    "    if necessary to ensure the output has the exact sequence_length. Padding is applied\n",
    "    by repeating boundary values when the sequence extends beyond the available data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : dict\n",
    "        Dictionary containing training data arrays. Each key maps to a numpy array\n",
    "        of shape (N, feature_dim) where N is the total number of timesteps.\n",
    "        Common keys include 'action' and 'obs' (observations).\n",
    "    sequence_length : int\n",
    "        Desired length of the output sequence. All returned arrays will have\n",
    "        this length in the first dimension.\n",
    "    ptr : SequencePointer\n",
    "        Container of sequence pointer indices for extracting and placing the\n",
    "        sequence data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with the same keys as train_data, where each value is a numpy array\n",
    "        of shape (sequence_length, feature_dim). The arrays contain the extracted data\n",
    "        with appropriate padding applied.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The function handles three cases:\n",
    "    1. No padding needed: When sample_start_idx=0 and sample_end_idx=sequence_length,\n",
    "       the extracted data is returned as-is.\n",
    "    2. Start padding: When sample_start_idx > 0, the first sample_start_idx positions\n",
    "       are filled with the first value of the extracted sample.\n",
    "    3. End padding: When sample_end_idx < sequence_length, positions from sample_end_idx\n",
    "       to sequence_length are filled with the last value of the extracted sample.\n",
    "    \n",
    "    This function is typically used with indices generated by create_sample_indices()\n",
    "    to handle episode boundaries and ensure consistent sequence lengths for training.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> train_data = {'action': np.array([[1], [2], [3], [4], [5]]), \n",
    "    ...               'obs': np.array([[0.1], [0.2], [0.3], [0.4], [0.5]])}\n",
    "    >>> indices = SampleIndices(buffer_start_idx=1, buffer_end_idx=4,\n",
    "    ...                         sample_start_idx=2, sample_end_idx=5)\n",
    "    >>> result = sample_sequence(train_data, sequence_length=6, indices)\n",
    "    >>> # Extracts [2,3,4] from buffer indices 1:4, but places them at positions 2:5\n",
    "    >>> # result['action'] = [[2], [2], [2], [3], [4], [4]]  # padded at start and end\n",
    "    >>> # result['obs'] = [[0.2], [0.2], [0.2], [0.3], [0.4], [0.4]]  # same padding pattern\n",
    "    \"\"\"\n",
    "    result = dict()\n",
    "    for key, input_arr in train_data.items():\n",
    "        sample = input_arr[ptr.buffer_start_idx:ptr.buffer_end_idx]\n",
    "        data = sample\n",
    "        if (ptr.sample_start_idx > 0) or (ptr.sample_end_idx < sequence_length):\n",
    "            data = np.zeros(\n",
    "                shape=(sequence_length,) + input_arr.shape[1:],\n",
    "                dtype=input_arr.dtype)\n",
    "            if ptr.sample_start_idx > 0:\n",
    "                data[:ptr.sample_start_idx] = sample[0]\n",
    "            if ptr.sample_end_idx < sequence_length:\n",
    "                data[ptr.sample_end_idx:] = sample[-1]\n",
    "            data[ptr.sample_start_idx:ptr.sample_end_idx] = sample\n",
    "        result[key] = data\n",
    "    return result\n",
    "\n",
    "def get_data_stats(data):\n",
    "    data = data.reshape(-1,data.shape[-1])\n",
    "    stats = {\n",
    "        'min': np.min(data, axis=0),\n",
    "        'max': np.max(data, axis=0)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def normalize_data(data, stats):\n",
    "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])  # to [0, 1]\n",
    "    ndata = ndata * 2 - 1  # to [-1, 1]\n",
    "    return ndata\n",
    "\n",
    "def unnormalize_data(ndata, stats):\n",
    "    ndata = (ndata + 1) / 2  # to [0, 1]\n",
    "    data = ndata * (stats['max'] - stats['min']) + stats['min']  # to original\n",
    "    return data\n",
    "\n",
    "class PushTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path,\n",
    "                 pred_horizon, obs_horizon, action_horizon):\n",
    "\n",
    "        # Read from zarr dataset\n",
    "        dataset_root = zarr.open(dataset_path, 'r')\n",
    "        \n",
    "        # All demonstration episodes are concatenated in the first dimension N\n",
    "        train_data = {\n",
    "            'action': dataset_root['data']['action'][:],  # (N, action_dim)\n",
    "            'obs': dataset_root['data']['state'][:],  # (N, obs_dim)\n",
    "        }\n",
    "        # Marks one-past the last index for each episode\n",
    "        episode_ends = dataset_root['meta']['episode_ends'][:]\n",
    "\n",
    "        # |o|o|                             observations: 2\n",
    "        # | |a|a|a|a|a|a|a|a|               actions executed: 8\n",
    "        # |p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
    "\n",
    "        # Compute start and end of each state-action sequence,\n",
    "        # also add padding such that each timestep in the dataset is seen\n",
    "        self.sequence_pointers = create_sequence_pointers(\n",
    "            episode_ends = episode_ends,\n",
    "            sequence_length = pred_horizon,\n",
    "            pad_before = obs_horizon-1,\n",
    "            pad_after = action_horizon-1,\n",
    "        )\n",
    "\n",
    "        # Compute statistics and normalized data to [-1, 1]\n",
    "        stats = dict()\n",
    "        normalized_train_data = dict()\n",
    "        for key, data in train_data.items():\n",
    "            stats[key] = get_data_stats(data)\n",
    "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
    "\n",
    "        self.stats = stats\n",
    "        self.normalized_train_data = normalized_train_data\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.action_horizon = action_horizon\n",
    "        self.obs_horizon = obs_horizon\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Count of all possible segments of the dataset\"\"\"\n",
    "        return len(self.sequence_pointers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the sequence pointer for this datapoint\n",
    "        ptr = self.sequence_pointers[idx]\n",
    "\n",
    "        # Get normalized data using these indices\n",
    "        nsample = extract_sequence(\n",
    "            train_data=self.normalized_train_data,\n",
    "            sequence_length=self.pred_horizon,\n",
    "            ptr=ptr,\n",
    "        )\n",
    "\n",
    "        # discard unused observations\n",
    "        nsample['obs'] = nsample['obs'][:self.obs_horizon,:]\n",
    "        return nsample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PushTDataset` and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download demonstration data from Google Drive\n",
    "dataset_path = \"pusht_cchi_v7_replay.zarr.zip\"\n",
    "if not os.path.isfile(dataset_path):\n",
    "    id = \"1KY1InLurpMvJDRb14L9NlXT_fEsCvVUq&confirm=t\"\n",
    "    gdown.download(id=id, output=dataset_path, quiet=False)\n",
    "\n",
    "# |o|o|                             observations: 2\n",
    "# | |a|a|a|a|a|a|a|a|               actions executed: 8\n",
    "# |p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
    "\n",
    "pred_horizon = 16\n",
    "obs_horizon = 2\n",
    "action_horizon = 8\n",
    "\n",
    "# Create dataset from file\n",
    "dataset = PushTDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    pred_horizon=pred_horizon,\n",
    "    obs_horizon=obs_horizon,\n",
    "    action_horizon=action_horizon,\n",
    ")\n",
    "# Save training data statistics (min, max) for each dim\n",
    "stats = dataset.stats\n",
    "\n",
    "# Create dataloader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    num_workers=1,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,  # accelerate cpu-gpu transfer\n",
    "    persistent_workers=True, # don't kill worker process after each epoch\n",
    ")\n",
    "\n",
    "# Visualize data in batch\n",
    "batch = next(iter(dataloader))\n",
    "print(\"batch['obs'].shape:\", batch['obs'].shape)\n",
    "print(\"batch['action'].shape\", batch['action'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "id": "9ZiHF3lzvB6k"
   },
   "source": [
    "## **Neural network architectures**\n",
    "\n",
    "Defines a 1D UNet architecture `ConditionalUnet1D`\n",
    "as the noies prediction network\n",
    "\n",
    "Components:\n",
    "- `SinusoidalPosEmb` Positional encoding for the diffusion iteration k\n",
    "- `Downsample1d` Strided convolution to reduce temporal resolution\n",
    "- `Upsample1d` Transposed convolution to increase temporal resolution\n",
    "- `Conv1dBlock` Conv1d --> GroupNorm --> Mish\n",
    "- `ConditionalResidualBlock1D` Takes two inputs `x` and `cond`. \\\n",
    "`x` is passed through 2 `Conv1dBlock` stacked together with residual connection.\n",
    "`cond` is applied to `x` with [FiLM](https://arxiv.org/abs/1709.07871) conditioning.\n",
    "\n",
    "### Architecture changes in SFP\n",
    "We are able to **re-use existing diffusion $/$ flow policy architectures** with the following changes:\n",
    "- Add `scale` parameter to `SinusoidalPosEmb`.\n",
    "  - <u>*Reason:*</u> Diffusion policy embeds integer diffusion timesteps on the order of 0 to 100, whereas flow policies use a unit interval $[0, 1]$ for time. For compatibility, we scale the unit interval by 100.\n",
    "- Define the two additional modules `LinearDownsample1d` and `LinearUpsample1d`.\n",
    "  - <u>*Reason:*</u> Diffusion policy diffuses in the space of action *sequences*, which are processed with 1-D convolutions using `ConvUpsample1d` and `ConvDownsample1d`. However, SFP diffuses in the space of *single actions*. Therefore, we introduce a fully-connected upsampler$/$downsampler that acts on single actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "X-XRB_g3vsgf",
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim, scale = 1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.scale = scale # added - SFP\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.scale\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class ConvDownsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class ConvUpsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class LinearDownsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        # Reshape input to (batch_size, -1) for fully connected layer\n",
    "        batch_size, channels, seq_len = x.size()\n",
    "        x = x.view(batch_size, -1)  # flatten spatial dimensions\n",
    "        x = self.linear(x)\n",
    "        x = x.view(batch_size, channels, seq_len)  # reshape back to original dimensions\n",
    "        return x\n",
    "\n",
    "class LinearUpsample1d(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        # Reshape input to (batch_size, -1) for fully connected layer\n",
    "        batch_size, channels, seq_len = x.size()\n",
    "        x = x.view(batch_size, -1)  # flatten spatial dimensions\n",
    "        x = self.linear(x)\n",
    "        x = x.view(batch_size, channels, seq_len)  # reshape back to original dimensions\n",
    "        return x\n",
    "\n",
    "class Conv1dBlock(nn.Module):\n",
    "    '''\n",
    "        Conv1d --> GroupNorm --> Mish\n",
    "    '''\n",
    "\n",
    "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.GroupNorm(n_groups, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class ConditionalResidualBlock1D(nn.Module):\n",
    "    def __init__(self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            cond_dim,\n",
    "            kernel_size=3,\n",
    "            n_groups=8,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "            Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
    "        ])\n",
    "\n",
    "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
    "        # predicts per-channel scale and bias\n",
    "        cond_channels = out_channels * 2\n",
    "        self.out_channels = out_channels\n",
    "        self.cond_encoder = nn.Sequential(\n",
    "            nn.Mish(),\n",
    "            nn.Linear(cond_dim, cond_channels),\n",
    "            nn.Unflatten(-1, (-1, 1))\n",
    "        )\n",
    "\n",
    "        # Ensure dimensions compatible\n",
    "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) \\\n",
    "            if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        '''\n",
    "            x : [ batch_size x in_channels x horizon ]\n",
    "            cond : [ batch_size x cond_dim]\n",
    "\n",
    "            returns:\n",
    "            out : [ batch_size x out_channels x horizon ]\n",
    "        '''\n",
    "        out = self.blocks[0](x)\n",
    "        embed = self.cond_encoder(cond)\n",
    "\n",
    "        embed = embed.reshape(\n",
    "            embed.shape[0], 2, self.out_channels, 1)\n",
    "        scale = embed[:,0,...]\n",
    "        bias = embed[:,1,...]\n",
    "        out = scale * out + bias\n",
    "\n",
    "        out = self.blocks[1](out)\n",
    "        out = out + self.residual_conv(x)\n",
    "        return out\n",
    "\n",
    "class ConditionalUnet1D (nn.Module):\n",
    "    def __init__(self,\n",
    "        input_dim,\n",
    "        global_cond_dim,\n",
    "        updownsample_type: Literal['Conv', 'Linear'],  # added for SFP\n",
    "        sin_embedding_scale,  # added for SFP\n",
    "        diffusion_step_embed_dim=256,\n",
    "        down_dims=[256,512,1024],\n",
    "        kernel_size=5,\n",
    "        n_groups=8,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        input_dim: Dim of actions.\n",
    "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
    "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
    "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
    "        down_dims: Channel size for each UNet level.\n",
    "          The length of this array determines numebr of levels.\n",
    "        kernel_size: Conv kernel size\n",
    "        n_groups: Number of groups for GroupNorm\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        all_dims = [input_dim] + list(down_dims)\n",
    "        start_dim = down_dims[0]\n",
    "\n",
    "        dsed = diffusion_step_embed_dim\n",
    "        diffusion_step_encoder = nn.Sequential(\n",
    "            SinusoidalPosEmb(dsed, scale = sin_embedding_scale), # added - SFP\n",
    "            nn.Linear(dsed, dsed * 4),\n",
    "            nn.Mish(),\n",
    "            nn.Linear(dsed * 4, dsed),\n",
    "        )\n",
    "        cond_dim = dsed + global_cond_dim\n",
    "\n",
    "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
    "        mid_dim = all_dims[-1]\n",
    "        self.mid_modules = nn.ModuleList([\n",
    "            ConditionalResidualBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ),\n",
    "            ConditionalResidualBlock1D(\n",
    "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
    "                kernel_size=kernel_size, n_groups=n_groups\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        down_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            if updownsample_type == 'Linear':  # added for SFP\n",
    "                downsample_layer = LinearDownsample1d(dim_out) if not is_last else nn.Identity() #added\n",
    "            elif updownsample_type == 'Conv':\n",
    "                downsample_layer = ConvDownsample1d(dim_out) if not is_last else nn.Identity()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported updownsample_type: {updownsample_type}\")\n",
    "            down_modules.append(nn.ModuleList([\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_in, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_out, dim_out, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                downsample_layer,\n",
    "            ]))\n",
    "\n",
    "        up_modules = nn.ModuleList([])\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (len(in_out) - 1)\n",
    "            if updownsample_type == 'Linear':  # added for SFP\n",
    "                upsample_layer = LinearUpsample1d(dim_in) if not is_last  else nn.Identity()\n",
    "            elif updownsample_type == 'Conv':\n",
    "                upsample_layer = ConvUpsample1d(dim_in) if not is_last  else nn.Identity()\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported updownsample_type: {updownsample_type}\")\n",
    "            up_modules.append(nn.ModuleList([\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_out*2, dim_in, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                ConditionalResidualBlock1D(\n",
    "                    dim_in, dim_in, cond_dim=cond_dim,\n",
    "                    kernel_size=kernel_size, n_groups=n_groups),\n",
    "                upsample_layer,\n",
    "            ]))\n",
    "\n",
    "        final_conv = nn.Sequential(\n",
    "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
    "            nn.Conv1d(start_dim, input_dim, 1),\n",
    "        )\n",
    "\n",
    "        self.diffusion_step_encoder = diffusion_step_encoder\n",
    "        self.up_modules = up_modules\n",
    "        self.down_modules = down_modules\n",
    "        self.final_conv = final_conv\n",
    "\n",
    "        print(\"Number of parameters: {:e}\".format(\n",
    "            sum(p.numel() for p in self.parameters()))\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "            sample: Tensor,\n",
    "            timestep: Union[Tensor, float, int],\n",
    "            global_cond=None,\n",
    "        ) -> Tensor:\n",
    "        \"\"\"\n",
    "        x: (B,T,input_dim)\n",
    "        timestep: (B,) or int, diffusion step\n",
    "        global_cond: (B,global_cond_dim)\n",
    "        output: (B,T,input_dim)\n",
    "        \"\"\"\n",
    "        # (B,T,C)\n",
    "        sample = sample.moveaxis(-1,-2)\n",
    "        # (B,C,T)\n",
    "\n",
    "        # 1. time\n",
    "        timesteps = timestep\n",
    "        if not torch.is_tensor(timesteps):\n",
    "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
    "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
    "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
    "            timesteps = timesteps[None].to(sample.device)\n",
    "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
    "        timesteps = timesteps.expand(sample.shape[0])\n",
    "\n",
    "        global_feature = self.diffusion_step_encoder(timesteps)\n",
    "\n",
    "        if global_cond is not None:\n",
    "            global_feature = torch.cat([\n",
    "                global_feature, global_cond\n",
    "            ], axis=-1)\n",
    "\n",
    "        x = sample\n",
    "        h = []\n",
    "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        for mid_module in self.mid_modules:\n",
    "            x = mid_module(x, global_feature)\n",
    "\n",
    "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = resnet(x, global_feature)\n",
    "            x = resnet2(x, global_feature)\n",
    "            x = upsample(x)\n",
    "\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        # (B,C,T)\n",
    "        x = x.moveaxis(-1,-2)\n",
    "        # (B,T,C)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "4APZkqh336-M"
   },
   "outputs": [],
   "source": [
    "# Observation and action dimensions corresponding to the output of PushTEnv.\n",
    "obs_horizon = 2\n",
    "obs_dim = 5\n",
    "action_dim = 2\n",
    "\n",
    "# create network object\n",
    "sfp_velocity_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon,\n",
    "    # because SFP diffuses over a single action,\n",
    "    updownsample_type = 'Linear',\n",
    "    # because the original model assumes timesteps of the order of [0, 100]\n",
    "    # but SFP uses a time range of [0, 1]\n",
    "    sin_embedding_scale = 100,\n",
    ")\n",
    "\n",
    "# Example inputs\n",
    "a = torch.randn((1, 1, action_dim)) #changed SFP: action at time t\n",
    "obs = torch.zeros((1, obs_horizon, obs_dim))\n",
    "t = torch.zeros((1,))  # changed SFP: time t\n",
    "\n",
    "# the velocity prediction network\n",
    "# takes noisy action, diffusion iteration and observation as input\n",
    "# predicts the noise added to action\n",
    "with torch.no_grad():\n",
    "    v = sfp_velocity_net(  # changed SFP: predicted velocity at time t\n",
    "        sample=a,\n",
    "        timestep=t,\n",
    "        global_cond=obs.flatten(start_dim=1),\n",
    "    )\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "sfp_velocity_net.to(device)\n",
    "\n",
    "print(f\"Predicted velocity shape: {v.shape}\")\n",
    "print(f\"Predicted velocity values: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Baseline: Diffusion Policy**\n",
    "\n",
    "### Create PyTorch model for diffusion policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network object\n",
    "dp_noise_pred_net = ConditionalUnet1D(\n",
    "    input_dim=action_dim,\n",
    "    global_cond_dim=obs_dim*obs_horizon,\n",
    "    updownsample_type = 'Conv',\n",
    "    sin_embedding_scale = 1,  # original setting\n",
    ")\n",
    "\n",
    "num_diffusion_iters = 100\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=num_diffusion_iters,\n",
    "    # the choise of beta schedule has big impact on performance\n",
    "    # we found squared cosine works the best\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    # clip output to [-1,1] to improve stability\n",
    "    clip_sample=True,\n",
    "    # our network predicts noise (instead of denoised action)\n",
    "    prediction_type='epsilon'\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device('cuda')\n",
    "dp_noise_pred_net.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion policy training loop\n",
    "\n",
    "Takes about 4m 35s on an NVIDIA GeForce RTX 4090.\n",
    "\n",
    "If you don't want to wait, skip to the next cell to load pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema_dp = EMAModel(\n",
    "    parameters=dp_noise_pred_net.parameters(),\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=dp_noise_pred_net.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(dataset) * num_epochs\n",
    ")\n",
    "\n",
    "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
    "    # epoch loop\n",
    "    for epoch_idx in tglobal:\n",
    "        epoch_loss = list()\n",
    "        # batch loop\n",
    "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
    "            for nbatch in tepoch:\n",
    "                # Note that the data is normalized in the dataset.\n",
    "                # Device transfer\n",
    "                nobs = nbatch['obs'].to(device)  # (B, To, O)\n",
    "                naction = nbatch['action'].to(device)  # (B, Tp, A)\n",
    "                B = nobs.shape[0]\n",
    "\n",
    "                # Observation as FiLM conditioning\n",
    "                obs_cond = nobs.flatten(start_dim=1)  # (B, To*O)\n",
    "\n",
    "                # Sample noise to add to actions\n",
    "                noise = torch.randn(naction.shape, device=device)  # (B, Tp, A)\n",
    "\n",
    "                # sample a diffusion iteration for each data point\n",
    "                timesteps = torch.randint(\n",
    "                    0, noise_scheduler.config.num_train_timesteps,\n",
    "                    (B,), device=device\n",
    "                ).long()  # (B,)\n",
    "\n",
    "                # Forward diffusion process: Add noise to the clean images\n",
    "                # according to the noise magnitude at each diffusion iteration.\n",
    "                noisy_actions = noise_scheduler.add_noise(\n",
    "                    naction, noise, timesteps)  # (B, Tp, A)\n",
    "\n",
    "                # Predict the noise residual.\n",
    "                noise_pred = dp_noise_pred_net(\n",
    "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
    "\n",
    "                # L2 loss\n",
    "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
    "\n",
    "                # optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # step lr scheduler every batch\n",
    "                # this is different from standard pytorch behavior\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # update Exponential Moving Average of the model weights\n",
    "                ema_dp.step(dp_noise_pred_net.parameters())\n",
    "\n",
    "                # logging\n",
    "                loss_cpu = loss.item()\n",
    "                epoch_loss.append(loss_cpu)\n",
    "                tepoch.set_postfix(loss=loss_cpu)\n",
    "        tglobal.set_postfix(loss=np.mean(epoch_loss))\n",
    "\n",
    "# Weights of the EMA model\n",
    "# is used for inference\n",
    "ema_noise_pred_net_dp = dp_noise_pred_net\n",
    "ema_dp.copy_to(ema_noise_pred_net_dp.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained checkpoint (optional)\n",
    "Set `load_pretrained = True` to load pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "load_pretrained = True\n",
    "if load_pretrained:\n",
    "  ckpt_path_dp = \"pusht_state_100ep_dp.ckpt\"\n",
    "  if not os.path.isfile(ckpt_path_dp):\n",
    "      id = \"1mHDr_DEZSdiGo9yecL50BBQYzR8Fjhl_&confirm=t\"\n",
    "      gdown.download(id=id, output=ckpt_path_dp, quiet=False)\n",
    "\n",
    "  state_dict_dp = torch.load(ckpt_path_dp, map_location='cuda')\n",
    "  ema_noise_pred_net_dp = dp_noise_pred_net\n",
    "  ema_noise_pred_net_dp.load_state_dict(state_dict_dp)\n",
    "  print('Pretrained weights loaded for diffusion policy.')\n",
    "else:\n",
    "  print(\"Skipped pretrained diffusion policy weight loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion policy: Inference\n",
    "Takes about 6s to roll out 200 steps on an NVIDIA GeForce RTX 4090."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first observation\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Keep a queue of last obs_horizon (i.e. 2) steps of observations\n",
    "obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "\n",
    "# Save visualization and rewards\n",
    "imgs = [env.render()]\n",
    "rewards = list()\n",
    "done = False\n",
    "step_idx = 0\n",
    "\n",
    "max_steps = 200\n",
    "with tqdm(total=max_steps, desc=\"Eval PushTStateEnv [Diffusion Policy]\") as pbar:\n",
    "    while not done:\n",
    "        B = 1\n",
    "        # Stack the last obs_horizon (2) number of observations.\n",
    "        obs = np.stack(obs_deque)\n",
    "        nobs = normalize_data(obs, stats=stats['obs'])  # normalize observation\n",
    "        nobs = torch.from_numpy(nobs).to(device, dtype=torch.float32)  # device transfer\n",
    "\n",
    "        # Infer actions: reverse diffusion process\n",
    "        with torch.no_grad():\n",
    "            obs_cond = nobs.unsqueeze(0).flatten(start_dim=1)  # (B, To * A)\n",
    "\n",
    "            # Initialize action from pure Gaussian noise.\n",
    "            na_traj = torch.randn(\n",
    "                (1, pred_horizon, action_dim), device=device)   # (1, Tp, A)\n",
    "\n",
    "            # Init scheduler\n",
    "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
    "\n",
    "            for k in noise_scheduler.timesteps:\n",
    "                # Predict noise\n",
    "                noise_pred = ema_noise_pred_net_dp(\n",
    "                    sample=na_traj,\n",
    "                    timestep=k,\n",
    "                    global_cond=obs_cond\n",
    "                )\n",
    "\n",
    "                # Reverse diffusion (denoising) step\n",
    "                na_traj = noise_scheduler.step(\n",
    "                    model_output=noise_pred,\n",
    "                    timestep=k,\n",
    "                    sample=na_traj,\n",
    "                ).prev_sample\n",
    "\n",
    "        # Unnormalize action\n",
    "        na_traj = na_traj.detach().to('cpu').numpy()  # (1, Tp, A)\n",
    "        na_traj = na_traj[0]  # (Tp, A)\n",
    "        a_traj = unnormalize_data(na_traj, stats=stats['action'])  # (Tp, A)\n",
    "\n",
    "        # Only take action_horizon number of actions.\n",
    "        start = obs_horizon - 1\n",
    "        end = start + action_horizon\n",
    "        a_traj = a_traj[start:end, :]  # (Ta, A)\n",
    "\n",
    "        # Execute action_horizon number of steps without replanning.\n",
    "        for action in a_traj:\n",
    "            obs, reward, done, _, info = env.step(action)  # env step\n",
    "            obs_deque.append(obs)  # collect obs\n",
    "            rewards.append(reward)  # collect reward for visualization\n",
    "            imgs.append(env.render())  # collect image for visualization\n",
    "\n",
    "            # update progress bar\n",
    "            step_idx += 1\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix(reward=reward)\n",
    "            if step_idx > max_steps: done = True\n",
    "            if done: break\n",
    "\n",
    "# print out the maximum target coverage\n",
    "print('Score: ', max(rewards))\n",
    "\n",
    "# Visualize\n",
    "duration_in_ms = len(imgs) * 50  # 20 FPS\n",
    "jviz.gif(imgs, time_in_ms=duration_in_ms, hold_last_frame_time_in_ms=1000) \\\n",
    "  .html(width=256, pixelated=False, title=\"Diffusion policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ours: Streaming flow policy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating inputs and targets for conditional flow matching loss (CFM)\n",
    "\n",
    "Consider an action chunk segment from the training dataset $\\mathbf{\\xi} = (a_0, a_1, \\dots, a_T)$.\n",
    "\n",
    "- `LinearlyInterpolateTrajectory(ξ, t)`: Given a trajectory $\\xi: [0, 1] \\to \\mathcal{A}$ and time $t \\in [0, 1]$, this function linearly interpolates the trajectory to compute positions and velocities. It returns:\n",
    "  - `ξt`: linearly interpolated position $\\xi(t)$.\n",
    "  - `dξdt`: linearly interpolated velocity $\\dot{\\xi}(t)$.\n",
    "\n",
    "- `SampleCFMInputsAndTargets(ξt, dξdt, t, k, σ0)`: Samples inputs and targets for the conditional flow matching loss (CFM). It returns:\n",
    "  - `a`: The input action of the CFM, sampled as $a \\sim \\mathcal{N}\\left(\\xi(t), \\sigma_0^2\\,e^{-2kt}\\right)$. (Eq. 3 in the paper).\n",
    "  - `v`: The target velocity of the CFM, computed as $v = \\dot{\\xi}(t) - k \\left(a - \\xi(t) \\right)$. (Eq. 2 in the paper)\n",
    "\n",
    "\n",
    "These will be used to compute the conditional flow matching loss (CFM), which is simply the $L_2$-distance between the velocity $v_\\theta(a, t \\mid h)$ predicted by the neural network, and the target velocity $v$.\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathcal{L}}_\\mathrm{CFM} = \\|v_\\theta(a, t \\mid h) - v\\|_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Ctp2Ro6qbBBN"
   },
   "outputs": [],
   "source": [
    "def LinearlyInterpolateTrajectory(ξ, t):\n",
    "    \"\"\"\n",
    "    Vectorized computation of positions and velocities if each trajectory\n",
    "    (from a batch of trajectories) at given times for each trajectory, using\n",
    "    linear interpolation.\n",
    "\n",
    "    ξ (Tensor, dtype=float, shape=(B, T, A)): batch of action trajectories.\n",
    "    t (Tensor, dtype=float, shape=(B,)): batch of times in [0, 1].\n",
    "\n",
    "    Returns:\n",
    "        ξt   (Tensor, shape=(B, A)): positions at time t\n",
    "        dξdt (Tensor, shape=(B, A)): velocities at time t\n",
    "    \"\"\"\n",
    "    B, T, A = ξ.shape\n",
    "\n",
    "    # Compute the lower and upper limits of the bins that the time-points lie in.\n",
    "    scaled_t = t * (T - 1)  # (B,) lies in [0, T-1]\n",
    "    l = scaled_t.floor().long().clamp(0, T - 2)  # (B,) lower bin limits\n",
    "    u = (l + 1).clamp(0, T - 1)  # (B,) upper bin limits\n",
    "    λ = scaled_t - l.float()  # fractional part, lies in [0, 1]\n",
    "\n",
    "    # Query the values of the upper and lower bin limits.\n",
    "    batch_idx = torch.arange(B, device=ξ.device)  # (B,)\n",
    "    ξl = ξ[batch_idx, l, :]  # (B, A)\n",
    "    ξu = ξ[batch_idx, u, :]  # (B, A)\n",
    "\n",
    "    # Linearly interpolate between bin limits to get position.\n",
    "    λ = λ.unsqueeze(-1)  # (B, 1)\n",
    "    ξt = ξl + λ * (ξu - ξl)  # (B, A)\n",
    "\n",
    "    # Compute velocity as first-order hold.\n",
    "    # Note that the time interval between two bins is Δt = 1 / (T-1).\n",
    "    dξdt = (ξu - ξl) * (T - 1)  # (B, A)\n",
    "\n",
    "    return ξt, dξdt  # (B, A) and (B, A)\n",
    "\n",
    "def SampleCFMInputsAndTargets(ξt, dξdt, t, k, σ0):\n",
    "    \"\"\"\n",
    "    Sample inputs and targets for the conditional flow matching loss (CFM)\n",
    "    given positions and velocities at time t.\n",
    "\n",
    "    This functions performs the following sampling (Eq. 2 and 3 of the paper):\n",
    "        a ~ N(ξ(t), σ₀² exp(-2kt))  # (Eq. 3 in the paper)\n",
    "        v = -k (a - ξ(t)) + dξdt(t)  # (Eq. 2 in the paper)\n",
    "\n",
    "    Args:\n",
    "        ξt (Tensor, shape=(B, A)): positions at time t.\n",
    "        dξdt (Tensor, shape=(B, A)): velocities at time t.\n",
    "        t (Tensor, shape=(B,)): times in [0, 1].\n",
    "        k (float): Stabilizing gains of the conditional flow.\n",
    "        σ0 (float): initial standard deviation of the noise added to the action.\n",
    "\n",
    "    Returns:\n",
    "        a (Tensor, shape=(B, A)): noised actions at time t\n",
    "        v (Tensor, shape=(B, A)): noised action velocity targets at time t\n",
    "    \"\"\"\n",
    "    # error = σ0 * torch.exp(-k*t).unsqueeze(1) * torch.randn_like(xt)\n",
    "    t = t.unsqueeze(-1)  # (B, 1)\n",
    "    sampled_error = σ0 * torch.exp(-k * t) * torch.randn_like(ξt)  # (B, A)\n",
    "    a = ξt + sampled_error  # (B, A) ⟸ Eq. 3 in the paper\n",
    "    v = -k * sampled_error + dξdt  # (B, A) ⟸ Eq. 2 in the paper\n",
    "\n",
    "    return a, v  # (B, A) and (B, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming flow policy training loop\n",
    "\n",
    "Takes about 3min 3s on an NVIDIA GeForce RTX 4090, which is about **33% faster than diffusion policy training** (see \"Diffusion policy training loop\" above)\n",
    "\n",
    "If you don't want to wait, skip to the next cell to load pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "3f5a431343744cdfb659b221adf65de5",
      "595ecf429d2c43d1a59b1edf50df0428",
      "293332374b09405e82c6d2f9fa79fdd9",
      "0b383fb41afa4b9992adb69c376831b3",
      "a3fd1a1ad4a44ae3b93ea41f0d79b04b",
      "a652b8d2ca3f4c2b9cae225897f672e8",
      "340ff99229384d7fa03581972d940c30",
      "6c3eabccdf474b19a4578cb8baa51fed",
      "0b55ddc3ae644883b208fedba783c281",
      "8ebb166c5835410baa473de991cfda8a",
      "b44573e32c0d459787c97c34b54a2949",
      "ddc1bc0963f84a80b65891e5a86db38c",
      "d8904dd8ddb044b7a38121428b202c7a",
      "090c17be26ff4ee1b88b7a1579137b97",
      "753b77db948a425eb8afe1058fefc27f",
      "f2040ebfe5374f1f9cc6c732b815e5bf",
      "cb0beb7b5e8a42d3a56fac813bc58034",
      "abf78e134cc44f07b94bd9fc9506582e",
      "2cfa2584049e4fc4b7fa7098c9d5a84b",
      "b6a719d66577474fbaac081458659191",
      "65748691ba3e421b9a306c9465711a49",
      "31cf51181d454c9d9fd4d6b9812452b5",
      "fa27a30980d94254914bbe5d772d09bb",
      "1e9eaab643234b1dae5b9ad19642b78d",
      "a60d113f4f654dfdb351f712c139e6af",
      "78292810b8b04974a90f79f386f93656",
      "e0bd8e69259544f8a5eef3094ed9226c",
      "686e69745ab847a3892965a0397a5f21",
      "5bd24969aa5c4804812319fd398307b0",
      "021d19509aaa4ac6ad767f4fe5f5b8bf",
      "e995a79bed4548bbb80b71eb13c78462",
      "c081f6eb036246d4810396d48969bc87",
      "873952c58542427489dd5db686e4a7ec",
      "120bbb54e3734dedb41a9ad0b969ddf3",
      "351c1e809119425cbb63a2262769e6cb",
      "474569bfe3714dd9bde570cf351801eb",
      "485a2fdae5b64091869b22e3324735e9",
      "3361479ac8c841b19ba8cdb71e777da2",
      "81f5db7ee4ab4bd3b1110ae2478fc635",
      "55376832e25545ad9904a591dd0c4721",
      "2efb5c1aa97845bdb677987658c9949e",
      "d5e6d7ff44814aafb06c4313dc2a0aa3",
      "629ba6e18cae4ef98a7cf5e32fc60239",
      "6f3d18ffa5fe4830852ff9d0b57d91ce",
      "a6ddecaac98b4f31817146a363dbb264",
      "3f15513e2c6f48a5b8dbf992e423558d",
      "85d539a8687641a69e1d12b073c08dd1",
      "ec675cf995c341d6871ce9cf2a255f26",
      "dbe0dde67b3f48549227b7aed5e3dab9",
      "97a850fc222a41d7be7dadb52f4a47d3",
      "0b2fd0c3f20947e58db901efeff84ce9",
      "b28c2334d3094449a8b5481d2855e980",
      "d2b53d7ed1c94c59a152990e7ee52da0",
      "696b9d742e184079b4bc3e15218a518e",
      "e7b8270adf0340e696db9700b9bc4c04",
      "385d439bb3574289b663bce38917657b",
      "cda22325483c428aa4b4c40e8b41acd3",
      "40aded64e38f4aa9b143c098c7e4e5a4",
      "49ff82a499b04ce18f82c7c16bdba353",
      "0de1b12de1834452a46e294547dee2fb",
      "1334878421cf4510919171e711bbd8d2",
      "e07be37e1b6d4658af4e1a9cc81bdb8f",
      "ef26349bf72c47edae94bb3b630a6c3c",
      "7115fe1a9f15485aa3866b185635a2c1",
      "01592da23b534cd18fb1299216f447f7",
      "4af2ca3971804203bc9aaf7c580cebb3",
      "007d52fbc31047daaef7170ee97d08d0",
      "0ccb6084c97e45a091c6e364cdfaefa8",
      "196506e663c94def85bef8a5996c090b",
      "877434c39b074fdea91869584faca3b3",
      "46659a843a52447692ced51984cd5be2",
      "d8403b502d544d929d70527211362d88",
      "d9fa10dfcb324b78bbe5554c21711461",
      "af4b4cf4a82549acbb15f678e4b38ec9",
      "7162b30a4dcc4cbaa28f319309434d3b",
      "448d1bbce09a47f2ad33fc49054eb16c",
      "3f17ab198d054305b9d91c2184c60bba",
      "37b703efc83443f4a9462eed3a63942e",
      "cca8240f2f5f4bb0a6c3f9319795e277",
      "368e97b690cf4d28ac372cdd00212473",
      "d188e7f4b1104bd0877f1c80efe0b510",
      "a0730222e27649ac863e1fb823f63277",
      "48a4e2682dc646579a5e1557bda005f8",
      "3037c5299302447ab04b98d360d10cc7",
      "d24e47777aa84cc7b0c4d335a948401e",
      "55a0b9487cc544d589f35340e2a6a0b7",
      "948cc8c238c9449cbf93da5ddb0462ef",
      "b3b7cfce8f354c08b59bd2934b7b9dba",
      "3c1684152a254422a379dd52e05bf4f4",
      "a30d327936a8404a9c533e3200be3c22",
      "bd6cf3835e984a418d51cdecd536040c",
      "03eb0053bdf6451681e6750001f331c8",
      "0d0a9bdeeeeb4a8ca69558a7841cb71e",
      "3a41e35879b5498e9b168f69a5a6def7",
      "c76ddfb8d6c140a4aa6010cfee77cbd9",
      "d77516a9aa15445a9a5ceaebcfe8083c",
      "be49a5e6666f4f0da05931b464c3c273",
      "e018cb461214441da4186e6b29988311",
      "1e080af82416468dafcdba20d85bbffc",
      "73401b0a50424428ab398b9cb7af8460",
      "1e131e83a31640cd84fb9f5032b39c15",
      "51665c0f06a049759aeb52328a78dbaf",
      "edb5c7c4052845b98b145fbaa386800d",
      "0f4237be951e452aa3b795ffaae61f80",
      "0e5b817795da4421bf1b64a9b4ab9e68",
      "0d37d72b44da4ba08f60f8aa33f9a0df",
      "7d968ee6c31842359a00cfc1ce98e554",
      "543b143b52364497b487a761deba5af9",
      "a341098a07264528ba4313afbed29b8d",
      "6e0e0bf2287946988fc0ed1800ca7710",
      "12981c6b58224d5392df1f7fa49b7ccf",
      "86bd1cf1b014452daab19e6e7c93246e",
      "536e93cb95ea444898a02b918eafc7a6",
      "d01a131880c34664916b23d03a3cf668",
      "dbfe348d101e45e487c98ea68a156001",
      "43bb04254c4a4422b6aa24ceea17ae0e",
      "c516adcce45e429b9278c37ad5774d67",
      "f5b8c5c8f46c4c518b497e0b6c8c1f91",
      "56881b23d4c94285b846f58970eeec2f",
      "9f25f4d036ee48aaaea0859c2f2466cc",
      "c634cef4d657493aa10bccde349b29a3",
      "597512e085d34b5eaf38a921c1583160",
      "efa66c119803483f86a695f850b8f45d",
      "8fa7696e8f8e494d96388f7c88b4bea6",
      "34a602c951874758b7e8ea707d6c22d1",
      "b004128f2a9f4071934bbf542062f421",
      "d3f55888839e401cba0fc08416db4966",
      "349896f4cb1b4a6aad6db2b034f9e0b4",
      "327c71cf0c6d43a4a5486afcc8bdc9de",
      "662c7f1620414163b33063e77e51e784",
      "72d169657b71404abba39ddf9e4e35b0",
      "e2801413af4f4979843408264c2471ea",
      "431c28a5bd7a4e37bc1a468d97f2b982",
      "9b1e24ee9289407a98e98003f2c2f28a",
      "edba843405cf444ebc9017f50a7a2bc0",
      "e9e03facc7614649ad0b0939d5da46ae",
      "30f6ccd5d5f543e1b79923e2157d010a",
      "d6a6fcdd7d664f849ad9f50af2940037",
      "023c1e064c7b4392880a117e0894b8f9",
      "bdfc379308f647c89186a1076d9933d7",
      "628263d709ad4c0589737e066c7ee6d3",
      "417cf5e5a1e54969b3d4cb32f352b35e",
      "787ef6510c88495f941dcbaa6f0a42a0",
      "9890fdcc122347a3b14fb3f2c6b33e93",
      "a79ead0fd7714b5197b0c0ec2cc7f849",
      "520fe717e305471d83bb95a5070cf2ea",
      "376bfe0cc8d743afa2979ae85ac00544",
      "4d19b4ead0b847f6bca9ef4a1699147e",
      "78212b310e9746568aa65761694439d2",
      "1ef0ac26d6df4bfc9c525c8d1faee1d4",
      "6988cd76bbed4d62b230de266556a5ee",
      "ef832e9c248c47cfbba2e3070b0945d0",
      "faaca6ec02604fff920cee63a220a2d3",
      "3b2cc38a9d4b405d83af058215ef891c",
      "420f2170e4524563906a96e2db52e9b2",
      "b7da3f8115f148c7a89e1b7e2d7d25f3",
      "b1de189282f746818fc315278f1592f0",
      "0bf0eb3dd0f04ea2a2949e7c98d2b7fa",
      "a6c352ea03044037b9489f0fece891a4",
      "3e8a12d335be4836ba33fb3d006c3fd0",
      "ebcddaae47324007b89006cb368b440c",
      "516eef5dd50c4a93bb93f3b1a3523f8e",
      "1a9140ace15746f9b7e6d59bbb6ab226",
      "48bb258f2b3845a4b7ebae98d5cc9b9f",
      "866b0d72f11a4edda7ffb13fbe3e6cb5",
      "2725a84cd846440ba0f802ffb0b57dfc",
      "69c4029629624c66887228a8ac9dd1fc",
      "d8e0a2e5029a49d5a6fe7bedb58fa6fd",
      "02dd1fd82ba94935a1100785a81c9d39",
      "f570c75dc215447c911b409741885a30",
      "1b4630f91ec44301b342e3818fed63d0",
      "fb226263fa2f48f38bac3c11627f2058",
      "50eb854142ee4fbebfc946e80fdeb30a",
      "a2f0ba75d27a447a81fd8e5feb9cdc7e",
      "7e6250ddce7949d5928105958c4e1926",
      "27440cbf640249268b4b21b4041fb1dd",
      "fc152acd069f488bafd258bf795e1ae1",
      "16e7071611644a7aaf58efffc0cf30dc",
      "898c5a66d04241b2a35413676c5315a4",
      "b641d9f8c8f44fd38bb170e96cefd94f",
      "879c1feae2c048f6a3ea4dde12db30da",
      "7421570d605b49aeb6f22a2e9582f82c",
      "f96125ea28cb4856ae8bd6e2b88de210",
      "bd2a46b7c8e54889929ba19a69b6eb70",
      "b03a284e42b84471976c8ec63507731b",
      "8f218923808342c0a4ea30de55b3529e",
      "d9818eac29614da5b7b0ab689cee28a9",
      "759800b8681b474180ae783f7b86b3cf",
      "e8c8d55733884f63a1ec2e26bbfaf8d7",
      "f06f38930e6c4cfb9aadf4849bd5fec5",
      "7698fbafb41b4acc911af267157f3908",
      "8a91b99dfd82483a9a0940eb4a60215c",
      "088a683455db4f1e8cb3a757ed38b62e",
      "8b0516b66f5a491495525558e53f48bc",
      "9c44eaa608b64c56a419e8d0e9b4644b",
      "13c2595e51744ba6babbd09d457796d7",
      "b169319cb9e741ca8e0b125b93e586e4",
      "6b40872891a642d3bdf214c87a05a3e4",
      "1c1e3621e1f649059f1ba4da7adbb0cf",
      "a2f960ff099749ccbb84353ee67b6fff",
      "fc00ad3cd802436a80fb2b89845bbf60",
      "88ba4f3c947d4612b15a4035d6a451a5",
      "8a6d93c9025c4213a9b25754fa28c76f",
      "aca8d46cd333465c955d3de44b4fcaaa",
      "52b356e49d964b79b471d3289edd44ca",
      "a287f6a02c2143638b665c5f2cbc2ad1",
      "02efe66db70f4186a751ad2b20b148d7",
      "afe69850c0d04b9384ab4d2719d4f45f",
      "4cd74f57d1ed40e1aea8d68229ecc927",
      "bc9d74ed07104fae9578b839229a3b08",
      "4f2b44d9f4854848913d5eb4c2b504db",
      "68b2820822914b21810cd2b0f9659918",
      "6067c9537d1244aab7d6126bbdf7c081",
      "97929b6709dd4b6dbe7806d773d4752f",
      "10967ff78c5b477dbadc4e31980c15be",
      "763b6ed0c83842a0939c042e03df36c1",
      "cd9a3144f7e44eb78e11c9c8bc3c952a",
      "3c3f265a764b44cb95a8536d75403540",
      "201c5972445a426ab2accf3fa1b76222",
      "dd802fb8f23d43a39268c2aed2b9024f",
      "08ac829e4581403e94cbb9e78202c4b4",
      "e6510afb2bed47c5a6de1ae9c7844448",
      "202e10df8d2a45b2aedf8eeb289cf795",
      "d33124f1ac494157a55bdd65b186c10d",
      "9dbbf9a81ab84b94a364bd7613f0955c",
      "f27fecc9a5494f09983343346a32d52f",
      "cac392d9e01244ca86f571d977210cdc",
      "6e1b1aea657b47aa8653a5b3a0cf4932",
      "360e4dfdbde6402a9f1e6404bbc1e48e",
      "f6c1aeb4803645a38ca172163b0360d8",
      "3f7b14162f624bd0bd6e124fc14abd5f",
      "da6d985f4d994e8e824fb7887720b197",
      "98325ad9074647d7bd33918606d78ab9",
      "f104f8453ef44045830508dfabfa301e",
      "4776b22808ca48bb9e4a08ad10c3ee09",
      "fcac2c280f3b451c95f604bca3f0082e",
      "fe09cfb1ad05479e8eb26194c1e87980",
      "9a6a744bf58e4c77bad921eb9fc61639",
      "5ed04eca5cdb449d9417efc6f1f8966e",
      "6080aed0b3d946b5a4b89d10d8955e3a",
      "99f46d7b389b4c5893b65d69be183a90",
      "df2a7d947b01417287dd7d3e4208ca02",
      "1c2cfe342f314cba9cdca9251de00bdb",
      "c635f82e9b9948c6905c8a31e6a715e8",
      "642201d502e54b4a86ab99033e8f5cdc",
      "e6efa42167c849f29706f32dfb0da7d2",
      "e14fa65410d94529a9bbc1ce8b420856",
      "2bdd6587f9e644eda0a516fc16c71644",
      "5040790a45ad46adb0a7aaa0bbb31b7a",
      "40ca6cbc09f5426e8f1a974de16809d0",
      "fbd1b65bd7b34a4f83fc162fae8fe0da",
      "045b612a9ff942199cfc5084ad9e0478",
      "26ff982e8b464f5282bc1d4eb31929eb",
      "e2b4a3bc54634a9385ee0ba7c2a748b0",
      "05e3ac3910cf426d80bcde8fb88bf21b",
      "95bfecfce4894c0aa9672dbb47f60831",
      "31b78989450947dca2a9477b4b644e69",
      "f28cdfc68fe646cbb0b20eb97f621ba5",
      "6666b482fe2e45b5b440a795b1578de2",
      "3e64a421b24f40eb9256428d4073f29e",
      "0bcaf48d6d5c4596ae5334d838244a02",
      "31753fa6854f40719045cfda889c0c7f",
      "80922d27ae644494b319ce4121b5bbc4",
      "b5194d8aa32340188334a509307d4e08",
      "48845666ccd148daad3dc450a3efae58",
      "7e3c27acfe2b429f83337a9cf4000659",
      "ad39ae3a68cd481f9df4622a7b6f92a0",
      "9359721d306048ddad5aa544d25b5afb",
      "2bf3b0add06543b88d6e3ce245c1d7f0",
      "63317529c2554e94825781bd2cc75af6",
      "ea88518ebf5b4596b22855a98dc7ad2f",
      "c63274de58c04690b6eb2a0cef26daae",
      "35e1dcbf54ee401f94eb26985c3fcb9e",
      "db71c848643e42f68fc0570eb1020310",
      "83424e8087ed467daeaed3c18127a81c",
      "5a69c8e479344749803e5a93f6ebcd14",
      "0e6ae5b80a8d4c509b3cb063712846b8",
      "cd61096be16842fc96d900e8b12362ca",
      "e274f964c3304219ab012dbfb426f9cb",
      "fb6c82f5cd2342bfbfb23d0dcfbab6c6",
      "b8ee87f39c7d49889db87a2341c0214c",
      "358ccf166ddc44dbbbbb4f5e21f2b0e8",
      "d0a1e34307bd4eddaec76fdaa6eb531c",
      "de8b109b07994b4eb9f6f14c315b63ea",
      "a5728cce708e4005857fa6016f0f1af4",
      "7d9828bb4c0c4845886fffac9e658952",
      "a4d5e7fea1bc455ea32ac9b521ca4cd4",
      "c8fba7be4e2c41cf81088cd95da1cf14",
      "b1f546de1ac242f88d07e7a0d6bb3ad5",
      "b6f22e9714c541b08b43faeb395b5feb",
      "6ea8731a896a4aed8158ce03a425c70d",
      "a7f0fb6c9cb14faeb294e4c2cae14eaf",
      "8f84c3356a254cc5a5f9d7a7bb5a7803",
      "6920260f288746db81d445231be96a47",
      "7a6bd24ef5d8476fa8a6d6eca0d3487a",
      "6ece29101e4047008e2fadb4a5365137",
      "93f341bd6fcc457eaf412e4c06efc412",
      "a6a7f8b506e74cfe8d1104372bc52611",
      "7a38b62220814da9a82cf3bebe4a54b5",
      "75f2cdd5e5f944a5b812dab866c47754",
      "91c70d88a7f74dfa9daa6699c591cc3a",
      "24df9a17c4a94858a0f210e3b14d3d68",
      "7de9ae9486294de59d5eb06e8e200f0a",
      "bbdc00418a824b32930c2d5ce009a54c",
      "0cc4b709e99c4d0e9ef3d785131e8e2d",
      "d58fd9b178484eeea6b247f233ac8639",
      "ccddb594eb9c437b974878e20f3ad1ef",
      "9bed2fa2c73e40778f9b306cd9719278",
      "5a6aad44b2c949049ebed02f18c6f2fe",
      "15c61f3e38594b8f940db7ecb77adace",
      "d7382bdcc4a6405ca3f347799f6bf9ef",
      "a6e8281e981c473099a519ae9ccc599f",
      "cba25a17bb544b58878a86e32ac37a4f",
      "568d5d57514c42f6ae501471af4895c2",
      "0d369d062dc14186a731c1fce1364618",
      "3999755f752443c1a7f93c3baa64ef8e",
      "468e0a55be554d69ae2cdc322865e77e",
      "ba8942eb4333430fbd6d5875ee47406a",
      "14255c0b6e5d4a3aa20e7f6f02dec490",
      "0b5dd41a2bd7407c9881f7f9cd628a99",
      "3e6f77b0f15f42fea527bd79ae1e01ac",
      "454f02973cf941b5ac4fde4d14521e2b",
      "b87d83744a3c496b8383d0d938676dc3",
      "34722d12211349f49e39aca5cbcbb348",
      "46b5b44889e3452580ca9b6ef667d631",
      "144e90875a0b40d59a38128a0b0c1578",
      "963061f840ac49e79598517f9f47f293",
      "2e8f50b86b6c4c318ba29cc1fe285a8a",
      "3187cec2b1964e31a0f9aea503b9bb63",
      "9ce692572033405695f2641420ebd7c0",
      "5887179743f5438db56feea09f2b0fa8",
      "b7930e611bc54d668bf74786ede50c5f",
      "1f0ad7ce77844928bfe4ab626e229db7",
      "5a615add241f4188bbeccc93646a6850",
      "285f1d146d9246a7bba97f25b5791eef",
      "a5fae90e6b3746b8a979406b2c40cf68",
      "f7d32ec045f9408db56b68c981c7e1eb",
      "7f91d97be80c4ccaa688685527499532",
      "4f47526a8c444c43a9d89d49d2744ad8",
      "ba5110542df945899c4894f688f84b3b",
      "ea92bd5663be487b9ef4e4de721117d7",
      "00be0c494fb34b909ed6443639e3ec2b",
      "6603fb96fe004c1e9b70c0ebb6eaaeec",
      "7f1bd3ae62544208a7f4b6467dec757c",
      "18b11f48ad0f48139e6b347a472010f7",
      "6186edc88c36470597dacce080aebc71",
      "36b5988434594920b32232491202d319",
      "a53915a9e8b942bdae1b976d73acb2db",
      "2d37efcfacb749909cb87c5b73fefc7d",
      "c2ae3c1c360b41d2a942219e862b5452",
      "4c302fedeea642b6b5620b2611e1414d",
      "bf25506365f94fa281d80fb409324045",
      "0c58f2e537144f85b7a1f445c99087a3",
      "7f88cd5bdf144054b098fed3946a7b2e",
      "26aeed29c55e4e06bf230c6edf45aeb5",
      "e2106efe5f844ba988f1a0428de7cb3b",
      "22911b8b00e94ceaadde1cde50528997",
      "6ebdd6037d974a30b97fea9e6062a34b",
      "c113dea2248d42eda4a4a160e6e3e7bb",
      "0ef81af0f8194bd984e1392de718c738",
      "d03fa9b95e844fc99308f46e5f5aa1c2",
      "255fa49aefb541f39428c56a7f3ec966",
      "8b980b312fd144e3bee3d0706d20e925",
      "4f54cf1ebdd943179ca02fe0360e6b7a",
      "aafbd16184d94beaa0f7ac9b7fb4bb06",
      "c981feac3d3841f48f43fa517787aeb6",
      "f421ca8897d04ac18a8cb5fa06e61563",
      "092731872c7e40c793a02ec13cac7667",
      "b9954aa6f7e74060b8f22e9a67eda8e8",
      "29cfe8ba2e2c4c549531e675f184f909",
      "f5ec8dc796b542b2b0fe49d0ea4c6b1b",
      "461fbf9bd67d42079f5f51d68307c6cd",
      "83f682a0f2f44debbf5bca75028dfa28",
      "26ab9689b2ab4434ba96f505301d63e4",
      "36e5f69081e24b919bf1a2ae5c5d7440",
      "4cd4e3ac09f14fc9af14c6e66c1da6fa",
      "305b89862ec24cca800651d1b79ad056",
      "179c910f5c584d2eb435be9af3a0c0a6",
      "1539f1f86f88481d8840d3d5c3a7513f",
      "05d65f698ed247b7a7099b26bc61d1cf",
      "febdd7f40260415ea204c590eef9f64d",
      "d205be408aa249368b0d9a8216acbb93",
      "f948ffd70e374902a64b722e3615c3ce",
      "ff12cefe469d42cc918ec34a0de94acf",
      "6f58aee320de4fd3821b879c946bd213",
      "bf9d767cc44e466483be3e92edafd7be",
      "d8c81ed9a1994d0282836361bd73c389",
      "28c91a714713467f9c0efa9e7b4de1a6",
      "4e62c0e83e4d40d7b45e7f992f6a35e1",
      "060809b85b6746b69ef5062a3411c473",
      "b53894d9a6fa4aa5bfc7e83cb958c6f6",
      "47332eb49a6845bd8bab82914675b1a2",
      "f772dac899f54ad298a99095b912f9b1",
      "a5587818f73f439d9e6c22bbec04abbd",
      "16d9976497594ac88f0141be5ce4864d",
      "ae19d619e6154de0bc63c45a578133d7",
      "a739b167d3224150aff807a3242e09af",
      "536203bcb7674df790e51f73ddcc19bf",
      "df9bd3e8449648da8e3818be05448e4b",
      "e0839994c3ce4965a25eb5b0353584c9",
      "91c06b683cbe4a469c973eeb61351b57",
      "8de95b0723d840c48b387d02735c7e84",
      "7b66962a0586477783f409f7042fc49a",
      "677d93f5b4524c84927ae209b716fde2",
      "b9f1a55d651d4b3eb8fb779883715ad0",
      "051c8fa6e92b41ce8db12d2c1a0cadf3",
      "050aece13bf344c9b59769cba1df7807",
      "69db16e672684824ac9889200429b056",
      "8e185b554533406c9fdfb46549fcd7d8",
      "0e7626e6c5eb4b76832a84419ccc1430",
      "bd653f5d2b1b409ebd9ec1b908651531",
      "7a00a43f1e974e0980d419de3818d992",
      "19c95d77b53f43e2805186fcd4202e57",
      "8e3a1f915e5e4250a3d1f5c1de1d2f39",
      "d9ceff9463d840d7b354835edda24141",
      "2c7d343dbd854411b99ba39316d2c98a",
      "bfb55575d19b45108150790048090cd7",
      "7012ffb329c74e71907c9e35e2f8ae32",
      "05e37435228f4e7380e3ec0cc9527a9d",
      "e3b9296ae4904366bf1fa662f0d9027a",
      "0f810441676c42e6948b63e0af6aa8cf",
      "637fdae2e86c41b7b096e8622cb64518",
      "be31b6bd36524c3b937b24360a06d1f7",
      "f14107de56d94954bcb27b65d35ae697",
      "49cc51db481a4e0a8d5294ea4e459986",
      "99614505e68a46ea89f7adab2bcf9744",
      "4c79bb0c9a184e778841d3570f4ef74c",
      "1f301b345c494c58be930f61b115ed61",
      "fb0628bb8e614bbab3609535d881ceda",
      "121a7612bbfb4155a6a90adaf70609ce",
      "f8baafc12d2e46eebea2ef71ce0b3e16",
      "4d15c01d66104353801e2f252e54be45",
      "29d2b80d7e6c4294b90c51fcce164b34",
      "b2fc5cc2b1be42d7954549115c674afa",
      "2f6d26299d144a8b9b4a421ee81d1000",
      "f5ca535a199a4bf296d251e79cb43fe5",
      "3b25816dd3e749abbebe9f55aa91df80",
      "cd20d74ccee04fca8eebe18d25ed3d51",
      "4f382753ebbc405595925cb53f17d996",
      "fa9722aeff854e9ba387e9078c0e5c3f",
      "e7576487e4024d4e98f67fc579b397b8",
      "81f627ce26b64ccfb494da348a2de050",
      "bfa20db73b93448daa167b8cbb2edf3e",
      "e5e88389dd524fb5a67fd9cbb7b65085",
      "1355c5ae144f4086a49ec39cf1253c97",
      "3a21fd048099485aad0b70c19641a3af",
      "0c953272c0184349b8c3cd56fec46ff2",
      "326844c111ec4465b3e59db2fffc4b26",
      "3d85fd086d60449b8f0ec53baab92d8a",
      "deef9c656f2147a9aaad23abe54e6190",
      "ab651af9b7334d2b9d6d018ec135e7a4",
      "5be068aface24bc3ab350fe8d6a271e2",
      "2ecc028203c343d299515fe32d140cdd",
      "c4eb2db88f064a63a09f2bd2a5fab7dd",
      "7f8aa7bbc0534d40be0ea583b276f503",
      "138943ff9edc4c119457744335e3b760",
      "8ba84f9ebad344158dc1f4fd19c223bf",
      "412d09c5fcdf421aae4bd25c23b34e65",
      "14edb3c54051450483529c6ebd2970e9",
      "bd38bf5f11264838a0705019cc04cc9c",
      "93d4b778a1a042d58facd8c684a13b8d",
      "d6c6ffe79a944730997711c81fa17b60",
      "d1f51c441d25499f8bbc92d0a54db592",
      "cc8b3e9a40f64ad8836e80e82d042b8b",
      "e3333ed8188f40d6b53ad3b579c7731f",
      "8d8225692b6d411e91e5db9701193970",
      "35cbfb9aeb844555965ae9e8c67bae28",
      "4de56bc5a70f4623a80ff7f14e1afe1a",
      "c12aca5bf3e64af2a2545f09235c97ab",
      "9df9c38c31be4648804509b65fb0eba5",
      "8d3072e9af8d4bb883fcd54f7edec512",
      "5fa6128e20ce4bf1bfc0638fe99b9dac",
      "28c7e2b41f7940f89ba211db10567b2a",
      "0a4f32f8cfa04012a3bc741c86fc7806",
      "f33dacf5add745e2b6498278b9fce910",
      "cc0112202eb946b89086873e667b3981",
      "ca1fa19a9aa94b188f29531d771850b2",
      "2e29131168f24a6b913ae40ffb8c0aa7",
      "0c5b3383e2534f53bf36fc4710cecf24",
      "fc6164bd709049dc9f341b64be5f5881",
      "4a8fc8db44cd4dc0b6d577130a045d3d",
      "7974be56f2c9489394bdbeb1b63a0598",
      "a2946166175348428c28fd98beb28730",
      "6530bea888b040568c2a45555402bf3e",
      "9596f171802444bcbe819b49c9992f36",
      "0f18aa8353ae4d758ef550e3dfaae562",
      "291938a17cc4436d9403da961d2c04fa",
      "7aa06c96cc364edfb0d271760114cdad",
      "575ba552c757423f87828b4d5ca475ff",
      "2a1ceb61e2a1444dad0f1de45caf1dd7",
      "c00c8acab9fd453082beb0d166d13a77",
      "fbdcb60b37df4028b2d5a61b3aa11f81",
      "4846f20be12346c5b8a601aa29ccf490",
      "c36f31466fdc452485c19dcac50ae7bb",
      "34540d8704fb4ae9810162ffbd044b4c",
      "a342238d83184adea2bb192d87347001",
      "07f7cecaefaa45b7ae642023a992c721",
      "6b93ae98745f4c6c8b30151c22cc887c",
      "cb10d4067e364fd4bc2c50593cb6a41d",
      "87d3f11cfa144e738f3d61810bc32076",
      "443a51a9510d4179afdac288c36ad472",
      "fe288c17abef4ea28525638172bee6fb",
      "610b05ddd5c24c4dad53554b6092724a",
      "8fda437ab4994b4882ff78ebff610633",
      "255fb23b140743bba95f3e0db2d5a119",
      "a5258a68a04f43a89fb1d6b56076080b",
      "1b46f2ec3dbb4d3aa17b0d97fecf04b8",
      "aec22900ba9a4b1eb5d3c20d302a8d30",
      "7633ee582dae4877becdbccc8b9b5bbe",
      "af2eb4e19fd24bce8576957a24794e8f",
      "f69cf6608e50419780c79d4b9f5027a5",
      "2369c67206154d41b205a9819565f506",
      "63ea4c97b54c47cca2f2088235dead7f",
      "526f1e5fd42c40b18aec3c65de710c16",
      "49186c10edaf46f6972e261aa555b768",
      "253d11282e4f4447a42be092883d75e5",
      "9d191111e7574fbca28bcda2b1bfa26a",
      "ae2920800c454ba786cc4f540614a555",
      "afb8659654af40ada8de6e4d1b9b6d3b",
      "20ecc189658d48c58338461cfacd4056",
      "4024ad4cc40a4c558756d35c87e4b469",
      "7650cec3710748b08b9db82d83a3c080",
      "c7f095e3c4a648a58c86616801956175",
      "8db34260ad2847d2ba6d4b59ee29572a",
      "ac572868ed8b459ab9588276ff58b950",
      "5f8e6d988299495f86a208b5e8ec4b22",
      "358f7607a7764ec394519d37188bd9ec",
      "61e81a83a3d346c8b43357e530aeed1b",
      "f884f58b8a544433952acd51c5841a1f",
      "d523dca552c24c859fca0ea26ad23446",
      "07ecc963267f4ae3a72868d021b830f8",
      "01f27acbf0c64b42a9259842072f7c92",
      "33691d08d7c0469a8141aa00edbe63cd",
      "23c4f84dad6d4772a11077cbaa339b6c",
      "ee9afe595dfd471e911a4053d8c6395d",
      "f265d65a8e2f4f83a4da2bcca61b09a0",
      "8c06abd4c8f54441b632106b431bfae9",
      "52ccff736d8c4c489f769689e63fc504",
      "69ca32ae4670421188d41d53b9cfd52b",
      "bb4e92c0809042baa0b403d584bcdabc",
      "3ef7e62ab95b4c5fba646c0f0b0dcfb8",
      "fff6599da2ca4bc5a6dd0149727d89cd",
      "6269c266230444178ba35659f1e3ca2e",
      "603e8afc1908460b939c4a34bbecfaee",
      "4ff7c5b1b772482e815aba4fc2d4178a",
      "0a7c7cc6c1854ab482900242c6d4c9ac",
      "b34b7f9769684000acf2a6c732583601",
      "90a9720f80214d5bb2cc6dfb659f2836",
      "a59acc81475a4750a85939bb0ecbffe8",
      "6ca54325e86c4c3aa7f7817b7c9b6683",
      "6546b49a75b84b739db2c4c58204993e",
      "028ab3aa879045698ab1d0ba7391b3b2",
      "c5b52d28491440d8a903eab813de2a4d",
      "de89da76a9774b26a432712e92fcb243",
      "50239a42dbe94547af432e57b5e7d7f7",
      "fcd2c6fc72304a7793994cc963c8edec",
      "74b5591918bb4359a6dbc726ca324eb3",
      "40e04903fc51478ab0f70a0eb1292fdb",
      "47b57eac1c8840fcae87d310c93bf26d",
      "db480c68642944ee86d050c695badaf4",
      "209f822bb5b443a4a7d8e7ac6668be97",
      "de060668fe394dd0a27a47bff4655434",
      "82d51b0c9c344c0d9f66496ae0f42dc2",
      "be977a9dc0ba404da5846dec8e653510",
      "b63ce5601c574823b33b94cb8af08e4b",
      "58b5fc1931114dd2a1c303f6fa674387",
      "db2a2d6994bf4377994c1be1c98d838e",
      "1368828c2dcf420c9dff2c58341cdff8",
      "60fe62f1edad4f94b827c905f2ce6725",
      "4f24179fa841491092d0a17020594d10",
      "1e76c403e3ba4b0b8a50db5031f3eb8d",
      "e7e62a86842742f2bcac47c5f7ae7932",
      "6bf0d53fa8c9404ea2fecd56c4d946ad",
      "f688dfe2b5c54897a1a3c9f73dea8090",
      "1ee17dce23fa46dab286c6a33191b901",
      "a39edefaf1d24bf7aca7f26a37ce98f7",
      "c1dde19fdfca4cb0b8e42bf61858e5d4",
      "9a80ce89aafc4de79d7d54f032acb144",
      "46ddb8d549fd4b7c8cd6b5998a4ff2a7",
      "e940327f9f2e4cb0b06418a5b514705a",
      "86072fc1bf3e4e0a9b44ba056014d536",
      "71ceb9ebcb9543a0bbb335332a104c6c",
      "8bd210c3758b48519326ba0cabb3f5a3",
      "d03c74b4170a4b63abace159e5ae7047",
      "bfd4042a2cc3430bbb5651b275d6dac0",
      "76f822013df646e5b415a4ff4c12cf09",
      "8c5c8fb7c564458ab85d36f606320411",
      "22319d917cca44cf805218a19b6f7be1",
      "a27797b0b849450ea1150da47a3a934d",
      "c9ab222bca43474c8986f564a246c78d",
      "13679e8f24974392866afc5c7d13b6a0",
      "732d951eac964e74978eba04fbc23ecd",
      "790e41403707439498565ad363be2354",
      "ab3a93e40dec4481a69c23ae0aae0945",
      "4584c0bc0fcd4b5eb86b459aaea3cd64",
      "1a8ea32045dc43ed9845ae48e653d139",
      "cc78f45a0c644af8a95eaee93dc6c237",
      "a5a84bf9fdde47da9bf89f7846de2ab7",
      "0f64ae064d8b4c83a2f27319bfa6527d",
      "7487f8a792b340fb8b3d73f73bd3c26c",
      "afda49ff7e214a31bd5cebbd5a54ab4d",
      "c0d0e26ff9c54f9ebfe6e49e907603b7",
      "9712da3f075a4a0f954c3a9043987a29",
      "9805b7f78dd04958ab293b450ff560ef",
      "fc3a85b317c8436e84efe24d83688a26",
      "8e3e9c72378d40ff88aad9a58320aba0",
      "314d95f0d88b419584f59d6b880d59b2",
      "93540a9222c645388476cd2ce7bbb13a",
      "589a38845d7543a59d2b5a14bfaea4d0",
      "8b84a417ba4049a8905cc68a27f43cdb",
      "e30aba5761da4e9a872575217e21a9d2",
      "5df76328dff44a59ba1431d93aa5d495",
      "0cacc05f07254d02bc6e69a90c1387bb",
      "1df0e5a783ee4c99ac54c51f24e6bfa0",
      "00201b56559b44c1b64a8cf15bf0c8b9",
      "f516018aa43e47c8a64480b0856341ad",
      "7a420f7daaf344cf9079d6e614e5566f",
      "aeb0b1f474fc4a538d678aa4b2d9fb19",
      "b273444533cd491ea7eeef708cc3d707",
      "b4109ff9ff494c7b990ed57756d101da",
      "9e8de24532ee42a58344e3b70017208c",
      "3ddcba288bf145a0a3e01db8d9f96ec1",
      "ce8c758a0add4c769a51f15db0d3a7c0",
      "43643fe0f96c4b72a696bca1746473bc",
      "a951218240e14d4aab5c2055c5e431f3",
      "f211e7ff90af42ee8f5baf35f8baf2ca",
      "6b8820fc20714d24a07632700131e094",
      "349417a8218c4113b4c1cada9c01247f",
      "bc835aa4526c469fb10350f776c6a542",
      "8f8e724d22a94fd58a1162133b29a84b",
      "abb6245a2b0b424db5ed97f0423b4b7f",
      "4df2d9830bee436983dc738279e7fc12",
      "82455f85d6f0437fa2699b1ee668b904",
      "76ff672b562846ddb874fbb7ee7fd185",
      "ecba9a260a3e4bbe921a4bfe509ff46c",
      "b29188c40874492597883f718c8960c5",
      "3e524590870e48de82abbfcec0d34171",
      "7f7f0802714b4fba8326f4d0ce2f62e5",
      "83ec6654640943a3a2a3d483d36a2b3c",
      "ec79391d043b4d3b889a4ac526f6dc7b",
      "fecc0bf3bb5a4f22830ec8ec22598ef3",
      "acbcdf4f584a443d86459502ee34c04f",
      "b39e0546a80f4187800e579c8634d3e3",
      "62c0fbbd062c4a26a5be61d741362005",
      "6231420b79e0468c9b54c6d017a0ab5e",
      "36841090fb2943d08813483119707887",
      "ff38ab6a89ac4c8195e87cdf1c301911",
      "f563fbfdf4f540ce8cef3026242d65df",
      "48c2281b8ae1469f83eb6e9238906884",
      "5b21bfe7b85f4e729181f0ba770f691a",
      "7715e52d1fe94e739823179ca3f2a2f3",
      "8d7de236c6404feb8ec15e98946aa15d",
      "d90d0f23d31d41598f756dc83bfaf843",
      "139bee1d49da49e598e804f6f9243ef8",
      "fe94a8d1398649efaf084735dbd6ff09",
      "4d6c7f844f92414ab9bd11dd5fcb31eb",
      "95d64000e2ec4bd8bb674cbc5e1bd9d2",
      "9794de12561f41ffac6924fdef608998",
      "107c19ae2c404401a994044d42800b9e",
      "39de7517ac074020af30811bd7ce0293",
      "678714ca781f4d248b6c6b9166e5bffe",
      "9082238447034423ada73bab6e327bd7",
      "31903da90fbe4f229721dabe08e86bf0",
      "a89e2390e1bd4326b7156821a433a3c7",
      "696b41b5e6934208a4f255b952337b6a",
      "ba1ed1b5f5ce4de881cbe468e23f3a48",
      "455d37c1cb564dfb8952335bdc20a852",
      "4398a0caecdf48a292ccf91bce4237ad",
      "97bef4a3014f4123a6fce41c3535ec89",
      "da3318b3ad324eae9378ec8862b92386",
      "27be837dc05045dd99f55701156ec4bf",
      "36570de2b56c4334889a09781b09daa5",
      "250b384397f6492e88f4f47543d53f99",
      "87851c26dc4548b294a2e69be353a130",
      "6c62eb340cfe47959f9f0e5630d4624c",
      "5f16e8d64794448fbf56e395711444b2",
      "c3249b8db05642c888610b0e07b4a1b2",
      "5851f851d4a745e6a4a8e54efa4d2fe6",
      "e923617cb27a45d8888d993c768cb79f",
      "259d29b1fac14735af984efe42c257a7",
      "760ea0de1dcd4e4580920d7580f68deb",
      "ea0abdaeca794102b469cf5768760ec1",
      "97665199c5344b12b5e1bf4768409ec1",
      "10a9713d160d4ebaaa8c310304c00f0b",
      "63309eaf911e4755b927ff3ac4c7ebf9",
      "113f84ee121e48fe8d2bb7e5f2572358",
      "a278c7beaa484463b3d3026993894409",
      "e6c47724c7a9402faa0e4b15d098f02b",
      "d0005cfb71954e57b350ce4cae65615c",
      "90fea743feb1454fa2632656a45e47df",
      "5a21d1ae5e424ab3897b36efc4e4b155",
      "d05974f63d924bf7975d1922aad20aa2",
      "a0c468b368ec4c04bb2ee2cef77ef880",
      "7c9fcde38f5942e3abdc354ff246e7f3",
      "795828d4b06c42feae457e0630cb1414",
      "954cb52fb4f54340937a303bb17bdbe7",
      "13f3d1d949d9443c937cf63716a382b2",
      "327f795dc78e41df91f2291b9d1e5c86",
      "3d1d1aac83444cacbca59c507ec72c35",
      "f4140702b6614f74bcf31055046aff36",
      "6e5649912d17485d831bac09c97b8673",
      "1564f474a0fb4fe2b6ad4043c46410d4",
      "688ae15a0c2145c4b024494d825814e3",
      "27846e9931e84c62a67e37e21a62d38e",
      "f6c96fb99e7c4452a4bd4e753dcd9b14",
      "fdcd7e47149a4267889c0cc11329b7a4",
      "804e43ead18943f2a6fb6183dad227a3",
      "0ce6b7c0f5974d2391cea2cac4e96b97",
      "be14b0b7fb7e4071a992953d047cd5ca",
      "c81692453ea04b8fb78170afc42963ce",
      "aa1d152bd6be4352adf6125a169d5d24",
      "13cdc263365846438ffab9bede351297",
      "09bf2a07cc00440f8fb02338bc89d07f",
      "05e2c5e0eb3542c69e2905baa44e34e9",
      "2929a08b195a459690bd91f59c53f287",
      "272c382d1adb438e86ae5a9248b18234",
      "b4a6a4dae0e14f9b9a7da95ec7c1625d",
      "7aa8be13faf6473691f46b4390e786d4",
      "579d20812a2643a98d687580bac01289",
      "4f65bea91f1749eb8871be505c7a8411",
      "c835d782c519436cb0aade689218d0bf",
      "fa44cdad089f4988a111bc551f0bf381",
      "41836ee03afa4fb2923863c04a20eaca",
      "15d9d7104fe344a9b4ccd12f3ebfef6a",
      "d2f98051e4cf48049ef97656620dec09",
      "327d0bb20c2e4310a9b2d9b9a703691e",
      "3b86c94fa21241c49ca28a0b5f02d136",
      "46fb1ab3640947689ac1d9fd7c82553e",
      "22051c2505b24817a9a8462666800d54",
      "1faef1f110774da8bd77e2e74438439d",
      "7ea4f65369494f3bbca3db9c71edc03a",
      "54cdc3eeebce4f10a25e8031890a5b7c",
      "bb3140666c724da7bde50abb2d78249a",
      "103ae13482ec4495bd17291dd458b139",
      "84c8a487389441ca8f8e19fc7b7b4399",
      "69c6c39d622a459e941fcf3d61d74826",
      "1058b5a0628e45afb8176451f063a03c",
      "3bf5aac786b04108a8c50e80f9ab33f2",
      "33a692ee0da346e3babe439bf97f068b",
      "e8b8a0881f35444aac1b73fa7abc304b",
      "486bf1ac736a4fa2b71183ab1fc74e3d",
      "9daac459e63d4ee58fa5e392f259a179",
      "8929b258d78a42198d86365513932b2a",
      "60a221e06cd24f73a012acb7f83f94ca",
      "559d26c540484161ba110d8dfde36891",
      "55f2bdf04b5b41aba05e712b1f01e77a",
      "a35868b89f964b4baa6a4b24597d76b3",
      "c6c32b49652c4823ac6e86b374ae497d",
      "59800c64640a4060932294743094fe06",
      "41d8a66673ff4263a3bcb6fd61d83dd4",
      "8bb661bde2b647a5b15fc623129b915c",
      "355746f16b97416f8ea0925e8bd84b4a",
      "ce68c462ea2648f9904782a188b6ad58",
      "40ae02c0d7574205aa1b5d95f0b21428",
      "8ae74a2860ac4af3a29d2c9d6c397deb",
      "37124f07e9554702a7b4d910a8c63081",
      "a577901e08254834941c7f046676f4d4",
      "81957f3d271044a0a1d29d37eb9844e6",
      "dc03d51ae34e4184a79f550043361418",
      "c2ba291aedd94238ab99dd6149d373e6",
      "bf6f5dc936cc435f8fb5e69d3e0b1824",
      "a53759dea36c4d32aec380b9679f6cd0",
      "8ab51c10c4cc4690ba275e66b23e1a2e",
      "6b7b258cec32473e94213a6b114dcbc9",
      "d1fa1f16177b48f7a8fdc1eb41abb4dc",
      "7bdd7e36df064765bcb81bf81e007d03",
      "baeca70afd684219876e5c94dd340982",
      "86d46c3498ba40dab9215868fa4ab791",
      "ee169c07af65499b80859568069e834c",
      "a4b2063b6e7a4b61817083b67c35e93c",
      "bdece0b350ed47b89359ed9760c22779",
      "ffb473ff13e346269518a7d6067c6a1e",
      "da6a32e95ecc4af0b8f4055c55c430f6",
      "fc8af26fe7b14d519f32640631a951e3",
      "25bca5bc0fe14a3d85301784ef9d65d7",
      "acb3551cf6b24fc084046d4d57598992",
      "73612f32cbd7424ea9e4dbb67e2a9d61",
      "ff4c290a83064f338df37a76ff17b235",
      "1244e282e0ef404f92409960650d981a",
      "68cc90696c40427ea57191b22b786509",
      "1f642f064ba84deb814ed0b585b65ba8",
      "6ec2bdf3799d4256941321c616425962",
      "240745b6a9bb49528f41fe4ffcc70c21",
      "09964f5b161045e3972247b9ef0ba7db",
      "d8e9b030a2e94d18bfe40df2ba75b7c8",
      "5955ad76109c478ab71cdc9c2c5b06ac",
      "e28fbc8cf215454791f625095cfbd796",
      "795b71db64ee4b2fa8bcc74b6852e21e",
      "a3c5e33ecf7f4f32b6be109c61fd009b",
      "130ff3dfbd734be59fa4e8b52ba0a8a8",
      "580ffaaaa9a548d8be912a9ecc095d1a",
      "1805780842414291a04bcb4d0523a075",
      "e904ff3c9a4d48378c59459542c4ff00",
      "23f3cec34b664c118a8eae0ab96a032d",
      "bb37517dd5574a4cafbad9a6d14391c4",
      "3d57eb0bab944227ba21807fdeb3f822",
      "4bfdd0d4272644f9870b1e22e8f81697",
      "9e82708cf4ac4afab90db79150f0ddf6",
      "cb868d6c8ee740dc9f021513c814d5bd",
      "4ad4eec944c34458893e8190435d66fd",
      "35d3a860f4bb46769d5d9de42d4a82ab",
      "d408356f2007427ca93710fccdc40a67",
      "78383bb2cc9b49838a9fd8ed3e889b18",
      "fb443aa5be0644e7a57aed33b2df583e",
      "fc4bf58300bf45e0b715a6e9f74923fb",
      "1bd446404a164fce840f0606e00cae95",
      "ef0966e1018a48d78311081787be2fe4",
      "d8ce3fdedf034213bb89bfcd77768c38",
      "c99b5066aade4aec85307fcb25f75c0d",
      "d9887379f22f467faa0a930594330c4b",
      "53bc26072b8642a3a9a59198812dcb41",
      "1931813247ec49fb8d4f1d3f2d4cef42",
      "ac05a95fa9af4633acd52a2540da8b97",
      "fa44c083a5ce485482b1b410ad8ac958",
      "2fd31cf9a8264b19bf367007b7ebfbbd",
      "b66f7b926f1f44e9bfc63d98329cb161",
      "f59ce46f01ea4ce8b2482deaa566ecbe",
      "b6982c0b7aae47c49df243083cb58407",
      "8044c350d374417997571a7169ce8044",
      "29396db654df43fc80fb7ac782ce9705",
      "cb38b87c49ec4192baf69b60eac609b4",
      "857c4cb6d0374ab78591716fd7585d4a",
      "28c32bfa78ee4307a7b49bfada657e24",
      "0bf3827ed82e4623812f7c3ff66c60d0",
      "7427b6238101468694fe6396751583a2",
      "e285aca4584d4b51805251764cfa8d26",
      "0e825605f29b41af9608e423ec2ef524",
      "84ad71f8547b45bbaaa8252320c56d90",
      "bcff17cbcd714dbc9c118e61b5eee1a8",
      "be562d52894e4ccd97fd76eede108a9f",
      "24a12dae13944ce68d602d4643973a09",
      "c9a383738ec14ab7937b6ed8e56367b4",
      "963d11d400444d11ac0e7bafc3f8023b",
      "80c524d4a0ad468dad95128d5dae43cc",
      "5e29b95c900f4380a84404bd56f06cee",
      "9d5f1ad976004a17be026eba4030e20d",
      "4c4dc5165ea84d93a3af14a4c8565447",
      "a39ca205ca054bfcad382af421bf7008",
      "d0b242c7c0d34b008416a1d55b43463e",
      "4b4f0d81f45842349f7a1fdeec7a7844",
      "16a4f5b591e74bfa82e34a1ecfdb49c7",
      "9ec993ab86fe4747a5c275e5d647c8be",
      "0e851b90e0364696bfc2b9b69a6f9895",
      "c5f3fdca631745bb8e115a2bfbb0aa6c",
      "1d19974f95cd484abc9062f8e04ff269",
      "5dd4885fbc1f41f38e5e7a1e44ca88e7",
      "f5533a7d4d7c4eac92cfca700e1667ea",
      "a6196cca67d541d0b337e704378aab86",
      "90f33d6256a04e4a8c924dc94ada3500",
      "62834c1ea27e4c9eae0e6f49c200b75d",
      "82d6ca893afc47b9be0ddac6c4a12821",
      "9c8ccae6e3f74941880fb0b1965e9f4d",
      "042fab0a8793481b8cac0cd124dec288",
      "84d61f6878df4acdb932c172d9d04902",
      "39ed7a4eee5b4615a6db3b02c26a140f",
      "81903a14e3524826b9340ccbebad4f13",
      "1a8bb8f857eb4469af38a97e81eb0911",
      "b150a8628ba14daea6c2fd34c015d102",
      "e0b2b68cfd0542f682b21598a2c35a14",
      "c4033e8c3f0b460091557f2bcba6d376",
      "b58ccdfd73374bbaac05c772f1640203",
      "23b6f39781b6437c8d6a5d363eb9b55e",
      "f145078d89e24e01be46f847dbc53ba5",
      "ecd0ca70e1e5433b8bf82552534e7167",
      "ffed9e9cc251466b9eda175e3038ede6",
      "b32338dad2c14a50b9b23b013d3e9439",
      "6bdca834eeba4a22a111ff53fa69e739",
      "c433645c72c346e9a8015671afb0e73f",
      "a6d40beb1d5f4ea4998c0048a78ab642",
      "bc027007e5964a0eb0d0d58c5df83150",
      "980714ea93694ebb8f25c517b0590fd8",
      "bf9edaf5eabe4ef2b90a890ae4d29b7d",
      "4b42972571ba42c4bd6dd777c73476a7",
      "5127029d48ff4c3dbb25c89f41e88f60",
      "ff297279f9b9403cbce987a2b338f000",
      "a7ddfc31d60e4e54adc363b1c28c4a72",
      "67e1898cb1314ed993f34e0f60b8ee99",
      "15a904a249c24a18999861c7dd82dc26",
      "d0758079233f41ff9cf405011d96bce0",
      "ff54edbac5414db09545f0624a6a2de8",
      "e13f9c60773e4501a95c33e32df5a080",
      "b3ce678e1ada429fab47add0aed7cc9e",
      "e9b7068c3b934670a2dd3a23eace831b",
      "d41e7de65f734c629b7239baded62a30",
      "19bd0a67db464c0997bd8dfa25f8f800",
      "c8e24d6d70d5430f85a2f60e8dbac7ff",
      "b8f72a3db02e443ba9370e04872f35de",
      "4dad9f2374904515b867a61ed3ffec32",
      "53da9db8d4064f35ac0bdf40d8cf1917",
      "c926a654cb4041c883c59efa65379247",
      "a4e669c2cb084c44914ab1302868539f",
      "e5c30c009eb14a26984143c19c5e7f7d",
      "832d040093a14040bdb8eb172a078661",
      "e770cf6d5be54b4da9047bae0b0ace81",
      "7dc21cefcb88434a810c29e2a52aa70a",
      "337aec7aba044144b5e5ee27487b8a08",
      "a288a8eabfc74bc08ce49568891aed24",
      "1ca2f4063c644159a2f3eeaedf32e497",
      "56282da41f7c4d7b92796288e3887991",
      "948c0a3c7485485e80d12a39e3b61dee",
      "fbb73a1d832446dd93b29cdadb8e3338",
      "5ffc2fb37bb44cb5b23d53aef5a8e301",
      "b85c2813f2c742ffa49af5a31a843ee7",
      "14d6c2cdc8454147b4c42908983cb464",
      "1fc237b6107f4e3798af9e066ae062de",
      "9aa90e11107846cf859cc0ee41801d60",
      "b6199d78ec9a4677b2ca056cb3eb1985",
      "80e368ec329f4f2c90f163010eb269ff",
      "5116aa7c071c4012b417cae32ae14eb5",
      "61fd139f18064a40ab208c611db586a4",
      "37b790bd5ade4a2f909ac2f496f71598",
      "bde1dc32c69a4874a8eb418edc44a32a",
      "917184a133ac41d2a227c6f29c197753",
      "63db10b4397e4fc981e87b0fb268f978",
      "8fe4c5ee7f454c39ab08ce4e7235b66a",
      "987c760b938a4ba19f2b8d84d50a0bfa",
      "ed93cf9667034609aab7257d75bba39b",
      "aae338b2eb884bb58d38fb0fbb7f9efd",
      "fd563eb9a9294eaaa7deedb3989f8b55",
      "01cf257c395e4f88a690cf0040e5e243",
      "f6d8307e3f224179ac1aa673c1a5a122",
      "bfce938020e64ca585409eebd1f56525",
      "be5be23a9c56409d9617286a89da8f7e",
      "4604b5a901754e208b43b4d73b4547fe",
      "2f500024c91245adaaba001a726ae141",
      "56f7686efcac487e8a60675e6b419735",
      "0acf7473a5e44a8dae1781b5e92d12ba",
      "d850d29977114426b48c76d464b77e13",
      "b66abef935a6442ebce3619524e3d220",
      "9d744fb1167b4ffcad06351aa9ede6fc",
      "249ad48ae2034d7d90ecd00fb11aef4c",
      "2b469a8d6f9f45189f0b950122d6d260",
      "37a4371482814cbeba08b2b3fa746116",
      "e29322f561164d2494370d4d19086565",
      "c39a1317bf784f60833f9b7eba4c0b1d",
      "ec85cb9d0af84f378292f0fb0c6fe1ab",
      "d45a26838380485a8ca416ab3b825540",
      "f6665ade26834bef8ad6549936e19670",
      "4b104a7ef2214fb7a2c59aacf4e747be",
      "391a1e008f7e4cd395914eb5a797a99d",
      "1860509a410b4287a281b1e65916a10c",
      "e39916ad5b3048de97330c8a0e5bd05d",
      "a946e46b60de44a5b3e273244706370b",
      "946d741563104827a0d9793e27c40749",
      "9259d99f8f8f455697eaf834d63663c7",
      "b97ea4b9918148a486d966efa2b075fe",
      "62adb0c7594847a58ea7461535d3fdb0",
      "05e9bd8e6280421e8e07d8f070fff0c9",
      "cd49d3ddcdb54f4b9e77bca27c2064aa",
      "7e07133114c14171973672ff36769fcd",
      "467e6411058f406895a8897c8ad3bb40",
      "3dee2dcef14b4f939bdc6189d6bad1af",
      "24369d16ce2f4cb2ab802469023d352e",
      "29622284ca8e4a61a3192fc93093627b",
      "6cb248d42e3941d2874e27381de492d6",
      "8454eeeb73f54ae2a5c72e52ee14ab86",
      "9c724ae99cdb4263ab00c8cab7dd5a17",
      "d64bb56f2eb347348a193dcd3d7996a4",
      "09b0a18623db42c4af1f2381b65f8672",
      "88fde644bd3d47f29aa74af53cdd7b4b",
      "0da683ff716a4b48a1cd825ea38ac5c5",
      "49adbb3d64a84a8ea9322b93e122690c",
      "343b2de6952c4ed2bf4d88171ab1d127",
      "394f0d89b1bd42028054eaee0b086495",
      "c2b64db3f04c43439b33291668be4a4a",
      "c2f072650bcc451b9af4304a90821d7a",
      "673b281d7f4e4f838a679deee00a648d",
      "575a9464a7644a268f4a316b8d6cb4e2",
      "166028a913c74544a7b5b214fd6730b9",
      "4636c6e826e447e2b5973f23b3cc9043",
      "006b528f1d0e4f11b535c92af97247b0",
      "41cb869d33e24f34ae3b3b22cb4e655b",
      "a2fb0567ea694305851047299871a3a5",
      "c2fe37ab938647d1b68f7263c832f1e4",
      "5c4487609c4446eb969f10703b84e461",
      "bddcf1c899be4f0a938192bc8eda7439",
      "efc75533314e47808f50fb38de3ce628",
      "a3cf630f3d614962a1064f69e64cf8ba",
      "493fca9540734ba49620c44b970919e8",
      "d8e6f1c410a146668c22574aede0cbc3",
      "c233d0c4b19246ebb350720c13763d0b",
      "30a04d37c3bc435fba5dfd4cdf87f0bc",
      "345896c0bf3548acba07383a63fe589c",
      "6beb1283153f4e05b71c14aad5ccdc25",
      "710841d81a044a50a0ac5af36e5a17b3",
      "7ff8fa64aced4b979652ce446d499309",
      "c1259f7789f0469eb81864f2bc23cbb7",
      "6fb531d74da74c03998907bc1d5ef48e",
      "bf1e1f447a7a408084c2891569fea437",
      "2bfd0788bfa246c18c7b1be025a99a48",
      "df8cb686c57d45a48f6f3a93583378ce",
      "de8c1e4d810447f598e8e64a80967f02",
      "a46b8567a4ce4aada143211f45b5d92d",
      "2c2990f67f2944799d335dc659cb28d0",
      "48f3337e898245fea651f842d0261b1c",
      "251da716b5594fe1b8929fcf6d530497",
      "9c3762636f2649b8be560909aa143c7b",
      "c419bac8bfb84b63930ce05dbe1afc2b",
      "58cef771abbc4579bc996c6012bacf75",
      "bf06a2bd1dd44c938085df5e54942259",
      "cc82cfd4a871498b8e09a519fdaf5ff7",
      "a299d20ed4264aa98e37749da4f5c023",
      "eb68902b922441c98752e3a61c404e63",
      "4158bb9033c042dc8a42fde7ffd000d8",
      "a7b870b7cf764a9b8f4a2f4c15c5dc3b",
      "e27521ea675449e98968821efef4f141",
      "6c75e2c7284a4e418bd1bfd88e6ab702",
      "4d51fd65380049c1afd4b8e086d88a74",
      "5fda0a1e9ff74435a8ff14cc1e60db62",
      "cfe13171ff454dd0a7fbd59ae49dac91",
      "7f37c6dbe91d49f08a21fe44a5d7a6ce",
      "e68f9ef57b204b95ac57ffbb9e1aa8a6",
      "eaee02bb61c447e69597eb7527a91ed9",
      "a1648eb24a724fe6b5bed08fbaca3bfa",
      "6fd5618e88cd46a6a92335e96f0bf509",
      "30414ddff53f470790e885d5a14cf08a",
      "c439912c7fbf46fdb5b7e7e08d667b80",
      "7e68eb484dd44944ad731cb1c752b2fe",
      "a0340b5b910f456db1d93185dbc5a8a7",
      "0df6374db5d046ab8d2047379c67f6c7",
      "639ef4d88bd149088fd80850b101858c",
      "97284d050f4141caa8711b6d849f028d",
      "21fa8bf5797f4337b28e65b7992a7778",
      "cbdbebaae3524fd289c51473a9256c15",
      "47bb6d67042c4878a109fce4d05246e6",
      "1fb3f27f553f4fe6a56994149e2ced35",
      "85d89e7aebc24de28bace2554df2870d",
      "24d62e107d834ed0825cf745c714a6b3",
      "792fe44369ee462ab253ad2aa4a3c2e2",
      "1ec1be9035674f3cbfb56479a2518482",
      "3a98291ed69740f0957be1914dd7fc50",
      "8b3a16a3310948399b3999ad57cba5a4",
      "a93101fd33634690b9ab6105269ca554",
      "eb75748ab5704601a920471098b0c00b",
      "c317b8d0870747838311b6825a74dcab",
      "0687bd2055004108a7dfacf23b705117",
      "f81e44634aab41e9b0c078f2fdbef5ba",
      "73247598c5a847a59780b7366d74daa6",
      "3c8d76b1e4fe4cc9a171e848335e7127",
      "7825dc0413884d1cb9d47036447beac6",
      "98bc1b4a7418419da5ec2ca26fbc453b",
      "91cdf2948ad840a4b5c72e2ff2b2247d",
      "36c267e5e3424a3da486403a5afb0617",
      "1cdcd9edc95346bab38b56b830277162",
      "2d0469d43d48496cabcb924ea0ed7a97",
      "2e0e7552a31441ecbcdff58b4786a17a",
      "bd71f3b72c9044f497de3909e132063a",
      "e7ea0599e2904e2b8d78b7d09804c5d3",
      "1ebbb948cd374fe9aa2f46f4e54716e6",
      "418eb18629514d68a4379de90bd80a99",
      "28690f75591a415083a10f8b8bdc07f2",
      "b427923ea0894e1faf9a79505dfa773e",
      "0c8619c2e70a411ab34d136dd9c8fc14",
      "eda16b4d4b954f3ea7746bf0de240b38",
      "0493b95b757547a4bdbb86b181f4e60f",
      "7bcec2a4fad948ff8ae89de72c6b301e",
      "a3da08c956df482886cf7237fc2751f8",
      "fdf215996edf444b943937ec58de67ed",
      "13c55fbd99be474fb412be95c3b4171d",
      "3e9fa8a288974dc0ade79bc686ec8b65",
      "173f4470350348b6aa7ed94894e7a7fe",
      "87a46cb44b9c4b528f8ad3b16fcac552",
      "a7446bc936a94defb45e9b8321430458",
      "924f8abc38454f9a868dbc50c83ca987",
      "4fe5e93cf2574f7e979c0288a44a64d0",
      "a03b667501bb4a29b7cfcf16d54c091d",
      "5c78277f605a44cda0faf278c4a68f9f",
      "8ed36193669a4869bda1596885cdb0d2",
      "f350bb8f275e43ee8013bbd7ddce9cd6",
      "34f5d99c694b4666beb28fc72a22c270",
      "be849746c6ca470db1c5e7c3f1cf8499",
      "43c75081bddc4234a692daf1ef1012b4",
      "4f968d0e884642a7a1fe3d4a188d7bcb",
      "8498f8475f614ce1a6dd037e41b204ee",
      "a3425c2358ac49b8bb33580b87b60188",
      "08ae05553e58456bba1a09b55b9b7f43",
      "8483006f1bf5477cb095d9b0ece27d38",
      "2bca801157394bfa879cff739272ae44",
      "fd9fa459e9fd4afa886e0cebfc294bf6",
      "e05c4665d8f6407c998675f3281676fb",
      "9cc28518a6064d5b88122e1737d57106",
      "f8f62b0a8a1344ceb12633aec36c4bb9",
      "4aa456362391412187805543964fad5c",
      "8eba24b2d58d480da511583ba54b674c",
      "ef4adfc703414ec2bf8f83b5937a8202",
      "ab38791e03344f6ca852a85d7a6419f3",
      "929a80771cd3485d8f7f5d945f1c3439",
      "0dbd401565ab476b807e5f804b94adfd",
      "0b9dbc7045bf43aa93009d046bcbed2f",
      "b11e76b643c44b8eb1b5a3857d494f7e",
      "07e8ab3962bc47a490ace21742289f16",
      "1247b5c5b8c5462593da8d12962e7ebd",
      "b22b6a09c1ca4fa080f7ddeb2c63beab",
      "d6b71be62acf42bc8d6d99b4d071e4c7",
      "b6f3ecefc37d4c3995dcf4d4fdecf6ec",
      "749426a4ae134fb0a6617fa57adced3f",
      "9ef1fdf8b94b4729a097ed761f62ff85",
      "f8db7763c00e48b0ab7eb63141d96e4b",
      "46c3efc65e4648f8aa450166c2222158",
      "43ddc544d83a4816ab0828e91b4add7a",
      "4eadea0ab0484359a223a7cbef591673",
      "354859247cb448329091c20eed6a06ff",
      "a86d5f17db6f4f2683a1f7c1088feb55",
      "cae4b0b3f6cd472f9705090a6667a010",
      "97f46e70b51446169cb6cf4e1741e9f8",
      "9d157c388b8943c4b94d76d5eae67633",
      "05654d2aca204aea92a26189a1ca3355",
      "f22a40b2f832446c9b0879b92e201e8c",
      "0b1ffea1c21f41479379875aa47802fd",
      "b51bf36e4e244ceea58d333a82ef1831",
      "eb05f1df7f64463d98ed56221b2ddd41"
     ]
    },
    "id": "93E9RdnR4D8v",
    "outputId": "cd5c6049-a748-48ed-aac9-9b8183e92dd2"
   },
   "outputs": [],
   "source": [
    "σ0 = 0.4\n",
    "k = 10\n",
    "num_epochs = 100\n",
    "\n",
    "# Exponential Moving Average\n",
    "# accelerates training and improves stability\n",
    "# holds a copy of the model weights\n",
    "ema = EMAModel(\n",
    "    parameters=sfp_velocity_net.parameters(),\n",
    "    power=0.75)\n",
    "\n",
    "# Standard ADAM optimizer\n",
    "# Note that EMA parametesr are not optimized\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=sfp_velocity_net.parameters(),\n",
    "    lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "# Cosine LR schedule with linear warmup\n",
    "lr_scheduler = get_scheduler(\n",
    "    name='cosine',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=500,\n",
    "    num_training_steps=len(dataloader) * num_epochs\n",
    ")\n",
    "\n",
    "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
    "    # epoch loop\n",
    "    for epoch_idx in tglobal:\n",
    "        epoch_loss = list()\n",
    "        # batch loop\n",
    "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
    "            for nbatch in tepoch:\n",
    "                # Device transfer\n",
    "                # Note that data is already normalized in the dataset.\n",
    "                nobs = nbatch['obs'].to(device)  # (B, To, O)\n",
    "                naction = nbatch['action'].to(device)  # (B, Tp, A)\n",
    "\n",
    "                # SFP integrates actions starting from the current timestep.\n",
    "                # But sequences extracted from the PushTDataset include actions\n",
    "                # corresponding to the previous timesteps as well (Tp includes\n",
    "                # To - 1 previous actions). The next line removes those.\n",
    "                ξ = naction[:, obs_horizon-1:, :]  # (B, Tp - To + 1, A)\n",
    "\n",
    "                # Sample t uniformly from [0, 1].\n",
    "                t = torch.rand(ξ.shape[0]).float().to(device)  # (B,)\n",
    "\n",
    "                ξt, dξdt = LinearlyInterpolateTrajectory(ξ, t)  # (B, A) and (B, A)\n",
    "                a, v = SampleCFMInputsAndTargets(ξt, dξdt, t, k, σ0)  # (B, A) and (B, A)\n",
    "                a, v = a.unsqueeze(1), v.unsqueeze(1)  # (B, 1, A) and (B, 1, A)\n",
    "                \n",
    "                # Conditional flow matching (CFM) loss: Mean-squared error\n",
    "                # between predicted velocity and target velocity\n",
    "                v̂t = sfp_velocity_net(\n",
    "                    sample=a,\n",
    "                    timestep=t,\n",
    "                    global_cond=nobs.flatten(start_dim=1),\n",
    "                )  # (B, 1, A)\n",
    "                loss = nn.functional.mse_loss(v, v̂t)  # (,) L2 loss\n",
    "\n",
    "                # optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                # step lr scheduler every batch\n",
    "                # this is different from standard pytorch behavior\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                # update Exponential Moving Average of the model weights\n",
    "                ema.step(sfp_velocity_net.parameters())\n",
    "\n",
    "                # logging\n",
    "                loss_cpu = loss.item()\n",
    "                epoch_loss.append(loss_cpu)\n",
    "                tepoch.set_postfix(loss=loss_cpu)\n",
    "        tglobal.set_postfix(loss=np.mean(epoch_loss))\n",
    "\n",
    "# Weights of the EMA model\n",
    "# is used for inference\n",
    "ema_spf_velocity_net = sfp_velocity_net\n",
    "ema.copy_to(ema_spf_velocity_net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pretrained checkpoint (optional)\n",
    "Set `load_pretrained = True` to load pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "load_pretrained = False\n",
    "if load_pretrained:\n",
    "  ckpt_path_sfp = \"pusht_state_100ep_sfp.ckpt\"\n",
    "  if not os.path.isfile(ckpt_path_sfp):\n",
    "      id = \"1ImuaEbldF68sqJTidbJGRLy-fwlAjk-m\"\n",
    "      gdown.download(id=id, output=ckpt_path_sfp, quiet=False)\n",
    "\n",
    "  state_dict_sfp = torch.load(ckpt_path_sfp, map_location='cuda')\n",
    "  ema_spf_velocity_net = sfp_velocity_net\n",
    "  ema_spf_velocity_net.load_state_dict(state_dict_sfp)\n",
    "  print('Pretrained SFP weights loaded.')\n",
    "else:\n",
    "  print(\"Skipped pretrained weight loading for SFP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming flow policy: Inference\n",
    "The rollout for 200 steps takes about 1.2s on an NVIDIA GeForce RTX4090, which is **5x times faster** than Diffusion Policy which needs about 6s. (see the Diffusion Policy inference section above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326,
     "referenced_widgets": [
      "4dccb12ed0ff4bcc88498569c827d02b",
      "3e673fa0cd0942669da3eb4241f663a0",
      "68d540a736f84500af654a6e63f0a4b3",
      "9897070169dd4a33bb55db2dd1108b82",
      "30f515165c444741ba53a8d06f47de8b",
      "679f382c54f745db9f4527dddf7fe422",
      "cb12be4034bd4f3da74a17f96f5ab6ce",
      "15289204170142b792663506b6a8ffde",
      "df6f8cb26f9b4c0986e6472f88e847de",
      "84831b87493e4207acbeaedbe3e92211",
      "68777f3a622841e8966c53de2be20d86"
     ]
    },
    "id": "OyLjlNQk5nr9",
    "outputId": "5fc02176-e9d3-42ed-87d2-b9f876f1c880"
   },
   "outputs": [],
   "source": [
    "# Get first observation\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Keep a queue of last 2 steps of observations\n",
    "obs_deque = collections.deque([obs] * obs_horizon, maxlen=obs_horizon)\n",
    "\n",
    "# Save visualization and rewards\n",
    "imgs = [env.render()]\n",
    "rewards = list()\n",
    "done = False\n",
    "step_idx = 0\n",
    "\n",
    "# Since we are at the beginning of the episode, extract the pusher state from\n",
    "# the current observation, normalize it, and use it as the \"action predicted\n",
    "# from the previous chunk\".\n",
    "a = obs[:action_dim]  # (A,)\n",
    "na = normalize_data(a, stats=stats['action'])  # (A,)\n",
    "na = torch.from_numpy(na).to(device, dtype=torch.float32)  # (A,)\n",
    "na_from_prev_chunk = na.unsqueeze(0).unsqueeze(0)  # (1, 1, A)\n",
    "\n",
    "max_steps = 200\n",
    "with tqdm(total=max_steps, desc=\"Eval PushTStateEnv [Streaming Flow Policy]\") as pbar:\n",
    "    while not done:\n",
    "        # Stack the last obs_horizon (2) number of observations\n",
    "        obs = np.stack(obs_deque)  # (To, O)\n",
    "        nobs = normalize_data(obs, stats=stats['obs'])  # (To, O)\n",
    "        o_test = torch.from_numpy(nobs).to(device, dtype=torch.float32)  # (To, O)\n",
    "        o_test = o_test.flatten().unsqueeze(0)  # (1, To * O)\n",
    " \n",
    "        # Start integration for this action chunk from the last action\n",
    "        # predicted from the previous chunk.\n",
    "        # Note that \"na_from_prev_chunk\" is always normalized.\n",
    "        na = na_from_prev_chunk  # (1, 1, A)\n",
    "\n",
    "        # ODE integration step size\n",
    "        Δt = 1.0 / (pred_horizon - obs_horizon)\n",
    "\n",
    "        # Generate action chunk open loop i.e. the action chunk uses the same\n",
    "        # observation for conditioning.\n",
    "        # These actions can be streamed to execute in the environment asynchronously.\n",
    "        with torch.no_grad():\n",
    "            for i in range(action_horizon):\n",
    "\n",
    "                # Stream the action to the environment (asynchronous step)\n",
    "                a = na.detach().to('cpu').numpy().squeeze(axis=(0, 1))  # (A,)\n",
    "                a = unnormalize_data(a, stats=stats['action'])  # (A,)\n",
    "                obs, reward, done, _, info = env.step(a)  # env step\n",
    "                obs_deque.append(obs)  # collect obs\n",
    "                rewards.append(reward)  # collect reward for visualization\n",
    "                imgs.append(env.render())  # collect image for visualization\n",
    "\n",
    "                # Update progress bar\n",
    "                step_idx += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(reward=reward)\n",
    "                if step_idx > max_steps: done = True\n",
    "                if done: break\n",
    "\n",
    "                # Euler integration step (asynchronous).\n",
    "                # Compute next action in the chunk.\n",
    "                t = torch.tensor(i * Δt, device=device)  # (,) current time\n",
    "                nv = ema_spf_velocity_net(\n",
    "                    sample=na,  # (1, 1, A)\n",
    "                    timestep=t,  # (,)\n",
    "                    global_cond=o_test,  # (1, To * O)\n",
    "                )  # (1, 1, A)\n",
    "                na = na + nv * Δt  # (1, 1, A)\n",
    "\n",
    "        # The last action is saved for the next chunk.\n",
    "        na_from_prev_chunk = na  # (1, 1, A)\n",
    "\n",
    "# print out the maximum target coverage\n",
    "print('Score: ', max(rewards))\n",
    "\n",
    "# Visualize\n",
    "duration_in_ms = len(imgs) * 50  # 20 FPS\n",
    "jviz.gif(imgs, time_in_ms=duration_in_ms, hold_last_frame_time_in_ms=1000) \\\n",
    "  .html(width=256, pixelated=False, title=\"Streaming flow policy\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "sfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
